#1559623402
dcsav
#1559623402
cdsa
#1559623403
csa
#1559623403
dc
#1559623408
history 
#1559623433
source ~/.bashrc
#1559623448
cat .bashrc
#1559623452
history 
#1559622845
man bash
#1559623679
source ~/.bashrc
#1559623768
ll
#1559623799
source ~/.bashrc
#1559623801
ll
#1559623851
source ~/.bashrc
#1559623858
ll | grep .
#1559623868
ll | grep .bash
#1559623874
source ~/.bashrc
#1559623877
ll | grep .bash
#1559623903
source ~/.bashrc
#1559623905
l
#1559623908
man openssl
#1559623967
source ~/.bashrc
#1559623968
ll
#1559623999
cde projetos
#1559624000
ll
#1559624002
cd projetos
#1559624002
ll
#1559624006
cd seg
#1559624007
ll
#1559624010
cd seg
#1559624014
cd seguranca/
#1559624015
ll
#1559624112
source ~/.bashrc
#1559624114
ll
#1559624121
cat trabalho_0
#1559624128
ls trabalho_0
#1559624130
ls trabalho_0*
#1559624183
source ~/.bashrc
#1559624185
ll
#1559624130
ls trabalho_0*
#1559624185
ll
#1559624277
cd ..
#1559624289
ls | grep .ba
#1559624292
ls | grep .ba*
#1559624306
ls -ls
#1559624310
ls -lt
#1559624528
source ~/.bashrc
#1559624529
ll
#1559624841
source ~/.bashrc
#1559624851
ll
#1559624886
source ~/.bashrc
#1559624899
ll
#1559625010
source ~/.bashrc
#1559625053
source ~/.bashrc
#1559625056
ll
#1559625365
source ~/.bashrc
#1559625366
ll
#1559625490
source ~/.bashrc
#1559625491
ll
#1559624310
ls -lt
#1559625545
ll
#1559625588
source ~/.bashrc
#1559625605
cd projetos/devops/
#1559625606
ll
#1559625628
cd git/
#1559625628
ll
#1559625630
cd images/
#1559625631
ll
#1559625744
source ~/.bashrc
#1559625745
ll
#1559625773
source ~/.bashrc
#1559625775
wget https://raw.githubusercontent.com/nachoparker/xcol/xcol_bash/xcol.sh -O - >> ~/.bashrc
#1559625790
source ~/.bashrc
#1559625792
ll
#1559625810
source ~/.bashrc
#1559625811
ll
#1559625823
wget https://raw.githubusercontent.com/nachoparker/xcol/xcol_bash/xcol.sh -O - >> ~/.bashrc
#1559625829
source ~/.bashrc
#1559625831
ll
#1559625833
cd ..
#1559625835
lol
#1559625835
ll
#1559625838
cd ..
#1559625839
ll
#1559625906
source ~/.bashrc
#1559625908
ll
#1559625972
1
#1559625972
2
#1559625972
3
#1559625972
sudo netstat -putan | xcol httpd sshd dnsmasq pulseaudio conky tor Telegram firefox   "[[:digit:]]+\.[[:digit:]]+\.[[:digit:]]+\.[[:digit:]]+" ":[[:digit:]]+" "tcp." "udp."   LISTEN ESTABLISHED TIME_WAIT
#1559625985
lspci | xcol audio vga pci usb amd ati hdmi ethernet radeon amd intel
#1559626051
source ~/.bashrc
#1559626053
ll
#1559626111
source ~/.bashrc
#1559626112
ll
#1559626143
source ~/.bashrc
#1559626144
ll
#1559626272
source ~/.bashrc
#1559626273
ll
#1559626281
ip addr
#1559626313
source ~/.bashrc
#1559626315
ip addr
#1559626373
source ~/.bashrc
#1559626375
ip addr
#1559626378
ll
#1559626384
cd git/
#1559626384
ll
#1559626427
source ~/.bashrc
#1559626430
ip addr
#1559626441
source ~/.bashrc
#1559626443
ip addr
#1559626487
which ip
#1559626540
ll
#1559626544
source ~/.bashrc
#1559626546
ll
#1559626567
source ~/.bashrc
#1559626569
ll
#1559626574
source ~/.bashrc
#1559626575
ll
#1559626595
echo $NORMAL
#1559626600
echo NORMAL
#1559626626
python -m unittest discover -v 2>&1 | colout '(.*ERROR$)|(.*FAIL$)|(\(.*\))' red,yellow,black bold
#1559626641
python -m unittest discover -v
#1559626647
python -m unittest discover -v 2>&1 | colout '(.*ERROR$)|(.*FAIL$)|(\(.*\))' red,yellow,black bold
#1559626705
cd
#1559626711
ll
#1559626714
ls -t
#1559626720
ll -t
#1559626726
cd nojhan-colout-b62b575/
#1559626727
ll
#1559626739
python setup.py install
#1559626760
sudo chmod 777 setup.py 
#1559626765
ll
#1559626770
python setup.py install
#1559626779
sudo python setup.py install
#1559626792
ll
#1559626794
cd ..
#1559626806
python -m unittest discover -v
#1559626815
python -m unittest discover -v 2>&1 | colout '(.*ERROR$)|(.*FAIL$)|(\(.*\))' red,yellow,black bold
#1559626866
cd nojhan-colout-b62b575/
#1559626867
sudo python3 setup.py install
#1559626893
ll
#1559627095
source ~/.bashrc
#1559627097
ll
#1559627112
source ~/.bashrc
#1559627114
ll
#1559627343
source ~/.bashrc
#1559627344
ll
#1559627370
source ~/.bashrc
#1559627371
ll
#1559627561
source ~/.bashrc
#1559627563
ll
#1559627742
source ~/.bashrc
#1559627747
ll
#1559627848
source ~/.bashrc
#1559627849
ll
#1559627860
source ~/.bashrc
#1559627863
ll
#1559627924
source ~/.bashrc
#1559627925
ll
#1559628079
source ~/.bashrc
#1559628149
ll
#1559628160
source ~/.bashrc
#1559628161
ll
#1559628169
source ~/.bashrc
#1559628171
ll
#1559628195
source ~/.bashrc
#1559628197
ll
#1559628208
source ~/.bashrc
#1559628209
ll
#1559628223
source ~/.bashrc
#1559628224
ll
#1559628293
source ~/.bashrc
#1559628313
ls -d ~/.dircolors
#1559628316
ll
#1559628355
ls -d ~/.dircolors
#1559628357
source ~/.bashrc
#1559628359
ll
#1559628509
source ~/.bashrc
#1559628510
ll
#1559628567
source ~/.bashrc
#1559628568
ll
#1559628650
source ~/.bashrc
#1559628664
ll
#1559628666
source ~/.bashrc
#1559628756
ll
#1559628757
source ~/.bashrc
#1559628761
ll
#1559628811
source ~/.bashrc
#1559628815
ll
#1559628859
source ~/.bashrc
#1559628862
ll
#1559628889
source ~/.bashrc
#1559628892
ll
#1559628946
source ~/.bashrc
#1559629027
ll
#1559629069
source ~/.bashrc
#1559629073
ll
#1559629106
source ~/.bashrc
#1559629111
ll
#1559629421
source ~/.bashrc
#1559629430
ll
#1559629432
source ~/.bashrc
#1559629440
ll
#1559629443
source ~/.bashrc
#1559629494
ll
#1559629498
source ~/.bashrc
#1559629502
ll
#1559629518
source ~/.bashrc
#1559629523
ll
#1559629538
source ~/.bashrc
#1559629570
ll
#1559629571
source ~/.bashrc
#1559629575
ll
#1559629593
source ~/.bashrc
#1559629597
ll
#1559629617
source ~/.bashrc
#1559629620
ll
#1559629779
source ~/.bashrc
#1559629783
ll
#1559629849
source ~/.bashrc
#1559629853
ll
#1559629891
source ~/.bashrc
#1559629894
ll
#1559629923
cd
#1559629933
cd projetos
#1559629934
ll
#1559629988
source ~/.bashrc
#1559629993
ll
#1559629998
cd ba
#1559630000
cd banco-de-dados/
#1559630002
ll
#1559630053
source ~/.bashrc
#1559630056
ll
#1559630175
source ~/.bashrc
#1559630179
ll
#1559630223
source ~/.bashrc
#1559630226
ll
#1559630291
source ~/.bashrc
#1559630297
ll
#1559630379
cd  ..
#1559630381
ll
#1559630386
cd becoming-a-expert-python/
#1559630386
kk
#1559630387
ll
#1559630399
source ~/.bashrc
#1559630402
lll
#1559630404
ll
#1559630468
source ~/.bashrc
#1559630472
ll
#1559630502
source ~/.bashrc
#1559630505
ll
#1559630549
source ~/.bashrc
#1559630552
çç
#1559630554
ll
#1559630562
source ~/.bashrc
#1559630566
ll
#1559630617
source ~/.bashrc
#1559630621
ll
#1559630633
source ~/.bashrc
#1559630636
ll
#1559630719
cd images/
#1559630723
ll
#1559630726
cd ..
#1559630727
ll
#1559630730
cd images/
#1559630756
source ~/.bashrc
#1559630759
ll
#1559630776
source ~/.bashrc
#1559630780
ll
#1559630782
cd ..
#1559630783
ll
#1559630837
source ~/.bashrc
#1559630840
ll
#1559630901
source ~/.bashrc
#1559630905
ll
#1559631006
source ~/.bashrc
#1559631010
ll
#1559631029
source ~/.bashrc
#1559631032
ll
#1559631145
source ~/.bashrc
#1559631148
ll
#1559631192
source ~/.bashrc
#1559631195
ll
#1559631213
source ~/.bashrc
#1559631216
ll
#1559631249
source ~/.bashrc
#1559631252
ll
#1559656776
ip addr
#1559656944
cd projetos
#1559656945
ll
#1559656991
mkdir linx
#1559656995
cd linx/
#1559656998
git clone git@github.com:chaordic/platform.git
#1559657016
git clone git@github.com:chaordic/platform-central.git
#1559657032
git clone git@github.com:chaordic/platform-dao.git
#1559657046
git clone git@github.com:chaordic/platform-confserver.git
#1559657068
git clone git@github.com:chaordic/platform-spark.git
#1559657086
git clone git@github.com:chaordic/platform-tools.git
#1559657106
git clone git@github.com:chaordic/platform-clients.git
#1559657136
cd
#1559657139
cd .ssh/
#1559657139
ll
#1559657167
rm -r apache.certificado.csr apache.privada.pem assinatura brunocampos.privada.pem brunocampos.publica.componentes brunocampos.publica.pem chave_secreta_brunocampos.bin chave_secreta_brunocampos.enc id_rsa_trab_02 id_rsa_trab_02.pub msgCifrada
#1559657206
sudo rm -r apache.certificado.csr apache.privada.pem assinatura brunocampos.privada.pem brunocampos.publica.componentes brunocampos.publica.pem chave_secreta_brunocampos.bin chave_secreta_brunocampos.enc id_rsa_trab_02 id_rsa_trab_02.pub msgCifrada
#1559657226
rm -r apache.certificado.csr apache.privada.pem assinatura brunocampos.privada.pem brunocampos.publica.componentes brunocampos.publica.pem chave_secreta_brunocampos.bin chave_secreta_brunocampos.enc id_rsa_trab_02 id_rsa_trab_02.pub msgCifrada
#1559657229
ll
#1559657232
cd bkp/
#1559657233
ll
#1559657259
mv id_rsa /home/campos/.ssh/
#1559657267
mv id_rsa.pub /home/campos/.ssh/
#1559657272
ll
#1559657274
cd ..
#1559657275
ll
#1559657282
git clone git@github.com:chaordic/platform.git
#1559657319
git clone git@github.com:chaordic/platform-dao.git
#1559657364
git clone git@github.com:chaordic/platform.git
#1559657368
git clone git@github.com:chaordic/platform-clients.git
#1559657387
git clone git@github.com:chaordic/platform-tools.git
#1559657415
git clone git@github.com:chaordic/platform-confserver.git
#1559657459
git clone git@github.com:chaordic/platform-central.git
#1559657513
git clone git@github.com:chaordic/platform-dumps.git
#1559657562
git clone git@github.com:chaordic/platform-dockerized.git
#1559657616
git clone git@github.com:chaordic/platform-search.git
#1559657658
git clone git@github.com:chaordic/platform-cache.git
#1559657675
git clone git@github.com:chaordic/platform-neemu-etl.git
#1559657732
git clone git@github.com:chaordic/platform-devops-services.git
#1559657746
git clone git@github.com:chaordic/platform-dumps-spark.git
#1559657762
git clone git@github.com:chaordic/platform-rt-storm.git
#1559657798
git clone git@github.com:chaordic/platform-chef-repo.git
#1559657917
git clone git@github.com:chaordic/platform-confclient-scala.git
#1559657962
git clone git@github.com:chaordic/platform-api-tools.git
#1559658047
git clone git@github.com:chaordic/operations-infra.git
#1559658091
git clone git@github.com:chaordic/dc-ansible.git
#1559658123
git clone git@github.com:chaordic/engage-search-routine.git
#1559658153
git clone https://github.com/chaordic/monit-infra.git
#1559658176
git clone git@github.com:chaordic/onsite-data-service.git
#1559658213
git clone git@github.com:chaordic/integration-pipeline.git
#1559658230
git clone git@github.com:chaordic/etl4_onsite.git
#1559658363
git clone https://github.com/chaordic/datalake-ingestion.git
#1559658378
git clone git@github.com:chaordic/etl4_mail.git
#1559658388
git clone https://github.com/chaordic/engine-dags.git
#1559658400
git clone git@github.com:chaordic/engine2.git
#1559658437
git clone https://github.com/chaordic/etl4_search.git
#1559658454
git clone https://github.com/chaordic/ansible-role-cloudwatch-dashboards.git
#1559658477
git clone git@github.com:chaordic/pp-scripts.git
#1559658508
git clone https://github.com/chaordic/ansible-role-aws-alarms.git
#1559658519
git clone git@github.com:chaordic/tiopatinhas.git
#1559658529
git clone git@github.com:chaordic/search.git
#1559659159
ll | grep data
#1559659180
git clone https://github.com/chaordic/datalake-ingestion.git
#1559659203
git clone git@github.com:chaordic/onsite-data-service.git
#1559692752
ll
#1559692762
cd ..
#1559692763
ll
#1559749546
jupyter-notebook
#1559749562
ll
#1559749568
cd projetos
#1559749568
ll
#1559749580
personal_config/
#1559749581
ll
#1559749589
git status
#1559749595
git add --all
#1559749602
git commit -m "refactor"
#1559749607
git push origin master 
#1559749666
code .
#1559749929
fc-cache
#1559749937
fc-cache -h
#1559750387
git add --all
#1559750390
git commit -m "refactor"
#1559750394
git push origin master 
#1559750402
ll
#1559750588
ifconfig
#1559750604
ipconfig
#1559750611
ip addr
#1559751103
ping www.ufsc.br
#1559751165
ping 
#1559751529
ping -c 
#1559751552
ping -c www.ufsc.br
#1559751560
ping -c 100 www.ufsc.br
#1559753845
man ping
#1559754502
cd
#1559754505
cd projetos
#1559754505
ll
#1559754508
cd compiladores/
#1559754510
ll
#1559754598
cd ..
#1559754601
ll
#1559754536
vim ~/.bashrc
#1559754652
source ~/.bashrc
#1559754664
ll
#1559754669
cd ..
#1559754670
ll
#1559758548
sudo add-apt-repository ppa:gnome-terminator
#1559758591
sudo apt-get update
#1559758607
sudo apt-get install terminator
#1559758634
cd .config/
#1559758634
ll
#1559758689
cd projetos
#1559758690
ll
#1559758704
cd becoming-a-expert-python/
#1559758705
ll
#1559758748
ip addr
#1559758767
cd ..
#1559758769
code .
#1559758966
ll
#1559759506
code .
#1559759569
cd ..
#1559759570
ll
#1559775335
ip addr
#1559775341
cd projetos
#1559775341
ll
#1559775347
cd becoming-a-expert-python/
#1559775348
ll
#1559775622
cd projetos
#1559775623
ll
#1559775721
cd becoming-a-expert-python/
#1559775723
ll
#1559775984
cd projetos
#1559775985
ll
#1559775987
cd becoming-a-expert-python/
#1559775989
ll
#1559776026
cd ..
#1559776027
ll
#1559776031
cd personal_config/
#1559776031
ll
#1559776034
git status
#1559776041
git add --all
#1559776048
git commit -m "amend"
#1559776053
git push origin master 
#1559776059
ll
#1559819813
cd ..
#1559819824
ll
#1559819838
cd cd personal_config/
#1559819845
cd personal_config/
#1559819847
ll
#1559819862
cpde .
#1559839780
code  
#1559839802
cd ..
#1559839804
ll
#1559845717
cd becoming-a-expert-python/
#1559845718
ll
#1559845723
cd ..
#1559845724
ll
#1559845744
cd devops/
#1559845745
ll
#1559845747
git status
#1559845758
git add --all
#1559845766
git commit -m "amend"
#1559845770
git push origin master 
#1559845791
cd
#1559845873
cd projetos
#1559845874
ll
#1559845935
cd personal_config/
#1559845936
code .
#1559846166
ll {HOME}/.config/terminator/config
#1559846172
ll {HOME}/.config/
#1559846183
ll .config/terminator/config
#1559846189
cat .config/terminator/config
#1559846198
code . .config/terminator/config
#1559846262
time for i in {1..30} ; do gnome-terminal --profile=Quickexit; done
#1559874260
ll
#1559874315
systemctl
#1559874396
systemctl -h
#1559874422
systemctl enable 
#1559874452
journalctl
#1559874470
journalctl -f
#1559874512
journalctl -h
#1559874530
journalctl 
#1559874566
journalctl | grep jun 06
#1559874568
journalctl | grep jun
#1559874654
cd projetos
#1559874655
kk
#1559874656
ll
#1559874659
cd seguranca/
#1559874660
cd ..
#1559874662
cd devops/
#1559874663
ll
#1559874664
code .
#1559874674
charm . &
#1559874678
charm .
#1559874681
pycharm .
#1559874688
code .
#1559874891
ll
#1559874896
cd projetos
#1559874897
ll
#1559874903
cd devops/
#1559874903
ll
#1559874954
journalctl -since=today
#1559874967
journalctl --since=today
#1559877738
ping www.google.com
#1559879848
ll
#1559879850
cd projetos
#1559879851
ll
#1559883912
kk
#1559884028
cd compiladores/
#1559884032
idea .
#1559884116
idea -h
#1559884126
idea --help
#1559884137
idea -v
#1559884167
cd trabalho_parte_02/
#1559884167
ll
#1559884240
javacc langX++.jj
#1559884249
javac parser/langX.java
#1559884257
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559884270
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559884458
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559884820
javacc langX++.jj
#1559884863
javacc parse/langX++.jj
#1559884891
javacc parser/langX+++.jj 
#1559884920
javac parser/langX.java
#1559884927
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559884938
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559885006
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559885345
java parser.langX -debug_AS testes_e_logs/debugAS.x 
#1559885514
java parser.langX -debug_AS testes_e_logs/classbody.x 
#1559885631
java parser.langX -debug_AS testes_e_logs/classbody2.x 
#1559885791
java parser.langX -debug_AS testes_e_logs/debug_analisador_sintatico.txt 
#1559885837
java parser.langX -debug_AS testes_e_logs/expression.x 
#1559886187
javacc parse/langX++.jj
#1559886199
javacc parser/langX++.jj
#1559886222
javacc parser/
#1559886232
cd parser/
#1559886232
ll
#1559886259
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1559886260
ll
#1559886262
cd ..
#1559886268
javacc parser/langX+++.jj 
#1559886275
javac parser/langX+++.jj 
#1559886298
javac parser/langX.java
#1559886300
ll
#1559886310
ls parse
#1559886322
ls parser/
#1559886329
javacc parser/langX+++.jj 
#1559886362
cd parser/
#1559886363
ll
#1559886370
javacc langX+++.jj 
#1559886372
ll
#1559886375
cd ..
#1559886421
ll
#1559886435
javac parser/langX.java
#1559886443
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559886451
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559886481
java parser.langX -debug_AS testes_e_logs/bintree-erro-sintatico.x
#1559886538
java parser.langX testes_e_logs/empty.x 
#1559886548
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1559886577
java parser.langX testes_e_logs/debugAS.x 
#1559886592
java parser.langX testes_e_logs/expression.x 
#1559886642
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559887178
java parser.langX testes_e_logs/expression.x 
#1559887202
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559887464
java parser.langX 
#1559887469
java parser.langX -h
#1559887475
java parser.langX --elp
#1559887478
java parser.langX --help
#1559887482
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559887494
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559887569
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559887868
cd
#1559887874
cd Downloads/
#1559887875
ll
#1559884154
idea .
#1559916659
cd projetos
#1559916660
ll
#1559916782
cd compiladores/
#1559916782
ll
#1559916784
code .
#1559917717
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559917728
cd trabalho_parte_02/
#1559917729
ll
#1559917731
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559917781
sudo apt install javacc
#1559917787
javacc parser/langX+++.jj
#1559917796
javac parser/langX.java
#1559917804
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559917820
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559917880
javacc parser/langX+++.jj
#1559918020
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559918484
javacc parser/langX+++.jj
#1559918499
javac parser/langX.java
#1559918506
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559918514
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559918536
java parser.langX -debug_AS testes_e_logs/expression.x 
#1559918580
javacc parser/langX+++.jj
#1559918609
cd parser/
#1559918616
javacc langX+++.jj
#1559918622
javac parser/langX.java
#1559918628
javac langX.java
#1559918657
cd ..
#1559918674
javac parser/langX.java
#1559918677
ll
#1559918698
java parser.langX -debug_AS testes_e_logs/expression.x 
#1559918787
cd ..
#1559918837
cd trabalho_parte_02/
#1559918837
ll
#1559918842
cd testes_e_logs/
#1559918843
ll
#1559918846
cd clean/
#1559918847
ll
#1559918854
javacc langX+++.jj
#1559918874
ll
#1559918885
cd ..
#1559918893
javac clean/langX.java
#1559918901
pwd
#1559919220
cd ..
#1559919222
ll
#1559919605
javacc parser/langX+++.jj
#1559919618
javac parser/langX.java
#1559919637
javacc parser/langX+++.jj
#1559919719
javac parser/langX+++.jj
#1559919723
cd parser/
#1559919724
ll
#1559919752
javac parser/langX+++.jj
#1559919756
ll
#1559919758
pwd
#1559919783
cd ..
#1559919784
ll
#1559919786
javac parser/langX+++.jj
#1559919808
javacc parser/langX+++.jj
#1559919816
javac parser/langX.java
#1559919827
cd parser/
#1559919829
javac parser/langX.java
#1559919834
javac langX.java
#1559919853
javac Parser.java 
#1559919862
cd ..
#1559919867
javac parser/Parser.java 
#1559919872
ll
#1559919882
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559919917
java parser.Parser testes_e_logs/bintree-erro-sintatico.x
#1559919966
ll
#1559919968
cd parser/
#1559919970
ll
#1559919985
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1559919986
ll
#1559920005
javacc langX+++.jj
#1559920379
ll
#1559920390
javacc -h
#1559920394
javacc --help
#1559920411
cd ..
#1559920429
javac parser/langX.java 
#1559920450
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559922318
cd parser/
#1559922320
ll
#1559916795
idea .
#1559922558
cd
#1559922560
cd projetos
#1559922561
ll
#1559922567
cd compiladores/
#1559922568
ll
#1559922575
cd trabalho_parte_02/
#1559922577
ll
#1559922583
cd parser/
#1559922583
ll
#1559922600
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1559922603
ll
#1559922706
cd projetos
#1559922707
ll
#1559922715
cd compiladores/
#1559922715
ll
#1559922738
idea . &
#1559922878
cd trabalho_parte_02/
#1559922879
ll
#1559922886
javacc parser/langX+++.jj
#1559922893
File "SimpleCharStream.java" does not exist.  Will create one.
#1559922909
javac parser/langX.java
#1559922926
javac --help
#1559922955
ll
#1559923019
javacc parser/langX+++.jj
#1559923079
javac -verbose parser/langX+++.jj
#1559923087
javac parser/langX+++.jj
#1559923118
javac parser/langX.java 
#1559923133
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559923675
cd..
#1559923676
ll
#1559923678
cd trabalho_parte_0
#1559923679
ll
#1559923680
cd ..
#1559923685
cd trabalho_parte_01/
#1559923685
ll
#1559923710
total 204K
#1559923723
java parser.langX -short testes_e_logs/teste-com-erro-lexico.x
#1559923731
ll
#1559923759
java parser.langX -short testes_e_logs/teste_lexico.x 
#1559923772
java parser.langX -short testes_e_logs/teste_lexico_com_erro.x 
#1559923921
code .
#1559923998
java parser.langX -short ../trabalho_parte_02/testes_e_logs/teste_expressoes_logicas.x 
#1559924083
java parser.langX -short ../trabalho_parte_02/testes_e_logs/expression.x 
#1559924098
java parser.langX -short ../trabalho_parte_02/testes_e_logs/empty.x 
#1559924108
java parser.langX -short ../trabalho_parte_02/testes_e_logs/debugAS.x 
#1559924120
java parser.langX -short ../trabalho_parte_02/testes_e_logs/classbody_sintactic_error.x 
#1559924179
cd ..
#1559924183
cd trabalho_parte_02/
#1559924183
ll
#1559924186
cd parser/
#1559924187
kk
#1559924188
ll
#1559924613
javacc parser/langX+++.jj
#1559924621
javacc langX+++.jj
#1559924625
ll
#1559924666
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1559924668
ll
#1559924673
javacc langX+++.jj
#1559924803
javac langX.java
#1559924808
cd ..
#1559924813
javac parser/langX.java
#1559924822
ll
#1559924842
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559924970
cd
#1559924977
cd projetos/c
#1559924979
cd projetos/compiladores/
#1559924980
ll
#1559924984
cd livro_como_construir_compilador/
#1559924985
ll
#1559924994
cd cap04/
#1559924996
ll
#1559925000
cd parser/
#1559925002
ll
#1559925022
javacc langX++.jj 
#1559925047
cd ..
#1559925048
ll
#1559925058
javac parser/langX.java 
#1559925096
java parser.langX ../ssamples/bintree-erro-sintatico.x 
#1559925248
java parser.langX -debug_AS ../ssamples/debugAS.x 
#1559925461
cd ..
#1559925467
cd trabalho_parte_02/
#1559925468
ll
#1559925975
git diff 
#1559926978
cd projetos
#1559926979
ll
#1559926981
cd compiladores/
#1559926981
ll
#1559926988
cd trabalho_parte_0
#1559926988
ll
#1559927000
idead . &
#1559927004
idea . &
#1559928013
ip addr
#1559928187
ll
#1559928209
javacc parser/langX+++.jj
#1559928300
git status
#1559928328
git reset --hard HEAD~1
#1559928336
ll
#1559928372
javacc parser/langX+++.jj
#1559928414
cd parser/
#1559928419
javacc langX+++.jj
#1559928429
cd ..
#1559928434
javac parser/langX.java 
#1559928437
ll
#1559928460
java parser.langX -debug_AS testes_e_logs/empty.x 
#1559928479
java parser.langX -debug_AS testes_e_logs/classbody_sintactic_error.x 
#1559928489
java parser.langX -debug_AS testes_e_logs/bintree-erro-sintatico.x 
#1559928500
java parser.langX -debug_AS testes_e_logs/expression.x 
#1559928517
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559928901
cd parser/
#1559928909
javacc langX+++.jj
#1559929007
cd ..
#1559929011
javacc langX+++.jj
#1559929021
javac langX+++.jj
#1559929028
javac parser/langX+++.jj
#1559929034
javac parser/langX.java 
#1559929050
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1559929090
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1559929190
kk
#1559929191
ll
#1559929198
cd parser/
#1559929199
ll
#1559929224
rm -r 'langX$JJCalls.class 'langX$LookaheadSuccess.class'
#1559929234
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1559929247
javacc langX+++.jj
#1559931530
cd ..
#1559931535
javac parser/langX.java 
#1559931550
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1559931556
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559931636
javac parser/langX.java 
#1559931654
cd parser/
#1559931655
ll
#1559931668
javacc langX+++.jj
#1559931671
cd ..
#1559931674
javac parser/langX.java 
#1559931684
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x 
#1559937079
cd projetos
#1559937079
ll
#1559948915
code .
#1559960625
cd devops/
#1559960625
ll
#1559960627
code .
#1559964653
cd ..
#1559964654
ll
#1559964656
code .
#1559966565
< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-32};
#1559968800
host localhost 
#1559968861
ll
#1559968876
telnet localhost 22
#1559968880
telnet localhost 3306
#1559969259
ll
#1559969285
mkdir learning-linux
#1559969288
de learning-linux/
#1559969295
cd learning-linux/
#1559969295
ll
#1559969302
code .
#1559970258
dig cockpit-db.platform.linximpulse.net 
#1559970285
ll
#1559970342
dig localhost
#1559970350
dig -h
#1559970357
man dig
#1559970396
dig www.ufsc.br
#1559970296
ssh cockpit-db.platform.linximpulse.net 
#1559970414
dig luigi.platform.chaordicsystems.com
#1559973001
cd ..
#1559973004
git clone git@github.com:brunocampos01/design-parttens.git
#1559973157
cd de
#1559973166
cd devops/
#1559973167
ll
#1559973171
git status
#1559973178
git add --all
#1559973201
git commit -m "upgrade"
#1559973204
git push origin master 
#1559973375
cd ..
#1559973376
ll
#1559973395
mkdir database-scripts
#1559973402
cd database-scripts/
#1559973709
cd ..
#1559973710
ll
#1559973720
cd devops/
#1559973722
ll
#1559973732
code .
#1559973778
git status
#1559973796
git add --all
#1559973806
git commit -m "refactor"
#1559973810
git push origin master 
#1559974003
cd ..
#1559974005
ll
#1559974007
cd becoming-a-expert-python/
#1559974008
ll
#1559974011
git status
#1559974022
git add --all
#1559974032
#git push origin master
#1559974040
git commit -m "refactor"
#1559974043
git push origin master
#1559974168
cd ..
#1559974170
code .
#1559974306
ll
#1559974312
cd linx/
#1559974313
ll
#1559974338
cd pp-scripts/
#1559974339
ll
#1559974410
cd ..
#1559974413
ll
#1559974438
mkdir etl-metrics-luigi
#1559974441
cd etl-metrics-luigi/
#1559974442
ll
#1559974444
code .
#1559974654
cd ..
#1559974655
ll
#1559974665
cd linx/
#1559974669
code .
#1559974723
cd ..
#1559974724
ll
#1559974726
cd seguranca/
#1559974727
ll
#1559974735
git pull origin master 
#1559974747
ll
#1559974751
rm -r becoming-a-expert-python/
#1559974756
ll
#1559974758
git status
#1559974763
git add --all
#1559974770
git commit -m "amend"
#1559974775
git push origin master 
#1559975078
mkdir redes
#1559975081
cd redes/
#1559975081
ll
#1559975085
code .
#1559977086
cd ..
#1559977096
code .
#1559977118
cd ..
#1559977123
git clone git@github.com:brunocampos01/introducao-a-informatica.git
#1559977142
code .
#1559996683
ping www.ufsc.br
#1559997630
cd projetos
#1559997631
ll
#1559997662
code .
#1560008429
ll
#1560008705
sudo chmod 776 -R arduino-e-hardware/
#1560008710
ll
#1560008729
sudo chmod 666 -R arduino-e-hardware/
#1560008731
ll
#1560008742
cd arduino-e-hardware/
#1560008762
sudo chmod 766 -R arduino-e-hardware/
#1560008763
ll
#1560008769
cd arduino-e-hardware/
#1560008771
ll
#1560008773
cd ..
#1560008775
ll
#1560008832
sudo chmod 736 -R arduino-e-hardware/
#1560008834
ll
#1560008851
sudo chmod 746 -R arduino-e-hardware/
#1560008852
ll
#1560008874
sudo chmod 756 -R arduino-e-hardware/
#1560008876
ll
#1560008896
sudo chmod 751 -R arduino-e-hardware/
#1560008897
ll
#1560008915
sudo chmod 761 -R arduino-e-hardware/
#1560008916
ll
#1560008925
sudo chmod 711 -R arduino-e-hardware/
#1560008926
ll
#1560008934
sudo chmod 731 -R arduino-e-hardware/
#1560008935
ll
#1560008948
sudo chmod 741 -R arduino-e-hardware/
#1560008949
ll
#1560008972
sudo chmod 751 -R arduino-e-hardware/
#1560008974
ll
#1560008991
sudo chmod 751 -R organization_and_architecture/
#1560008993
ll
#1560009010
sudo chmod 751 -R 'Probabilidade e estatística - INE 5606'/
#1560009012
ll
#1560009024
sudo chmod 751 -R tcc/
#1560009026
ll
#1560009043
sudo chmod 751 -R sistemas_operacionais/
#1560009044
ll
#1560009073
mv organization_and_architecture/ organizacao-e-arquitetura/
#1560009075
ll
#1560009107
mv sistemas_operacionais/ sistemas-operacionais/
#1560009156
mv 'Probabilidade e estatística - INE 5606'/ probabilidade-e-estatistica/
#1560009158
ll
#1560009330
code .
#1560009551
cd ..
#1560009558
code .
#1560009630
source .bashrc
#1560009634
ll
#1560009647
cd projetos
#1560009648
ll
#1560009726
source ~/.bashrc
#1560009730
ll
#1560009738
source ~/.bashrc
#1560009741
ll
#1560009834
#sudo chmod 751 -R projetos/
#1560009836
cd ..
#1560009846
ll | grep projetos
#1560009853
sudo chmod 751 -R projetos/
#1560009855
ll
#1560009858
ll | grep projetos
#1560009861
cd projetos
#1560009862
ll
#1560009868
cd t
#1560009871
cd tcc/
#1560009872
ll
#1560009873
cd ..
#1560009875
ll
#1560009938
source ~/.bashrc
#1560009943
ll
#1560010001
source ~/.bashrc
#1560010005
ll
#1560010012
source ~/.bashrc
#1560010015
ll
#1560010023
source ~/.bashrc
#1560010026
ll
#1560010037
source ~/.bashrc
#1560010040
ll
#1560010055
source ~/.bashrc
#1560010058
ll
#1560010067
source ~/.bashrc
#1560010070
ll
#1560010076
source ~/.bashrc
#1560010079
ll
#1560010092
source ~/.bashrc
#1560010095
ll
#1560010112
source ~/.bashrc
#1560010115
ll
#1560010127
source ~/.bashrc
#1560010130
ll
#1560010143
source ~/.bashrc
#1560010146
ll
#1560010161
cd becoming-a-expert-python/
#1560010162
ll
#1560010173
cd becoming-a-expert-python/
#1560010176
source ~/.bashrc
#1560010180
ll
#1560010236
source ~/.bashrc
#1560010240
ll
#1560010254
source ~/.bashrc
#1560010268
ll
#1560010270
source ~/.bashrc
#1560010273
ll
#1560010308
cd ..
#1560010311
code .
#1560011088
ll
#1560011470
cd ..
#1560011473
cd projetos_bkp/
#1560011475
ll
#1560011555
code .
#1560011685
cd ..
#1560011689
cd projetos
#1560011690
ll
#1560011725
mkdir venv_global
#1560011728
cd venv_global/
#1560011748
python3 -mod venv venv_global
#1560011751
ll
#1560011756
cd ..
#1560011757
ll
#1560011759
cd venv_global/
#1560011760
ll
#1560011768
python3 -mod venv .
#1560011770
ll
#1560011778
python3 -m venv .
#1560011781
ll
#1560011790
cd ..
#1560011796
source venv_global/bin/activate
#1560011797
ll
#1560011829
cd ..
#1560011832
cd projetos_bkp/
#1560011833
ll
#1560011839
cd data_warehouse/
#1560011913
pip3 install --user od                     numpy                     pandas                     matplotlib \
#1560011923
pip3 install --user od                     numpy                     pandas                     matplotlib jupyter
#1560011995
pip freeze
#1560012015
pip3 install jupyter
#1560012036
pip freeze
#1560012055
code .
#1560012095
jupyter-notebook 
#1560014295
ll
#1560014302
cd ..
#1560014305
cd learning_programming/
#1560014306
ll
#1560014308
cd java/
#1560014309
ll
#1560014314
idea . &
#1560014404
ll
#1560014407
idea . &
#1560014485
cd Trabalho2/
#1560014489
ll
#1560014492
idea . &
#1560014803
ll
#1560014807
cd ..
#1560014807
ll
#1560014836
mv Trabalho2 trabalho-app_android
#1560014837
ll
#1560014854
cd Trabalho1
#1560014854
ll
#1560014859
idea . &
#1560015297
ll
#1560015300
cd ..
#1560015301
kk
#1560015302
ll
#1560015310
rm -r Trabalho1
#1560015313
rm -r Trabalho1/
#1560015323
rm -r Trabalho01/
#1560015324
ll
#1560015570
cd ..
#1560015577
code .
#1560015594
cd ..
#1560015595
ll
#1560015601
cd data_warehouse/
#1560015602
ll
#1560015604
code .
#1560015653
file .
#1560015844
ll
#1560015847
cd ..
#1560015848
ll
#1560015862
cd ..
#1560015863
ll
#1560015871
cd projetos_bkp/
#1560015872
ll
#1560015877
ll
#1560015969
cd de
#1560015970
ll
#1560015973
cd devops/
#1560015974
ll
#1560015977
cd ..
#1560015983
rm -r devops/
#1560015983
ll
#1560016217
mv web_development/ /home/campos/projetos/
#1560016226
ll
#1560016229
cd softwares/
#1560016231
ll
#1560016248
code .
#1560016308
cd ,,
#1560016310
cd ..
#1560016312
ll
#1560016318
rm -r softwares/
#1560016319
ll
#1560016326
cd projects_arduino_sensors/
#1560016327
ll
#1560016329
code .
#1560016360
cd arduino-e-hardware/
#1560016361
ll
#1560016366
code .
#1560016420
mv _14_12_sem_sensor/ /home/campos/projetos/arduino-e-hardware/
#1560016440
mv Blink___/ /home/campos/projetos/arduino-e-hardware/
#1560016449
mv libraries/ /home/campos/projetos/arduino-e-hardware/
#1560016455
mv sensor_de_distancia_/ /home/campos/projetos/arduino-e-hardware/
#1560016457
ll
#1560016459
cd ..
#1560016469
rm -r projects_arduino_sensors/
#1560016470
ll
#1560016473
ll
#1560016508
cd analysing/
#1560016511
ll
#1560016521
cd ..
#1560016522
ll
#1560016529
git clone git@github.com:brunocampos01/analysing.git
#1560016615
cd ..
#1560016616
ll
#1560016618
cd analysing/
#1560016619
ll
#1560016621
cd ..
#1560016626
rm -r analysing/
#1560016627
ll
#1560016633
cd 
#1560016638
cd projetos_bkp/
#1560016639
ll
#1560016642
cd algoritms/
#1560016642
ll
#1560016724
code .
#1560016786
ll
#1560016850
git clone git@github.com:brunocampos01/algoritms.git
#1560016855
cd ..
#1560016856
ll
#1560016860
ll
#1560016868
rm -r algoritms/
#1560016868
ll
#1560016877
cd big_data/
#1560016878
ll
#1560017083
code .
#1560017205
ll
#1560017207
cd ..
#1560017208
ll
#1560017213
rm -r big_data/
#1560017215
ll
#1560017299
cd challenges/
#1560017300
ll
#1560017305
cd challenges/
#1560017306
kk
#1560017308
ll
#1560017331
code .
#1560017513
cd ..
#1560017514
ll
#1560017529
cd ..
#1560017529
ll
#1560017534
cd web_development/
#1560017534
ll
#1560017539
code .
#1560017576
cd .
#1560017578
cd ..
#1560017581
code .
#1560017980
cd crawler_and_scrapping/
#1560017981
ll
#1560018064
code .
#1560018164
cd ..
#1560018164
ll
#1560018182
mv crawler_and_scrapping/ /home/campos/projetos/
#1560018185
ll
#1560018187
cd ..
#1560018188
ll
#1560018215
mv crawler_and_scrapping/ crawlre-and-scrapping/
#1560018216
ll
#1560018225
mv crawler_and_scrapping/ crawler-and-scrapping/
#1560018236
mv crawlre-and-scrapping/ crawler-and-scrapping/
#1560018238
ll
#1560018242
cd crawler-and-scrapping/
#1560018243
ll
#1560018289
ll
#1560018293
cd ..
#1560018294
ll
#1560018324
cd data_
#1560018327
cd data_base/
#1560018328
ll
#1560018337
cd ..
#1560018349
rm -r data_base/
#1560018350
ll
#1560018358
cd data_science/
#1560018359
ll
#1560018362
cd machine_learning/
#1560018363
ll
#1560018365
cd supervised_learning/
#1560018365
ll
#1560018368
cd decision_tree/
#1560018368
ll
#1560018371
code .
#1560018468
ll
#1560018502
cd ..
#1560018503
cde ..
#1560018505
cd ..
#1560018508
ll
#1560018510
cd artificial_inteligence/
#1560018511
ll
#1560018529
code .
#1560018943
cd de
#1560018945
cd design-parttens/
#1560018946
ll
#1560018964
cd ..
#1560018965
cd introducao-a-informatica/
#1560018966
ll
#1560019350
cd ..
#1560019352
ll
#1560019369
git clone git@github.com:brunocampos01/desenvolvimento-de-sistemas.git
#1560019513
ll
#1560019522
cd li
#1560019524
cd livros-computacao/
#1560019525
ll
#1560019531
cat conceitos_linguagens_programação_e_paradigmas.pdf 
#1560019543
cat bin conceitos_linguagens_programação_e_paradigmas.pdf 
#1560019658
ll
#1560019660
cd ..
#1560019661
ll
#1560019713
git clone git@github.com:brunocampos01/programacao-paralela-e-distribuida.git
#1560019757
ll
#1560020194
cd data-science/
#1560020196
ll
#1560020243
cd ..
#1560020244
ll
#1560020534
cd ..
#1560020536
ll
#1560020585
cd ..
#1560020589
cd projetos_bkp/
#1560020590
ll
#1560020592
code .
#1560020903
cd linx/
#1560020903
ll
#1560025403
ping www.google.com
#1560063042
ll
#1560063044
cd ..
#1560063111
ll
#1560063115
cd algoritms/
#1560063116
ll
#1560063122
cd ..
#1560063123
ll
#1560063129
cd analysing/
#1560063130
ll
#1560063139
cd we
#1560063143
cd ..
#1560063143
ll
#1560063146
cd web_development/
#1560063146
ll
#1560063153
git status
#1560063179
git init
#1560063181
ll
#1560063189
cd .git/
#1560063191
ll
#1560063196
code .
#1560063208
ll
#1560063212
cd papyrus/
#1560063213
ll
#1560063216
cd .git/
#1560063217
ll
#1560063219
code .
#1560063486
pwd
#1560063506
ll
#1560063511
cd ..
#1560063512
ll
#1560063549
git add --all
#1560063558
git commit -m "First commit"
#1560063568
git add -h
#1560063594
git -h
#1560063634
git remote -h
#1560063675
git remote add https://github.com/brunocampos01/web_development
#1560063686
git remote add origin
#1560063698
git remote add origin https://github.com/brunocampos01/web_development
#1560063703
git config
#1560063706
git config --all
#1560063713
git config --list 
#1560063728
git status
#1560063734
git push origin master 
#1560063827
git config --list
#1560063842
git config -h
#1560063899
git config --global user.name brunocampos01
#1560063941
git config --global user.email brunocampos01@gmail.com
#1560063966
git push origin master 
#1560064113
git push -u origin master
#1560064129
git config --list
#1560064143
git push -u origin master
#1560064172
git pull
#1560064192
git pull origin master 
#1560064210
git push -u origin master
#1560064245
git pull origin master -f
#1560064248
git push -u origin master
#1560064368
git pull origin master -f
#1560064382
gitk --all
#1560064417
ll
#1560064501
git config --list
#1560064530
git pull origin master -f
#1560064535
ll
#1560064543
git push origin master
#1560064599
cd
#1560064603
cd projetos/
#1560064603
ll
#1560064606
cd de
#1560064576
git push origin master -f
#1560064609
cd devops/
#1560064617
code .
#1560065044
git config remote -h
#1560065051
git config -h
#1560065064
git remote -h
#1560065074
git remote add -h
#1560065236
git config --list
#1560065462
ll
#1560065465
git status
#1560065471
git add --all
#1560065481
git commit -m "amend"
#1560065484
git push origin master 
#1560065556
code .
#1560066130
git add --all
#1560066136
git commit -m "amend"
#1560066139
git push origin master 
#1560066353
code .
#1560067812
git remote -v
#1560070625
eval "$(ssh-agent -s)"
#1560070639
ps | aux 
#1560070645
ps aux 
#1560070651
ps aux | grep ssh
#1560070668
systemctl ssh
#1560070681
systemctl --state ssh
#1560133923
ll
#1560133932
cd projetos/
#1560133932
ll
#1560135305
cd seguranca/
#1560135305
ll
#1560135436
cd ..
#1560135436
ll
#1560135452
cd compiladores/
#1560135452
ll
#1560135456
git status
#1560135492
cd ..
#1560135516
cd database-scripts/
#1560135517
ll
#1560135583
git init
#1560135585
ll
#1560135598
git remote add git@github.com:brunocampos01/database-scripts.git
#1560135607
git remote add origin git@github.com:brunocampos01/database-scripts.git
#1560135609
ll
#1560135612
git status
#1560135617
git config --list
#1560135625
ll
#1560135631
git pull origin ma
#1560135634
git pull origin master
#1560135642
ll
#1560135653
git add --all
#1560135663
git commit -m "first"
#1560135667
git push origin master 
#1560137156
cd ..
#1560137157
ll
#1560137224
mv data_warehouse/ data-warehouse/
#1560137226
ll
#1560137230
cd data-warehouse/
#1560137231
ll
#1560137277
code .
#1560137338
git init
#1560137409
git status
#1560137430
git remote add origin git@github.com:brunocampos01/data-warehouse.git
#1560137447
git config --list
#1560137466
git remote -h
#1560137513
git remote rename git@github.com:brunocampos01/data-warehouse-.git git@github.com:brunocampos01/data-warehouse.git
#1560137518
git config --list
#1560137534
git remote rename https://github.com/brunocampos01/data-warehouse-.git git@github.com:brunocampos01/data-warehouse.git
#1560137560
git remote -v
#1560137582
git add --all
#1560137590
git commit -m "first"
#1560137600
git push origin master 
#1560137630
ll
#1560137637
rm -rf .git/
#1560137638
ll
#1560137643
git init
#1560137649
ll
#1560137656
git remote -v
#1560137664
git remote add origin git@github.com:brunocampos01/data-warehouse.git
#1560137671
git add --all
#1560137688
git pull origin master
#1560137704
git commit -m "First"
#1560138797
ll
#1560138799
cd ..
#1560138800
ll
#1560138814
cd compiladores/
#1560138815
ll
#1560138823
idea . &
#1560137710
git push origin master
#1560139348
ll
#1560139352
cd trabalho_parte_02/
#1560139353
ll
#1560139549
javacc parser/langX++.jj
#1560139569
javacc parser/langX+++.jj 
#1560139571
ll
#1560139580
javac parser/langX.java 
#1560139588
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1560139599
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1560139610
java parser.langX testes_e_logs/debugAS.x
#1560139653
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560139729
javac parser/langX.java
#1560139742
javacc langX+++.jj
#1560139752
javacc parse/langX+++.jj 
#1560139759
javacc parser/langX+++.jj 
#1560139762
javac parser/langX.java
#1560139773
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1560139803
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560139830
ll
#1560139836
cd  parser/
#1560139836
ll
#1560139858
rm -r 'langX$JJCalls.class'* 'langX$LookaheadSuccess.class'*
#1560139860
ll
#1560139865
cd ..
#1560139872
javacc parser/langX+++.jj 
#1560139878
javac parser/langX.java
#1560139882
ll
#1560139888
cd ..
#1560139892
cd trabalho_parte_0
#1560139895
cd trabalho_parte_02
#1560139896
ll
#1560139942
cd parser/
#1560139943
ll
#1560139945
cd ..
#1560139946
ll
#1560140610
javacc parser/langX+++.jj 
#1560140612
ll
#1560140618
javac parser/langX.java 
#1560140632
ll
#1560140640
cd parser/
#1560140641
ll
#1560140644
cd ..
#1560140646
ll
#1560140672
javacc parser/langX+++.jj 
#1560140674
ll
#1560140720
javacc parser/langX+++.jj 
#1560140721
ll
#1560140725
cd parser/
#1560140725
ll
#1560140729
cd ..
#1560140730
ll
#1560140740
javac parser/langX.java 
#1560140757
java parser.langX testes_e_logs/bintree-erro-sintatico.x
#1560140823
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560140851
javacc parser/langX+++.jj 
#1560140858
javac parser/langX.java 
#1560140864
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560141158
javacc parser/langX+++.jj 
#1560141191
javac parser/langX.java 
#1560141194
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560141222
javacc parser/langX+++.jj 
#1560141223
javac parser/langX.java 
#1560141225
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560141253
javacc parser/langX+++.jj 
#1560141254
javac parser/langX.java 
#1560141258
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560146138
ll
#1560146180
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560146205
javacc parser/langX+++.jj 
#1560146208
javac parser/langX.java 
#1560146211
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560146356
javacc parser/langX+++.jj 
#1560146357
javac parser/langX.java 
#1560146360
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560146944
javacc parser/langX+++.jj 
#1560147177
javac parser/langX.java 
#1560147180
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560147202
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560147529
javacc parser/langX+++.jj 
#1560147531
javac parser/langX.java 
#1560147737
javacc parser/langX+++.jj 
#1560147738
javac parser/langX.java 
#1560147741
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560147753
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560147827
javacc parser/langX+++.jj 
#1560147829
javac parser/langX.java 
#1560147833
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560147939
javacc parser/langX+++.jj 
#1560147941
javac parser/langX.java 
#1560147971
javacc parser/langX+++.jj 
#1560147972
javac parser/langX.java 
#1560147989
ll
#1560147990
javacc parser/langX+++.jj 
#1560147992
javac parser/langX.java 
#1560148017
javacc parser/langX+++.jj 
#1560148018
javac parser/langX.java 
#1560148035
javacc parser/langX+++.jj 
#1560148035
javac parser/langX.java 
#1560148052
javacc parser/langX+++.jj 
#1560148053
javac parser/langX.java 
#1560148082
javacc parser/langX+++.jj 
#1560148083
javac parser/langX.java 
#1560148092
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560148101
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560148265
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560148827
javacc
#1560148889
lltree parser/langX+++.jj 
#1560148894
jjtree parser/langX+++.jj 
#1560148839
man javacc
#1560149765
javacc parser/langX+++.jj 
#1560150015
javac parser/langX.java 
#1560150019
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560150027
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560150136
javacc parser/langX+++.jj 
#1560150138
javac parser/langX.java 
#1560150142
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560150471
javacc parser/langX+++.jj 
#1560150473
javac parser/langX.java 
#1560150477
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560150996
javacc parser/langX+++.jj 
#1560151096
javac parser/langX.java 
#1560151099
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151128
javacc parser/langX+++.jj 
#1560151131
javac parser/langX.java 
#1560151133
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151251
javacc parser/langX+++.jj 
#1560151253
javac parser/langX.java 
#1560151256
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151302
javacc parser/langX+++.jj 
#1560151303
javac parser/langX.java 
#1560151306
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151319
javacc parser/langX+++.jj 
#1560151321
javac parser/langX.java 
#1560151324
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151370
javac parser/langX.java 
#1560151372
javacc parser/langX+++.jj 
#1560151374
javac parser/langX.java 
#1560151377
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151507
javacc parser/langX+++.jj 
#1560151509
javac parser/langX.java 
#1560151511
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560151739
javacc parser/langX+++.jj 
#1560151742
javac parser/langX.java 
#1560151745
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152081
javacc parser/langX+++.jj 
#1560152082
javac parser/langX.java 
#1560152085
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152111
javacc parser/langX+++.jj 
#1560152112
javac parser/langX.java 
#1560152115
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152163
java parser.langX testes_e_logs/classbody_sintactic_error.x 
#1560152196
java parser.langX testes_e_logs/debugAS.x 
#1560152231
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152507
javacc parser/langX+++.jj 
#1560152509
javac parser/langX.java 
#1560152513
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152550
javacc parser/langX+++.jj 
#1560152551
javac parser/langX.java 
#1560152554
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152582
javacc parser/langX+++.jj 
#1560152584
javac parser/langX.java 
#1560152587
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152677
javacc parser/langX+++.jj 
#1560152679
javac parser/langX.java 
#1560152681
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152755
javacc parser/langX+++.jj 
#1560152757
javac parser/langX.java 
#1560152760
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560152814
javacc parser/langX+++.jj 
#1560152816
javac parser/langX.java 
#1560152819
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560153255
javacc parser/langX+++.jj 
#1560153256
javac parser/langX.java 
#1560153258
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560153359
javacc parser/langX+++.jj 
#1560153361
javac parser/langX.java 
#1560153363
javacc parser/langX+++.jj 
#1560153365
javac parser/langX.java 
#1560153368
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560153491
java parser.langX testes_e_logs/expression.x 
#1560153580
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154238
javacc parser/langX+++.jj 
#1560154240
javac parser/langX.java 
#1560154242
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154266
javacc parser/langX+++.jj 
#1560154268
javac parser/langX.java 
#1560154270
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154368
javacc parser/langX+++.jj 
#1560154370
javac parser/langX.java 
#1560154372
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154403
javac parser/langX.java 
#1560154406
javacc parser/langX+++.jj 
#1560154407
javac parser/langX.java 
#1560154410
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154428
javacc parser/langX+++.jj 
#1560154430
javac parser/langX.java 
#1560154439
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154819
javacc parser/langX+++.jj 
#1560154846
javac parser/langX.java 
#1560154848
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560154998
cd ..
#1560154999
kk
#1560155000
[ll
#1560155009
cd compiladores/
#1560155009
ll
#1560155012
git status
#1560155016
git add --all
#1560155058
git commit -m "refactor: add new tests and changes in langX+++"
#1560155062
git push origin master 
#1560155090
git pull origin master 
#1560155101
git push origin master -f
#1560155888
javacc parser/langX+++.jj 
#1560155890
javac parser/langX.java 
#1560155894
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560155977
javacc parser/langX+++.jj 
#1560155979
javac parser/langX.java 
#1560155982
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156125
javacc parser/langX+++.jj 
#1560156126
javac parser/langX.java 
#1560156129
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156144
javacc parser/langX+++.jj 
#1560156146
javac parser/langX.java 
#1560156148
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156294
javacc parser/langX+++.jj 
#1560156295
javac parser/langX.java 
#1560156298
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156341
javacc parser/langX+++.jj 
#1560156343
javac parser/langX.java 
#1560156346
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156373
javacc parser/langX+++.jj 
#1560156374
javac parser/langX.java 
#1560156377
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156428
javacc parser/langX+++.jj 
#1560156430
javac parser/langX.java 
#1560156433
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156647
javacc parser/langX+++.jj 
#1560156649
javac parser/langX.java 
#1560156790
javacc parser/langX+++.jj 
#1560156792
javac parser/langX.java 
#1560156795
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156823
javacc parser/langX+++.jj 
#1560156825
javac parser/langX.java 
#1560156827
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560156845
java parser.langX testes_e_logs/expression.x 
#1560156847
javac parser/langX.java 
#1560156850
javacc parser/langX+++.jj 
#1560157110
javac parser/langX.java 
#1560157115
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560157221
javacc parser/langX+++.jj 
#1560157223
javac parser/langX.java 
#1560157225
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560157234
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560157508
javac parser/langX.java 
#1560157512
javacc parser/langX+++.jj 
#1560157514
javac parser/langX.java 
#1560157516
java parser.langX testes_e_logs/bintree-erro-sintatico.x 
#1560157527
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560157715
javacc parser/langX+++.jj 
#1560157717
javac parser/langX.java 
#1560157720
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560158162
code .
#1560160261
javacc parser/langX+++.jj 
#1560160632
javac parser/langX.java 
#1560160640
ll
#1560160683
pwd
#1560160686
javacc parser/langX+++.jj 
#1560160691
javac parser/langX.java 
#1560160951
cd parser/
#1560160952
ll
#1560160987
rm -r 'langX$LookaheadSuccess.class' 'langX$JJCalls.class'
#1560160989
cd ..
#1560160995
javac parser/langX.java 
#1560160999
javacc parser/langX+++.jj 
#1560161001
javac parser/langX.java 
#1560161012
cd parser/
#1560161012
ll
#1560161014
javac parser/langX.java 
#1560161020
javac langX.java 
#1560161030
pwd
#1560161032
cd ..
#1560161135
cd /home/campos/projetos/compiladores/livro_como_construir_compilador/cap05
#1560161136
ll
#1560161145
javacc parser/langX++.jj 
#1560161175
ll
#1560161178
cd parser/
#1560161179
ll
#1560161181
cd..
#1560161193
cd ..
#1560161195
ll
#1560161200
cd cap05/
#1560161201
ll
#1560161215
cd parser/
#1560161216
ll
#1560161223
javacc langX++.jj 
#1560161224
ll
#1560161231
cd ..
#1560161232
ll
#1560161260
javac parser.langX.java
#1560161272
javac langX.java
#1560161280
code .
#1560161338
javac langX.java
#1560161346
javacc langX++.jj 
#1560161349
ll
#1560161351
cd parser/
#1560161352
ll
#1560161354
javacc langX++.jj 
#1560161363
javac langX.java
#1560161387
cd ..
#1560161403
javac parser/langX.java 
#1560161763
ll
#1560161766
cd trabalho_parte_02-analisador_sintatico/
#1560161767
ll
#1560161771
cd parser/
#1560161772
ll
#1560161789
javacc parser/langX+++.jj 
#1560161796
ll
#1560161798
cd ..
#1560161800
javacc parser/langX+++.jj 
#1560161819
ll
#1560161831
javac parser/langX.java 
#1560161920
ll
#1560161923
pwd
#1560161926
javac parser/langX.java 
#1560162010
javacc parser/langX+++.jj 
#1560162013
javac parser/langX.java 
#1560162071
javacc parser/langX+++.jj 
#1560162073
javac parser/langX.java 
#1560162334
ll
#1560162338
cd parser/
#1560162339
ll
#1560162345
rm -r 'langX$LookaheadSuccess.class' 'langX$JJCalls.class'
#1560162352
ll
#1560162354
cd ..
#1560162359
ll
#1560162464
javacc parser/langX+++.jj 
#1560162472
javac parser/langX.java 
#1560162490
javac -Xlint parser/langX.java 
#1560162497
javac parser/langX.java 
#1560162645
javacc parser/langX+++.jj 
#1560162649
javac parser/langX.java 
#1560162679
javacc parser/langX+++.jj 
#1560162681
javac parser/langX.java 
#1560182124
javacc parser/langX+++.jj 
#1560182126
javac parser/langX.java 
#1560182134
pwd
#1560182141
ll
#1560182214
javacc parser/langX+++.jj 
#1560182217
javac parser/langX.java 
#1560182225
ll
#1560182233
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560182304
java parser.langX testes_e_logs/debugAS.x 
#1560182313
java parser.langX testes_e_logs/teste_com_erro_classbody.x 
#1560182326
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560183316
javacc parser/langX+++.jj 
#1560186245
javac parser/langX.java 
#1560186281
git add --all
#1560186353
javacc parser/langX+++.jj 
#1560186359
javac parser/langX.java 
#1560186476
javacc parser/langX+++.jj 
#1560186477
javac parser/langX.java 
#1560186924
ping www.ufsc.br
#1560188799
javacc parser/langX+++.jj 
#1560188800
javac parser/langX.java 
#1560188844
git status
#1560188852
git add --all
#1560188863
git commit -m "refactor"
#1560188870
git push origin master 
#1560188942
cd parser/
#1560188943
ll
#1560188945
rm -r 'langX$LookaheadSuccess.class' 'langX$JJCalls.class'
#1560188946
ll
#1560188948
cd ..
#1560188953
javacc parser/langX+++.jj 
#1560188959
javac parser/langX.java 
#1560189234
javacc parser/langX+++.jj 
#1560189235
javac parser/langX.java 
#1560189307
javacc parser/langX+++.jj 
#1560189309
javac parser/langX.java 
#1560189397
javacc parser/langX+++.jj 
#1560189399
javac parser/langX.java 
#1560189488
javacc parser/langX+++.jj 
#1560189490
javac parser/langX.java 
#1560189547
javacc parser/langX+++.jj 
#1560189549
javac parser/langX.java 
#1560189584
javacc parser/langX+++.jj 
#1560189586
javac parser/langX.java 
#1560189672
javacc parser/langX+++.jj 
#1560189673
javac parser/langX.java 
#1560189708
javacc parser/langX+++.jj 
#1560189709
javac parser/langX.java 
#1560189831
javacc parser/langX+++.jj 
#1560189832
javac parser/langX.java 
#1560189854
javacc parser/langX+++.jj 
#1560189855
javac parser/langX.java 
#1560189874
javacc parser/langX+++.jj 
#1560189875
javac parser/langX.java 
#1560189928
javacc parser/langX+++.jj 
#1560189929
javac parser/langX.java 
#1560189942
javacc parser/langX+++.jj 
#1560189943
javac parser/langX.java 
#1560189960
javacc parser/langX+++.jj 
#1560189961
javac parser/langX.java 
#1560190084
javacc parser/langX+++.jj 
#1560190085
javac parser/langX.java 
#1560190122
javacc parser/langX+++.jj 
#1560190124
javac parser/langX.java 
#1560190165
javacc parser/langX+++.jj 
#1560190166
javac parser/langX.java 
#1560190197
javacc parser/langX+++.jj 
#1560190198
javac parser/langX.java 
#1560190205
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560190241
java parser.langX testes_e_logs/teste_com_erro_classbody.x 
#1560190249
git add --all
#1560190273
git commit -m "refactor: compiled code"
#1560190277
git push origin master 
#1560209322
cd projetos/
#1560209322
ll
#1560209333
cd compiladores/
#1560209334
ll
#1560209352
idea . &
#1560209369
cd trabalho_parte_02-analisador_sintatico/
#1560209370
ll
#1560209374
cd parser/
#1560209375
ll
#1560209464
cd  ..
#1560209633
javacc parser/langX+++.jj 
#1560209640
javac parser/langX.java 
#1560209651
java parser.langX testes_e_logs/teste_com_erro_classbody.x 
#1560209683
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1560210491
java parser.langX testes_e_logs/teste_com_erro_classbody.x 
#1560210705
ll
#1560210749
lll
#1560210751
ll
#1560210797
java parser.langX testes_e_logs/teste_com_erro_classbody.x > log_erro.txt
#1560210810
cat log_erro.txt 
#1560210827
java parser.langX testes_e_logs/teste_com_erro_classbody.x > log_sem_erro.txt
#1560210829
ll
#1560210850
java parser.langX testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1560210859
cat log_sem_erro.txt 
#1560210871
sudo java parser.langX testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1560210875
ll
#1560210892
rm log_sem_erro.txt 
#1560210900
java parser.langX testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1560210902
ll
#1560210909
cat log_sem_erro.txt 
#1560210916
cat log_erro.txt 
#1560210929
mv log_* testes_e_logs/
#1560210932
ll
#1560210948
cd testes_e_logs/
#1560210949
ll
#1560212186
cd ..
#1560212187
ll
#1560212194
git status
#1560212198
git add --all
#1560212254
git commit -m "feat create logs files"
#1560212257
git status
#1560212261
git push origin master 
#1560212272
ll
#1560231285
cd projetos/
#1560231285
ll
#1560231369
cd projetos/
#1560231369
ll
#1560231390
cd etl-metrics-luigi/
#1560231390
ll
#1560231396
cd ..
#1560231845
cd analysing/
#1560231846
ll
#1560231854
git clone https://github.com/ronanknob/datapirates_challenge.git
#1560257229
cd ..
#1560257230
ll
#1560257233
cd devops/
#1560257234
ll
#1560257236
git status
#1560257240
git add --all
#1560257248
git commit -m "update"
#1560257253
git push origin master 
#1560257264
git pull origin master 
#1560257276
git push origin master 
#1560257411
cd ..
#1560257412
ll
#1560257414
cd compiladores/
#1560257414
ll
#1560257418
code .
#1560260811
git staus
#1560260813
git status
#1560260821
git add --all
#1560260872
git commit -m "style: update report"
#1560260877
git push origin master 
#1560260907
code .
#1560261125
git add --all
#1560261139
git commit -m "style: syntax highlight"
#1560261144
git push origin master 
#1560261808
cd ..
#1560261815
pip3 freeze
#1560261939
cd etl-metrics-luigi/
#1560261940
ll
#1560261961
python3 -m venv venv_luigi
#1560261964
ll
#1560261971
source venv_luigi/bin/activate
#1560261973
ll
#1560261987
pip3 freeze
#1560262002
pip3 install MySQL-python
#1560262012
pip3 freeze
#1560262030
pip install MySQL-python
#1560262042
apt-get install python-dev libmysqlclient-dev
#1560262047
sudo apt-get install python-dev libmysqlclient-dev
#1560262069
pip3 install MySQL-python
#1560262296
pip3 install mysql-connector-python
#1560262690
pip3 install luigi
#1560262703
pip freeze
#1560263504
sudo apt install mysql-server
#1560263557
sudo mysql_secure_installation
#1560263666
sudo mysql
#1560263756
mysql -u root -p
#1560263840
systemctl status mysql.service 
#1560269715
cd ..
#1560269715
ll
#1560269719
cd devops/'
#1560269723
cd devops/
#1560269723
ll
#1560269725
code .
#1560270543
luigid
#1560270548
luigid
#1560270564
cd ..
#1560270568
cd etl-metrics-luigi/
#1560270568
ll
#1560270576
source venv_luigi/bin/activate
#1560284143
ll
#1560284151
cd
#1560284153
cd Do
#1560284154
ll
#1560284159
cd Downloads/
#1560284160
ll
#1560284189
sudo chmod 777 mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560284197
ll
#1560284255
./mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb 
#1560284262
ll
#1560284728
./mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb 
#1560284739
bash mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb 
#1560284752
bash 'mysql-workbench-community_8.0.16-1ubuntu18.04_amd64 (1).deb'
#1560284822
sudo apt install mysql-workbench-community
#1560284835
sudo apt update 
#1560284847
sudo apt install mysql-workbench-community
#1560284865
sudo dpkg -i mysql-apt-config_0.5.3-1_all.deb
#1560284885
sudo dpkg -i mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb 
#1560285131
mysql
#1560285141
mysql -u root -p
#1560285180
ps | aux mysql
#1560285188
ps aux | grep mysql
#1560285522
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560285544
cd
#1560285551
code .
#1560285637
source ~/.bashrc
#1560285641
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560285659
source ~/.bashrc
#1560285664
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560285724
source ~/.bashrc
#1560285728
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560285736
source ~/.bashrc
#1560285739
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560288292
source ~/.bashrc
#1560288411
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560290120
mysql -u root -p
#1560270580
luigid
#1560303059
cd projetos/
#1560303060
ll
#1560303062
cd etl-metrics-luigi/
#1560303062
ll
#1560303073
source venv_luigi/bin/activate
#1560303074
ll
#1560303342
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560303357
systemctl status mysql
#1560303811
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560304549
ll
#1560304551
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560305165
sudo apt remove mysql-workbench-community
#1560305181
ll
#1560305192
sudo apt autoremove 
#1560305198
sudo apt autoclean 
#1560305233
ll
#1560305260
cd
#1560305263
cd Downloads/
#1560305263
ll
#1560305278
./ mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560305315
sudo dpkg --install mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560305560
mysql --version
#1560305585
sudo apt remove mysql*
#1560305611
sudo apt remove mysql-client-*
#1560305617
ll
#1560305619
sudo apt remove mysql-client-*
#1560305692
mysql --version
#1560305698
sudo apt remove mysql*
#1560305736
sudo apt remove mysql-client-5.7 mysql-client-core-5.7 mysql-common mysql-server mysql-server-5.7 mysql-server-core-5.7 mysql-workbench-community
#1560305753
apt --fix-broken install
#1560305757
sudo apt --fix-broken install
#1560305772
sudo apt remove mysql-client-5.7 mysql-client-core-5.7 mysql-common mysql-server mysql-server-5.7 mysql-server-core-5.7 mysql-workbench-community
#1560305777
ll
#1560305793
sudo apt remove mysql-client-5.7
#1560305807
sudo apt remove mysql-client-core-5.7
#1560305818
sudo apt remove mysql-common
#1560305852
sudo apt remove mysql-server-core-5.7
#1560305903
ll
#1560310115
kk
#1560310284
rm -r 'bruno_e_caio (1).zip'
#1560310303
rm -r 'bruno_e_caio (2).zip' bruno_e_caio.zip calcularINE5680.xlsx 'CapV-P-Exemplos(2).pdf'
#1560310357
rm -r drive-download-20190608T165450Z-001.zip DW_enunciado_trabalho_2_2018-2.pdf DW_trabalho_final-20190608T165038Z-001.zip Ex_Files_Git_Intermediate_Techniques.zip ICICSE.pdf iTerm2-3_2_9.zip 'Linguagens - Jerusa.pdf' Modulo07-Cria-o-de-Alertas.pptx mysql-apt-config_0.8.13-1_all.deb 'mysql-workbench-community_8.0.16-1ubuntu18.04_amd64 (1).deb'
#1560310388
rm -r newplot.pngmysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb nojhan-colout-v0.6.1-3-gb62b575.tar.gz openssl20191.zip pandas_with_python.pdf plano-ensino-INE5680-07238-20191.pdf platform-confclient-scala-master.zip platform-dumps-master.zip
#1560310398
ll
#1560310416
sudo dpkg --install mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560310453
sudo apt install libglibmm-2.4-1v5
#1560310466
sudo apt --fix-broken install
#1560310493
mysql --version
#1560310551
mysql
#1560310579
sudo apt-get update
#1560310593
systemctl start mysql
#1560310600
sudo systemctl start mysql
#1560310665
ll
#1560310727
rm -r '1032264567_Gramáticas Recursivas e Fatoração a esquerda.doc' annotations_eduardo.docx  'Compilador parte 2.rar' cv-237392.pdf 'mysql-shell_8.0.16-1ubuntu19.04_amd64
#1560310743
rm -r '1032264567_Gramáticas Recursivas e Fatoração a esquerda.doc' annotations_eduardo.docx  'Compilador parte 2.rar' cv-237392.pdf 'mysql-shell_8.0.16-1ubuntu19.04_amd64 (1).deb' 
#1560310819
rm -r newplot.png SImplificacaoDeGramaticas.pdf splitvt-1.6.6.tar.gz 'Tarefa Prática 2 OpenSSL e Apache - Filipe Linemburger.pdf' 'Trabalho II - Analisador Sintático - Parte 1.pdf' Untitled.html widget_state.json 
#1560310821
ll
#1560310858
rm terminator-1.90.tar.gz tmux-2.9.tar.gz 'Trabalho 1 (Analisador Léxico)-20190607T061003Z-001.zip' trabalho_final_DATA_WAREHOUSE.docx iTerm.app/
#1560310861
ll
#1560310877
rm mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb mysql-shell_8.0.16-1ubuntu19.04_amd64.deb t2_Compila.zip
#1560310885
rmdir tmux-2.9/
#1560310896
rm -r tmux-2.9/
#1560310901
ll
#1560310928
sudo dpkg --install mysql-apt-config_0.8.13-1_all.deb
#1560310966
sudo apt update 
#1560310997
sudo dpkg --install mysql-apt-config_0.8.13-1_all.deb
#1560311050
sudo apt update
#1560311060
sudo apt-get install mysql-server
#1560311336
mysql
#1560311344
mysql -u user -p
#1560311358
sudo systemctl status mysql
#1560311364
sudo systemctl enable mysql
#1560311374
sudo apt-get update
#1560311386
sudo apt-get install mysql-workbench-community libmysqlclient18
#1560311400
sudo apt-get install mysql-workbench-community
#1560311421
sudo mysql -u root -p
#1560311439
sudo apt-get install mysql-server
#1560311449
sudo apt autoremove 
#1560311468
sudo dpkg -i mysql-apt-config_0.8.10-1_all.deb 
#1560311484
wget -c https://dev.mysql.com/get/mysql-apt-config_0.8.10-1_all.deb 
#1560311490
sudo dpkg -i mysql-apt-config_0.8.10-1_all.deb 
#1560311614
sudo apt update
#1560311625
sudo apt-get install mysql-server
#1560311631
mysql
#1560311801
sudo mysql –u root –p
#1560311825
mysql –u root –p
#1560311827
mysql –u root
#1560311829
mysql
#1560311836
mysql -u root
#1560311840
mysql -u root -p
#1560311881
sudo apt install $ sudo apt-get install mysql-workbench-community libmysqlclient18
#1560311883
$ sudo apt-get install mysql-workbench-community libmysqlclient18
#1560311890
$ sudo apt-get install mysql-workbench-community
#1560311894
sudo apt-get install mysql-workbench-community
#1560311908
sudo apt-get install libmysqlclient18
#1560311920
sudo apt-get install libzip4
#1560311937
sudo apt-get install libzip5
#1560311945
sudo apt-get install mysql-workbench-community
#1560312008
ll
#1560312015
./mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560312027
sudo chmod 777 mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560312029
ll
#1560312034
./mysql-workbench-community_8.0.16-1ubuntu18.04_amd64.deb
#1560312102
wget http://archive.ubuntu.com/ubuntu/pool/universe/libz/libzip/libzip4_1.1.2-1.1_amd64.deb
#1560312105
ll
#1560312130
sudo dpkg --install libzip4_1.1.2-1.1_amd64.deb
#1560312133
ll
#1560312143
sudo apt-get install mysql-workbench-community
#1560312634
ll
#1560312642
wget -h
#1560312648
wget -r http://archive.ubuntu.com/ubuntu/pool/universe/libz/libzip/libzip4_1.1.2-1.1_amd64.deb
#1560312705
wget --verbose http://archive.ubuntu.com/ubuntu/pool/universe/libz/libzip/libzip4_1.1.2-1.1_amd64.deb
#1560312885
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560314155
mysql
#1560314166
mysql -u root -p
#1560314218
/etc/init.d/mysql restart
#1560314241
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560314820
systemctl status mysql
#1560314871
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560315009
mysql -u root -p
#1560315091
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560315740
ll
#1560315822
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560316483
mysql -h localhost -u root -p
#1560316504
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560317148
python --version
#1560317157
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560318255
< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-32};
#1560318267
< /dev/urandom tr
#1560318271
/dev/urandom tr
#1560318277
< /dev/urandom tr -h
#1560318424
ll
#1560318918
python3 /home/campos/projetos/database-scripts/mySQL/mysql_helper.py
#1560320005
cd
#1560320007
cd projetos/
#1560320008
ll
#1560320015
cd database-scripts/
#1560320016
ll
#1560320020
git status
#1560320030
git add --all
#1560320099
git commit -m "feat: mysql mysql_create_user_db_tables"
#1560320104
git push origin master 
#1560321176
< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-10};
#1560321958
cd ..
#1560321959
ll
#1560321961
cd analysing/
#1560321961
ll
#1560321971
wget https://github.com/chaordic/platform-workflow-manager.git
#1560321983
curl -get https://github.com/chaordic/platform-workflow-manager.git
#1560323187
cd ..
#1560323191
cd etl-metrics-luigi/
#1560323191
ll
#1560323211
cd ETL_metrics/
#1560323212
ll
#1560323220
cd ..
#1560323238
mv ETL_metrics/ etl_metrics/
#1560323239
ll
#1560323241
cd etl_metrics/
#1560323242
ll
#1560323255
python3 mysql_helper.py 
#1560323402
python mysql_initial_config.py 
#1560323656
python3 mysql_helper.py 
#1560323661
python mysql_initial_config.py 
#1560324996
luigid
#1560325009
pip freeze | grep luigi
#1560325016
pip freeze
#1560325032
pip2 freeze | grep luigi
#1560325036
pip3 freeze | grep luigi
#1560325058
../venv_luigi/bin/pip3 freeze | grep luigi
#1560325173
sudo apt install apt install libssl-dev
#1560325187
sudo luigid --background --logdir ./logs --port=8082
#1560325197
python setup.py install
#1560325205
cd ..
#1560325206
python setup.py install
#1560325725
pip list
#1560325738
whivh python
#1560325742
which python
#1560325748
cd ..
#1560325758
deactivate
#1560325764
cd luigi-metrics/
#1560325765
ll
#1560325771
source venv_luigi/bin/activate
#1560325772
ll
#1560325780
pip3 freeze
#1560325787
which python
#1560325796
cd venv_luigi/
#1560325798
ll
#1560325800
code .
#1560325820
deactivate
#1560326112
cd ..
#1560326113
ll
#1560326130
luigid
#1560326132
ll
#1560326135
cd etl_metrics/
#1560326135
ll
#1560326183
python setup.py install
#1560326218
sudo chmod 777 setup.py 
#1560326220
ll
#1560326234
python3 setup.py install
#1560326269
sudo chown root.root setup.py 
#1560326270
ll
#1560326286
sudo python3 setup.py install
#1560326345
pip3 freeze | grep l
#1560354808
ll
#1560354822
python3 -m venv venv_luigi
#1560354830
source venv_luigi/bin/activate
#1560354831
ll
#1560354836
which python
#1560354846
pip3 install luigi
#1560354866
ll
#1560354869
pip list
#1560354883
python3 setup.py install
#1560354903
sudo chown campos.campos setup.py 
#1560354907
ll
#1560354914
python3 setup.py install
#1560355015
sudo rm -r luigi_metrics_etl.egg-info/
#1560355018
python3 setup.py install
#1560355045
ll
#1560355054
rm -r luigi_metrics_etl.egg-info/
#1560355056
python3 setup.py install
#1560355178
luigid
#1560355355
sudo luigid --background --logdir ./logs --port=8082
#1560355361
luigid --background --logdir ./logs --port=8082
#1560355371
systemctl status luigi
#1560355373
systemctl status luigid
#1560356561
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --forc
#1560356732
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560356756
luigi --module luigi_metrics_etl RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560356766
pip freeze
#1560356784
luigi --module luigi-metrics-etl RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560356807
luigid --background --logdir ./logs --port=8082
#1560356822
python3 setup.py install
#1560356883
cd ..
#1560356885
python3 setup.py install
#1560357488
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 luigi_warehouse/postgres_to_redshift.py Run --params here --workers 50
#1560357562
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 etl_metrics/bigdataETL/bigdataETLWorkflow.py Run --params here --workers 1
#1560357604
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 etl_metrics/bigdataETL/bigdataETLWorkflow.py Run --env dev --workers 1
#1560357626
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 etl_metrics/bigdataETL/bigdataETLWorkflow.py Run --env dev --workers 3 --dry-run --force
#1560358727
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 etl_metrics/examples/bigdataETLWorkflow.py Run --env dev --workers 3 --dry-run --force
#1560361052
python3 etl_metrics/examples/bigdataETLWorkflow.py Run --env dev --workers 3 --dry-run --force
#1560361807
LUIGI_CONFIG_PATH=/path/to/your/luigi.cfg && python3 etl_metrics/examples/bigdataETLWorkflow.py Run --env dev --workers 3 --dry-run --force
#1560303895
ping www.google.com
#1560369459
cd projetos/
#1560369460
ll
#1560369484
cd luigi-metrics/
#1560369484
çç
#1560369486
ll
#1560370456
source venv_luigi/bin/activate
#1560370457
ll
#1560370461
which python
#1560370486
rm -r venv_luigi/
#1560370502
deactivate
#1560370526
virtualenv -p python3 venv_luigi
#1560370535
source venv_luigi/bin/activate
#1560370539
which python
#1560370542
ll
#1560370554
pip3 install luigi
#1560370572
python3 setup.py install
#1560370632
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560370668
pip freeze
#1560370688
ll
#1560370805
luigi --module etl_metrics RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560370828
luigi --module luigi_metrics RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560371426
python3 setup.py install
#1560371435
luigi --module luigi_metrics RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560371445
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560371504
luigi --module etl_metrics RunBigdataETLWorkflow --env dev --workers 3 --dry-run --forc
#1560371507
ll
#1560371515
luigi --module etl_metrics RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560371659
python3 setup.py  install
#1560371666
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560371698
sudo luigid --background --logdir ./logs --port=8082
#1560371711
luigid --background --logdir ./logs --port=8082
#1560371716
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560372149
python3 luigi_warehouse/postgres_to_redshift.py Run --workers 1
#1560372157
python setup.py install
#1560372160
python3 luigi_warehouse/postgres_to_redshift.py Run --workers 1
#1560372180
python3 etl_metrics/postgres_to_redshift.py Run --workers 1
#1560372410
cd
#1560372415
cd projetos/
#1560372416
ll
#1560372427
cd analysing/platform-workflow-manager-feat-luigi_console-metrics/
#1560372428
ll
#1560372468
python3 setup.py install
#1560372572
sudo `apt install libssl-dev`
#1560372581
sudo apt install libssl-dev
#1560372596
ll
#1560372599
python3 setup.py install
#1560372665
pip list
#1560372680
luigid --background --logdir ./logs --port=8082
#1560372688
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560373070
cd ..
#1560373074
cd luigi-metrics/
#1560373076
ll 
#1560373081
git clone https://github.com/groupon/luigi-warehouse.git
#1560373111
cd luigi-warehouse/
#1560373112
ll
#1560373122
luigid --background --logdir ./logs --port=8082
#1560373209
LUIGI_CONFIG_PATH=/home/campos/projetos/luigi-metrics/luigi-warehouse/luigi.cfg-example && python3 postgres_to_redshift.py Run --workers 1
#1560373248
LUIGI_CONFIG_PATH=/home/campos/projetos/luigi-metrics/luigi-warehouse/luigi.cfg-example && python3 /home/campos/projetos/luigi-metrics/luigi-warehouse/luigi_warehouse/postgres_to_redshift.py Run --workers 1
#1560373293
python setup.py install
#1560373320
pip3 install -r requirements.txt 
#1560373405
pip list
#1560373469
pip3 install -r requirements.txt 
#1560373543
LUIGI_CONFIG_PATH=/home/campos/projetos/luigi-metrics/luigi-warehouse/luigi.cfg-example && python3 /home/campos/projetos/luigi-metrics/luigi-warehouse/luigi_warehouse/postgres_to_redshift.py Run --workers 1
#1560374814
ll
#1560374821
cd projetos/
#1560374822
ll
#1560374846
cd l
#1560374851
cd luigi-metrics/
#1560374852
ll
#1560374855
cd ..
#1560374859
cd analysing/
#1560374859
ll
#1560374863
cd platform-workflow-manager-feat-luigi_console-metrics/
#1560374864
kk
#1560374867
ll
#1560374886
ll venv_python2/
#1560374907
virtualenv -p python3 venv_luigi
#1560374971
cd venv_luigi/
#1560374972
ll
#1560374974
cd ..
#1560374981
source venv_luigi/
#1560374987
source venv_luigi/bin/activate
#1560374988
ll
#1560374993
rm -r venv_python2/
#1560375192
sudo apt install libssl-dev
#1560375221
luigid --background --logdir ./logs --port=8082
#1560375231
pip3 install luigi
#1560375245
python3 setup.py install
#1560375309
pip3 install sasl==0.1.3
#1560375418
pip3 install sasl
#1560375631
python3 setup.py install
#1560375688
sudo apt-get install libsasl2-dev
#1560375697
python3 setup.py install
#1560375752
pip freeze
#1560375772
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 3 --dry-run --force
#1560375794
luigid --background --logdir ./logs --port=8082
#1560375803
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 1 --dry-run --force
#1560375845
which python
#1560375853
pip3 freeze
#1560375899
ll
#1560375914
pip3 install -r requirements.txt 
#1560376011
which python
#1560376019
python3 setup.py install
#1560376026
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 1 --dry-run --force
#1560376072
l
#1560376079
ls -lt
#1560376312
pip3 freeze
#1560376498
venv_luigi/bin/python3.7 setup.py install
#1560376528
venv_luigi/bin/pip3 install -r requirements.txt 
#1560376555
vim requirements.txt 
#1560376815
venv_luigi/bin/pip3 install -r requirements.txt 
#1560376826
pip3 freeze
#1560376831
luigi --module bigdataETLWorkflow RunBigdataETLWorkflow --env dev --workers 1 --dry-run --force
#1560376858
cd ..
#1560376866
lui
#1560376871
cd luigi-metrics/
#1560376872
ll
#1560376890
rm -r build/ dist/ luigi_metrics.egg-info/
#1560376892
ll
#1560376902
cat requirements.txt 
#1560376909
cd etl_metrics/
#1560376909
ll
#1560376913
cd ..
#1560376919
çç
#1560376920
ll
#1560376925
cd venv_luigi/
#1560376925
ll
#1560376927
cd ..
#1560376931
cd etl_metrics/
#1560376931
ll
#1560376940
rm -r venv_luigi/
#1560376942
l
#1560376946
cd metrics/
#1560376947
ll
#1560376951
cd ..
#1560376967
ll
#1560376973
python3 setup.py install
#1560377011
ll
#1560377028
luigid --background --logdir ./logs --port=8082
#1560377030
ll
#1560377056
luigi --module etl_metrics/ --env dev --workers 1 --dry-run --force
#1560377065
luigi --module etl_metrics --env dev --workers 1 --dry-run --force
#1560377083
luigi --help
#1560377119
luigi Run --workers 1
#1560377129
luigi Run etl_metrics/--workers 1
#1560377132
luigi Run etl_metrics/ --workers 1
#1560377160
python3 etl_metrics/postgres_to_redshift.py Run --workers 50
#1560377364
python3 etl_metrics/postgres_to_redshift.py.py Run --workers 50
#1560377651
luigi --module etl_metrics  etl_metrics--env dev --workers 1 --dry-run --force
#1560377932
cd .
#1560377940
cd ..
#1560377943
cd compiladores/
#1560377943
l
#1560377952
idea .7 &
#1560378014
javacc parser/langX+++.jj 
#1560378022
ll
#1560378025
cd trabalho_parte_02-analisador_sintatico/
#1560378026
ll
#1560378029
javacc parser/langX+++.jj 
#1560378035
javac parser/langX.java 
#1560378053
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1560381191
java parser.langX testes_e_logs/teste_com_erro_classbody.x
#1560381209
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1560433133
cd projetos/
#1560433134
ll
#1560433142
cd challenges/
#1560433143
ll
#1560433219
code .
#1560433267
cd
#1560433269
code .
#1560434725
python --version
#1560434735
python3 --version
#1560434750
ll
#1560434929
ll
#1560434952
git clone https://github.com/brunocampos01/challenge-keyrus.git
#1560434957
git status
#1560434974
cd challenge-keyrus/
#1560434974
ll
#1560435021
mv /home/campos/Downloads/teste_tecnico.zip .
#1560435023
ll
#1560435045
mv /home/campos/Downloads/'Processo Seletivo Ciência de Dados Keyrus.pdf' .
#1560435047
ll
#1560435061
cd ..
#1560435062
ll
#1560435085
code .
#1560435201
git status
#1560435213
cat LICENSE 
#1560435222
cat README.md 
#1560435858
ll
#1560435867
cd revelo/
#1560435867
ll
#1560435987
git init
#1560436007
git remote add origin drwxrwxr-x 2 campos campos 4,0K jun 13 10:45 images/
#1560436021
git remote add origin git@github.com:brunocampos01/revelo-questions.git
#1560436029
git remote -V
#1560436034
git remote -v
#1560436043
git pull origin ma
#1560436047
[
#1560436056
git pull origin master
#1560436126
git add --all
#1560436137
git commit -m "initial commit"
#1560436140
git push origin master 
#1560436175
cd ..
#1560436178
code .
#1560436353
git status
#1560436356
git add --all
#1560436391
ll
#1560436399
code .
#1560436466
git status
#1560436474
git add --all
#1560436479
git status
#1560436496
git reset --soft HEAD~1
#1560436500
git status
#1560436509
git reset --soft HEAD~1
#1560436511
git status
#1560436528
git reset HEAD revelo
#1560436530
ll
#1560436535
git status
#1560436552
git add  .gitignore LICENSE README.md
#1560436568
git commit -m "feat: new challege"
#1560436574
git push origin master 
#1560436598
git remote -v
#1560436635
git remote rename origin git@github.com:brunocampos01/challenges.git
#1560436651
git remote -v
#1560436654
git remote -h
#1560436678
git remote rename https://github.com/brunocampos01/challenges git@github.com:brunocampos01/challenges.git
#1560436698
git remote rename https://github.com/brunocampos01/challenges.git git@github.com:brunocampos01/challenges.git
#1560436702
git remote -h
#1560436723
git remote remove https://github.com/brunocampos01/challenges
#1560436735
git remote -v
#1560436790
git remote add origin git@github.com:brunocampos01/challenges.git
#1560436803
git remote remove origin
#1560436810
git remote -v
#1560436815
git remote add origin git@github.com:brunocampos01/challenges.git
#1560436817
git status
#1560436830
git add --all
#1560436837
git status
#1560436849
git reset HEAD revelo
#1560436852
code .
#1560436870
git status
#1560436876
git add .gitignore
#1560437552
ll
#1560437567
git commit -m "feat: add chagellenge"
#1560437570
git push origin master 
#1560437577
git pull
#1560437584
git pull origin master 
#1560437593
code .
#1560437639
git status
#1560437644
git add README.md
#1560437653
git commit -m "resolve conflits"
#1560437657
git push origin master 
#1560437917
ll
#1560437919
cd revelo/
#1560437920
ll
#1560437928
cd ..
#1560437929
kk
#1560437930
ll
#1560437934
cd challenge-keyrus/
#1560437941
ll
#1560437954
unzip teste_tecnico.zip -h
#1560437956
unzip teste_tecnico.zip
#1560437958
ll
#1560438014
mv 'Processo Seletivo Ciência de Dados Keyrus.pdf' processo_seletivo_ciencia_de_dados_keyrus.pdf
#1560438016
ll
#1560438024
cat callcenter_descricao.txt 
#1560438045
cat callcenter_marketing.csv 
#1560438055
cat callcenter_marketing.csv | jq
#1560438058
cat callcenter_marketing.csv | csv
#1560438103
cd ..
#1560438281
sudo apt install csvgrep
#1560438289
csvgrep
#1560438305
sudo apt install csvkit
#1560438351
de devops/
#1560438352
ll
#1560438355
de devops/
#1560438360
cd devops/
#1560438360
ll
#1560438372
code .
#1560438780
cat callcenter_marketing.csv | csvgrep
#1560438794
csvgrep callcenter_marketing.csv
#1560438813
csvgrep -d ; callcenter_marketing.csv
#1560438839
cat callcenter_marketing.csv | csvjson
#1560438857
cat callcenter_marketing.csv | csvjson | grep jq
#1560438988
cat callcenter_marketing.csv
#1560439004
csvlook callcenter_marketing.csv
#1560440070
ll
#1560440088
mkdir data
#1560440098
mv callcenter_* data/
#1560440099
ll
#1560440119
cd ..
#1560440120
ll
#1560440125
cd learning-linux/
#1560440126
ll
#1560440129
cd ..
#1560440129
ll
#1560440137
cd artificial_inteligence/
#1560440138
ll
#1560440140
cd data-science/
#1560440140
ll
#1560440188
cd ..
#1560440193
ll
#1560440199
code .
#1560440219
code .
#1560440487
source /home/campos/projetos/venv_global/bin/activate
#1560440487
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pep8
#1560440489
/home/campos/projetos/venv_global/bin/python3 -m pip install -U flake8
#1560440495
/home/campos/projetos/venv_global/bin/python3 -m pip install -U prospector
#1560440514
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pytest
#1560440864
ll
#1560440881
rm -r XDG_CACHE_HOME/
#1560440921
mv teste_tecnico.zip reports/
#1560440932
mv processo_seletivo_ciencia_de_dados_keyrus.pdf reports/
#1560440934
ll
#1560440957
code .
#1560441088
ll
#1560441098
rm -r XDG_CACHE_HOME/
#1560441151
virtualenv -p python3 venv_keyrus
#1560441165
ll
#1560441204
source venv_keyrus/bin/activate
#1560441206
ll
#1560441213
cd ..
#1560441214
code .
#1560441381
source ~/.bashrc
#1560441508
which python
#1560441512
whoami
#1560441514
users
#1560441529
python --version
#1560441531
ll
#1560441546
pip3 install jupyter
#1560441579
numpy                     pandas \
#1560441586
pip3 install numpy                     pandas                     matplotlib
#1560441604
pip freeze
#1560441619
pip3 freeze
#1560441634
pip3 freeze
#1560441661
ll
#1560441664
cd projetos/
#1560441665
ll
#1560441668
cd challenges/
#1560441669
ll
#1560441825
charm .
#1560441991
code .
#1560443971
cd ..
#1560443972
code .
#1560444037
tree
#1560444042
sudo apt install tree
#1560444052
tree
#1560444233
tree -h
#1560444238
tree --help
#1560444310
tree --ignore-case venv_keyrus
#1560444317
tree --ignore-case venv_keyrus/
#1560444392
tree --noreport venv*
#1560444406
cd challenges/challenge-keyrus/
#1560444406
çç
#1560444408
ll
#1560444412
tree --noreport venv*
#1560444424
tree --noreport venv_keyrus/
#1560444427
tree --noreport venv_keyrus/*
#1560444434
tree --help
#1560444452
ll
#1560444472
tree -o struture
#1560444475
ll
#1560444479
cat struture 
#1560444559
tree --help
#1560444582
tree -d
#1560444585
ll
#1560444587
tree --help
#1560444631
tree -C
#1560444639
tree --help
#1560444671
tree -J
#1560444684
tree --help
#1560444709
tree -x
#1560444714
tree --help
#1560444793
ll
#1560444806
tree -p config_environment.txt 
#1560444815
tree -p references/
#1560444893
tree -I venv_keyrus/
#1560444901
tree -I venv_keyrus/*
#1560444915
tree -p references/
#1560444920
tree -p venv_keyrus/
#1560444926
tree --help
#1560444969
tree -p notebooks/
#1560444976
tree -I notebooks/
#1560445107
tree -p notebooks/
#1560445120
tree -p notebooks/ src/
#1560445176
ll
#1560445186
rm struture
#1560445191
rm config_environment.txt
#1560445854
tree -I 'test*|docs|bin|lib'
#1560445878
tree -I venv_keyrus/*
#1560445885
tree -I 'venv_keyrus/*'
#1560445900
tree -I 'bin'
#1560445910
tree -I 'bin|share'
#1560445920
tree -I 'bin|share|lib'
#1560445937
tree -I 'bin|share|lib|include'
#1560445943
tree -I 'bin|share|lib|include|etc'
#1560445965
tree -I bin|share|lib|include|etc
#1560445983
tree -i 'bin|share|lib|include|etc'
#1560445987
tree --help
#1560448064
code .
#1560448423
echo -h
#1560448427
echo --help
#1560448433
man echo
#1560451705
htop
#1560451713
sudo apt install htop
#1560452127
charm .
#1560452157
pycha
#1560452162
pycha .
#1560452189
cd /usr/local/bin
#1560452190
ll
#1560452276
pyjet
#1560452284
cd
#1560455506
cd projetos/
#1560455514
cd artificial_inteligence/data-science/
#1560455530
ll
#1560455552
virtualenv -p python3 venv_data_science
#1560455562
source venv_data_science/bin/activate
#1560455564
ll
#1560455567
git status
#1560455588
pip3 freeze
#1560455593
pip3 list
#1560455620
pip3 install jupyter
#1560455633
pip3 install numpy
#1560455640
pip3 install pandas
#1560455652
pip3 install sklearn
#1560455660
ll
#1560455785
git branch
#1560455812
jupyter-notebook 
#1560451727
htop
#1560461350
ll
#1560461355
cd data/
#1560461356
ll
#1560441655
jupyter-notebook 
#1560461462
ll
#1560461464
git status
#1560480052
ll
#1560480055
cd projetos/
#1560480059
cd devops/
#1560480060
ll
#1560480098
git status
#1560480103
git pull origin master 
#1560480123
code .
#1560480170
git add --all
#1560480186
git commit -m "add: imgs logo"
#1560480191
git push origin master 
#1560480383
git pull origin master 
#1560480393
ll
#1560480457
git push origin master 
#1560480585
git add --all
#1560480597
git commit -m "refactor"
#1560480602
git push origin master 
#1560480630
code .
#1560481079
git add --all
#1560481082
git commit -m "refactor"
#1560481084
git push origin master 
#1560481145
ll
#1560481147
cd .git/
#1560481148
ll
#1560481154
cd ..
#1560481880
git add --all
#1560481883
git commit -m "refactor"
#1560481886
git push origin master 
#1560487508
git status
#1560487516
git add --all
#1560487521
git status
#1560487529
cd .git/
#1560487530
ll
#1560487544
cd objects/
#1560487545
ll
#1560487555
ls -t
#1560487559
ls -lt
#1560487570
cd 31/
#1560487570
ll
#1560487578
cat 5113642ddd9d5d7a9d8508f527e492b7de0371
#1560487581
ll
#1560487675
git commit -h
#1560487684
man git commit
#1560488062
git show
#1560487836
gitk --all
#1560489423
ll
#1560489433
pwd
#1560489439
ll
#1560489442
cd ..
#1560489443
ll
#1560489502
cd ..
#1560489506
ll
#1560489513
cd data-warehouse/
#1560489514
ll
#1560489524
cd .git/
#1560489524
ll
#1560489530
cd objects/
#1560489531
ll
#1560489639
cd ..
#1560489642
ll
#1560489644
git status
#1560489649
git add --all
#1560489677
git commit -m "refator: change describe commits"
#1560489682
git push origin master 
#1560489747
code .
#1560490319
git add --all
#1560490322
git commit -m "refator: change describe commits"
#1560490324
git push origin master 
#1560491762
git add --all
#1560491763
git push origin master 
#1560491769
git commit -m "refator: change describe commits"
#1560491773
git push origin master 
#1560492890
code .
#1560493703
git add --all
#1560493706
git commit -m "refator: change describe commits"
#1560493708
git push origin master 
#1560493816
cd projetos/
#1560493817
ll
#1560493831
cd challenges/challenge-keyrus/
#1560493833
ll
#1560493851
source venv_keyrus/bin/activate
#1560493854
cd venv_keyrus/
#1560493855
ll
#1560493857
cd ..
#1560506819
ll
#1560506825
git status
#1560506831
git add --all
#1560506838
git commit -m "amend"
#1560506842
git push origin master 
#1560506896
git remote add origin git@github.com:brunocampos01/challenge-keyrus.git
#1560506913
git remote remove origin
#1560506915
git remote add origin git@github.com:brunocampos01/challenge-keyrus.git
#1560506919
git remote -v
#1560506929
git push origin master 
#1560506999
git status
#1560493870
jupyter-notebook 
#1560528516
ll
#1560531847
cd projetos/
#1560531847
ll
#1560531902
cd challenges/
#1560531903
ll
#1560531907
cd challenge-keyrus/
#1560531909
ll
#1560531939
source venv_keyrus/bin/activate
#1560531940
ll
#1560531946
charm .
#1560532206
code .
#1560532269
cd ..
#1560532273
cd devops/
#1560532274
ll
#1560532276
code .
#1560550210
ll
#1560550212
ll
#1560550215
git status
#1560550220
git add --all
#1560550233
git commit -m "doc"
#1560550236
git push origin master 
#1560550450
code .
#1560561462
gitk --all
#1560561474
gitk --all
#1560561488
cd ..
#1560561491
cd analysing/
#1560561492
ll
#1560561496
cd platform-workflow-manager-feat-luigi_console-metrics/
#1560561499
gitk --all
#1560561511
cd ..
#1560561512
ll
#1560561516
cd pp-importhbasetomysql/
#1560561519
gitk --all
#1560600336
cd
#1560600343
cd projetos/
#1560600344
ll
#1560600413
cd artificial_inteligence/data-science/
#1560600414
ll
#1560600427
source venv_data_science/bin/activate
#1560629759
cd ..
#1560629761
ll
#1560629765
git status
#1560629768
cd ..
#1560629770
ll
#1560629779
cd becoming-a-expert-python/
#1560629780
ll
#1560629783
git status
#1560629818
git diffconfiguration_files/dynamic_loading/main.py
#1560629823
git diff configuration_files/dynamic_loading/main.py
#1560629835
git add --all
#1560629865
git commit -m "amend"
#1560629869
git push origin master 
#1560629880
git pull origin master 
#1560629892
git push origin master 
#1560629967
cd ..
#1560629979
ll
#1560629988
cd banco-de-dados/
#1560629990
ll
#1560629993
git status
#1560630042
git pull origin master 
#1560630051
git add --all
#1560630063
git commit -m "refactor: sorted"
#1560630069
git push origin master 
#1560630206
cd ..
#1560630207
ll
#1560630211
cd devops/
#1560630237
code .
#1560630750
git add --all
#1560630758
git pull origin master 
#1560630798
git commit -m "style: following markdown style"
#1560630803
git push origin master 
#1560631309
git add --all
#1560631313
git commit -m "style: following markdown style"
#1560631315
git push origin master 
#1560631434
code .
#1560631967
git add --all
#1560631970
git commit -m "style: following markdown style"
#1560631972
git push origin master 
#1560647172
cd ..
#1560647175
cd analysing/
#1560647175
ll
#1560673650
cd cd ..
#1560673653
cd  ..
#1560673660
cd challenges/challenge-keyrus/
#1560673661
ll
#1560673663
code .
#1560674878
cd ..
#1560674892
jupyter-notebook 
#1560723262
ll
#1560723264
cd ..
#1560723330
cd seguranca/
#1560723331
ll
#1560723351
mkdir trabalho_02_com_implementacao
#1560723432
cd trabalho_02_com_implementacao/
#1560723476
meninfo
#1560723480
meminfo
#1560723486
free -h
#1560723519
mv /home/campos/Downloads/wiressl4.zip .
#1560723520
ll
#1560723553
unzip wiressl4.zip 
#1560723554
ll
#1560723590
mv 'Criptografia e SeguranЗa de Redes-Cap17.pdf' criptografia_e_seguranca_de_redes_cap_17.pdf
#1560723591
ll
#1560723681
sudo apt update
#1560723696
sudo apt upgrade
#1560723771
code .
#1560723762
sudo apt install wireshark
#1560723852
sudo usermod -aG wireshark $(whoami)
#1560724118
cd ..
#1560724120
l
#1560724127
cd trabalho_01_com_implementacao/
#1560724129
ll
#1560724136
cd ..
#1560724891
code .
#1560725337
cd ..
#1560725339
cd devops/
#1560725340
ll
#1560725342
code .
#1560727814
cd ..
#1560727815
ll
#1560727829
cd artificial_inteligence/
#1560727829
ll
#1560727832
cd data-science/
#1560727833
ll
#1560727836
git status
#1560727844
git add --all
#1560727902
git commit -m "refactoring"
#1560727910
git push origin master 
#1560727919
git pull origin master 
#1560600436
jupyter-notebook 
#1560531962
jupyter-notebook 
#1560728139
cd ..
#1560728142
ll
#1560728146
cd banco-de-dados/
#1560728147
ll
#1560728151
code .
#1560727931
git push origin master 
#1560728717
ll
#1560728720
pwd
#1560728724
git status
#1560728731
git add --all
#1560728765
git commit -m "provas"
#1560728770
git push origin master 
#1560728779
git pull origin master 
#1560728789
git push origin master 
#1560734942
cd ..
#1560734950
seguranca/
#1560734951
ll
#1560734954
git status
#1560734965
git add --all
#1560735018
git commit -m "trabalho02: readme"
#1560735021
git push origin master 
#1560735028
git pull origin master 
#1560735204
cd
#1560735215
cd /opt/
#1560735216
ll
#1560735218
cd ..
#1560735232
sudo rm ClipGrab-3.8.2-x86_64.AppImage
#1560735253
sudo rm /opt/ClipGrab-3.8.2-x86_64.AppImage
#1560735255
ll
#1560735035
git push origin master 
#1560735410
grep wireshark
#1560736167
cd charm/
#1560736170
cd 
#1560736177
cd projetos/challenges/challenge-keyrus/
#1560736178
ll
#1560736180
git status
#1560736186
git add --all
#1560736196
git commit -m "intial commit"
#1560736200
git push origin master 
#1560736823
cd projetos/
#1560736824
cd seguranca/
#1560736825
ll
#1560736826
code .
#1560736993
dig https://github.com/brunocampos01
#1560737015
host https://github.com/brunocampos01
#1560737022
host https://github.com/
#1560737036
host https://github.com
#1560737042
host www.github.com
#1560739368
git status
#1560739373
git add --all
#1560739407
git commit -m "trabalho_03: until 4"
#1560739411
git push origin master 
#1560739886
cd trabalho_03_SSL/
#1560739886
ll
#1560739972
zip -r bruno_caio.zip bruno_campos.pcapng README.pdf
#1560739974
ll
#1560740205
zip -r bruno_caio.zip bruno_campos.pcapng README.pdf
#1560740207
ll
#1560740731
git add --all
#1560740733
git commit -m "trabalho_03: until 4"
#1560740735
git push origin master 
#1560743450
cd ..
#1560743459
cd challenges/challenge-keyrus/
#1560743459
ll
#1560743468
source venv_keyrus/bin/activate
#1560743469
ll
#1560743508
cd ..
#1560743520
cd artificial_inteligence/
#1560743520
ll
#1560743527
cd data-science/
#1560743528
ll
#1560743533
source venv_data_science/bin/activate
#1560748840
ping www.google.com
#1560749701
ping -r www.google.com
#1560770143
cd ..
#1560770147
ll
#1560770156
cd challenges/challenge-keyrus/
#1560770157
ll
#1560770432
cd data/
#1560770433
ll
#1560770823
rm tessssssssss.csv
#1560770827
ll
#1560773647
cd ..
#1560773654
ll
#1560773657
cd artificial_inteligence/
#1560773658
ll
#1560773660
cd data-science/
#1560773660
ll
#1560773676
cd ..
#1560773676
l
#1560773679
cd machine_learning/
#1560773680
ll
#1560773707
code .
#1560773722
jupyter-n
#1560773724
jupyter-notebook 
#1560743539
jupyter-notebook 
#1560774830
cd ..
#1560774832
ll
#1560774849
cd challenges/challenge-keyrus/
#1560774850
ll
#1560774954
source venv_keyrus/bin/activate
#1560774954
ll
#1560774959
jupyter-notebook 
#1560781484
git status
#1560781488
git add --all
#1560781564
git commit -m "step 1"
#1560781567
git pull
#1560781580
git push origin master 
#1560781643
code .
#1560781660
cd ..
#1560781662
code .
#1560781839
cd challenge-keyrus/
#1560743481
jupyter-notebook 
#1560782000
pipreqs
#1560782021
pip3 install pipreqs
#1560782028
pipreqs
#1560782032
pipreqs -h
#1560782843
jupyter notebook --generate-config
#1560782854
cat /home/campos/.jupyter/jupyter_notebook_config.py
#1560793923
code /home/campos/.jupyter/jupyter_notebook_config.py
#1560781846
jupyter-notebook 
#1560796695
pip ipywidgets beakerx
#1560796700
pip beakerx
#1560796782
which pip3
#1560796799
pip3 install bearkerx
#1560796712
pip install beakerx
#1560796811
pip3 install beakerx
#1560810722
ll
#1560810751
cd ..
#1560810754
deactivate
#1560810758
cd ..
#1560810763
idea .
#1560825702
cd challenges/challenge-keyrus/
#1560825703
ll
#1560825709
code .
#1560834713
cd ..
#1560834730
source challenges/challenge-keyrus/venv_keyrus/
#1560834736
source challenges/challenge-keyrus/venv_keyrus/bin/activate
#1560834736
ll
#1560834742
jupyter-notebook 
#1560810445
jupyter-notebook 
#1560779390
ping www.google.com
#1560877008
cd projetos/compiladores/
#1560877009
ll
#1560877016
cd trabalho_parte_02-analisador_sintatico/
#1560877017
ll
#1560877034
javacc parser/langX+++.jj 
#1560877037
ll
#1560877045
javac parser/langX.java 
#1560877066
cd parser/
#1560877073
javac langX.java 
#1560877077
ll
#1560877081
cd ..
#1560877082
ll
#1560877106
javac parser/langX.java 
#1560877143
javacc parser/langX+++.jj 
#1560877147
javac parser/langX.java 
#1560877304
git diff
#1560877313
javac parser/langX.java 
#1560877568
sudo apt install javacc
#1560877904
javac parser/langX.java 
#1560877945
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1560877953
java parser.langX testes_e_logs/teste_com_erro_classbody.x
#1560878134
git status
#1560878145
git add --all
#1560878164
git commit -m "refactor: Identations"
#1560878170
git push origin master 
#1560878465
ll
#1560878477
code .
#1560878604
javacc parser/langX+++.jj 
#1560878610
ll
#1560878617
javac parser/langX.java 
#1560878628
java parser.langX testes_e_logs/teste_com_erro_classbody.x
#1560878635
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1560878640
ll
#1560878672
code .
#1560878723
zip -cvf trabalho_ic2.zip
#1560878727
ll
#1560878744
cd ..
#1560878745
ll
#1560878749
cd trabalho_parte_01-analisador_lexico/
#1560878750
ll
#1560878773
cd ..
#1560878776
cd trabalho_parte_02-analisador_sintatico/
#1560878777
ll
#1560878797
mv relatório_parte02.pdf relatorio_ic2.pdf
#1560878800
code .
#1560878934
zip -cvf trabalho_ic2.zip .
#1560878939
cd ..
#1560878940
ll
#1560878950
zip -cvf trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/*
#1560878958
zip -cvf trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1560879010
zip -r trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1560879011
ll
#1560879034
mv trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1560879457
code .
#1560879618
cd trabalho_parte_02-analisador_sintatico/
#1560879619
ll
#1560879629
cd ..
#1560879630
ll
#1560879637
zip -r trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1560879638
ll
#1560879655
mv trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1560879656
ll
#1560879666
cd trabalho_parte_02-analisador_sintatico/
#1560879667
ll
#1560880051
cd ..
#1560880052
ll
#1560880053
cd ..
#1560880056
cd challenges/
#1560880057
ll
#1560880084
source challenge-keyrus/venv_keyrus/bin/activate
#1560880142
cd ..
#1560920026
cd ..
#1560880150
jupyter-notebook 
#1560943599
cd challenges/challenge-
#1560943604
cd challenges/challenge-keyrus/
#1560943606
ll
#1560943619
git status
#1560943838
git remote remove origin 
#1560943839
ll
#1560943851
gitk --all
#1560943865
rm -rf .git/
#1560943866
ll
#1560943873
git status
#1560943908
ll
#1560943910
cd ..
#1560943939
mkdir challenge-keyrus-ds
#1560943951
cd challenge-keyrus-ds/
#1560943953
ll
#1560943955
git status
#1560943961
gitk --all
#1560943975
cd ..
#1560943976
ll
#1560943984
cd challenge-keyrus
#1560943985
ll
#1560943988
gitk --all
#1560944006
git init
#1560944021
git remote add origin git@github.com:brunocampos01/challenge-keyrus.git
#1560944026
git remote -v
#1560944120
virtualenv -p python3 venv_keyrus
#1560944137
code .
#1560880090
jupyter-notebook 
#1560944649
pip frezee
#1560944652
pip freze
#1560944667
pip3 freeze | grep re
#1560944673
pip3 freeze | grep req
#1560944690
deactivate
#1560944697
deactivate
#1560945427
source venv_keyrus/bin/activate
#1560945450
ll
#1560945459
cat requirements.txt 
#1560945528
pip3 install pipreqs
#1560945544
pip3 freeze
#1560945561
pip3 install jupyter
#1560945575
pip3 freeze
#1560945598
pip3 freeze > external_requirements.txt
#1560945763
pip3 freeze | grep virtual
#1560946024
cd challenges/challenge-keyrus
#1560946025
ll
#1560946035
source venv_keyrus/bin/activate
#1560946037
ll
#1560946044
which pip3
#1560946063
pip3 install numpy
#1560946075
pip3 install pandas
#1560946090
pip3 install seaborn
#1560946107
pip3 install missingno
#1560946116
pip3 install sklearn
#1560946180
cd challenge-keyrus
#1560946180
ll
#1560946186
rm -r XDG_CACHE_HOME/
#1560946723
pip3 freeze | grep pipre
#1560947034
pip3 install virtualenv==16.6.0 pipreqs==0.4.9
#1560945984
jupyter-notebook 
#1560947155
git status
#1560947195
ll
#1560947237
git add --all
#1560947252
git commit -m "Initial commit"
#1560947303
code .
#1560947258
git push origin master 
#1560949366
git status
#1560949379
git fetch
#1560949315
sudo apt install docker.io
#1560949466
code .
#1560949477
git pull origin master 
#1560949488
code .
#1560949723
ll
#1560949726
docker pull jupyter/datascience-notebook
#1560950058
ll
#1560950071
git staus
#1560950073
git status
#1560950086
cat src/prepare_environment.py
#1560950093
git diff src/prepare_environment.py
#1560950495
ll
#1560950508
git status
#1560950519
git diff notebooks/1-analise-exploratoria.ipynb
#1560951758
git add --all
#1560951813
git commit -m "fix: hidden files of chanllenges"
#1560951818
git push origin master 
#1560952836
ll
#1560952852
code .
#1560949738
sudo docker pull jupyter/datascience-notebook
#1560952915
sudo docker run
#1560952931
docker ps
#1560952935
sudo docker ps
#1560952976
docker ls
#1560952985
sudo docker ls
#1560952988
sudo docker -h
#1560952996
sudo docker ps
#1560953000
ll
#1560953044
sudo docker run -p 8888:8888 jupyter/jupyter-notebook
#1560953091
sudo docker run jupyter/datascience-notebook
#1560948212
jupyter-notebook 
#1560953571
sudo docker -h
#1560953578
sudo docker stop 
#1560953583
sudo docker ps
#1560953593
sudo docker image
#1560953594
sudo docker images
#1560953606
sudo docker stop jupyter/datascience-notebook
#1560953659
docker run --rm -p 8888:8888 -p 4040:4040 -e JUPYTER_ENABLE_LAB=yes -v ~:/home/jovyan/work jupyter/all-spark-notebook
#1560953663
sudo docker run --rm -p 8888:8888 -p 4040:4040 -e JUPYTER_ENABLE_LAB=yes -v ~:/home/jovyan/work jupyter/all-spark-notebook
#1560953845
kk
#1560953847
ll
#1560954208
deactivate
#1560954213
deactivate
#1560954215
ll
#1560954237
rm -r XDG_CACHE_HOME/ venv_keyrus/
#1560954240
ll
#1560954257
virtualenv -p python3 venv_keyrus
#1560954277
source venv_keyrus/bin/activate
#1560954282
pip3 install -r external_requirements.txt requirements.txt
#1560954298
pip3 install -r external_requirements.txt
#1560954333
pip3 install -r external_requirements.txt & requirements.txt
#1560954360
deactivate
#1560954366
rm -r venv_keyrus/
#1560954439
deactivate
#1560954458
rm -r venv_keyrus/
#1560954535
cd notebooks/
#1560954607
cd ..
#1560954637
jupyter-notebook
#1561003557
ll
#1561003580
cd projetos/
#1561003580
ll
#1561003627
source venv_global/bin/activate
#1561003654
cd ..
#1561003655
ll
#1561003681
cd .config/
#1561003682
ll
#1561003701
cd ..
#1561003702
ll
#1561003707
cd .jupyter/
#1561003707
ll
#1561003712
code .
#1561003642
jupyter-notebook 
#1561003791
pip3 freeze | grep lo
#1561003999
jupyter-notebook 
#1561004619
jupyter notebook --generate-config
#1561004637
jupyter-notebook 
#1561005080
cd ..
#1561005082
ll
#1561005088
rm -r .jupyter/
#1561005092
git clone https://github.com/minrk/.jupyter.git
#1561005099
ll
#1561005103
cd .jupyter/
#1561005104
ll
#1561005114
jupyter-notebook 
#1561005123
jupyter notebook 
#1561005162
jupyter
#1561005164
jupyter notebook 
#1561005177
cd /home/campos/dev/mine/notebooks
#1561005183
cd /home/campos/dev/
#1561005188
cd /home/campos/dev
#1561005194
ll
#1561005206
code .
#1561005327
pip3 install jupyter-lab
#1561005253
jupyter-notebook 
#1561005441
cd ..
#1561005444
rm -r .jupyter/
#1561005451
rm -rf .jupyter/
#1561005452
ll
#1561005575
pip3 install jupyterlab
#1561005635
jupyter-qtconsole 
#1561005650
jupyter-run 
#1561005693
jupyter-lab
#1561006584
cd .jupyter/
#1561006584
ll
#1561006592
rm -rf lab/
#1561006593
ll
#1561006595
cd ..
#1561005919
jupyter-notebook 
#1561007209
deactivate
#1561007217
cd .jupyter/
#1561007218
ll
#1561007221
cd ..
#1561007223
rm -rf lab/
#1561007229
rm -rf .jupyter/
#1561007237
rm -r venv_global/
#1561007254
virtualenv -p python3 venv_global
#1561007272
source venv_global/bin/activate
#1561007307
pip3 install jupyter
#1561007330
pip3 install numpy==1.16.4
#1561007333
matplotlib==3.1.0
#1561007333
missingno==0.4.1
#1561007333
pandas==0.24.2
#1561007333
seaborn==0.9.0
#1561007333
ipython==7.5.0
#1561007333
scikit_learn==0.21.2
#1561007333
atlas==0.27.0
#1561007341
pip3 install xgboost==0.90
#1561007356
pip3 install matplotlib==3.1.0
#1561007631
find . -name '*.py'
#1561007645
find . -name '*.sh'
#1561007665
find . -name 'steps_data_science.sh'
#1561007678
find . -name steps_data_science.sh
#1561007685
find . -name steps_data_science
#1561007693
find -h
#1561007697
find --help
#1561007740
find . -name steps_data_science -ls
#1561007747
find . -name steps_data_science -ll
#1561007776
cd /home/campos/projetos/artificial_inteligence/data_science/steps_data_science/notebooks
#1561007781
find . -name steps_data_science -ls
#1561007794
find .. -name steps_data_science -ls
#1561007889
find ../ -name steps_data_science -ls
#1561007899
find /.. -name steps_data_science -ls
#1561007940
find /.. -name steps_data_science
#1561007976
sudo find /.. -name steps_data_science
#1561008010
sudo find .. -name steps_data_science
#1561008014
sudo find /.. -name steps_data_science
#1561008030
find /.. -name steps_data_science
#1561008199
find /.. -name steps_data_science -ls
#1561008210
sudo find /.. -name steps_data_science -ls
#1561039537
cd
#1561039546
cd projetos/challenges/challenge-keyrus/
#1561039547
ll
#1561039560
git status
#1561039567
git pull origin master 
#1561039589
code .
#1561039656
git add --all
#1561039707
git commit -m "refactor: Add function to remove feature without correlation"
#1561039716
git push origin master 
#1561039724
git pull origin master 
#1561039736
git push origin master 
#1561045028
jupyter notebooks/1-analise-exploratoria.ipynb 
#1561045055
ipython notebooks/1-analise-exploratoria.ipynb 
#1561045701
cd ..
#1561045702
ll
#1561045729
mkdir challenge-softplan-data-science
#1561045735
cd challenge-softplan-data-science/
#1561045735
ll
#1561045787
code .
#1561067934
cd ..
#1561067938
kk
#1561067939
ll
#1561067983
rm -rf porto-seguro-safe-driver-prediction/
#1561067988
code .
#1561068016
cd personal_config/
#1561068017
ll
#1561068019
git status
#1561068025
git add --all
#1561068034
git commit -m "refactor"
#1561068040
git push origin master 
#1561068054
git pull origin ma
#1561068059
git pull origin master 
#1561068072
code ,
#1561068084
code .
#1561068135
git push origin master 
#1561068144
git pull origin master 
#1561068160
git add --all
#1561068164
git commit -m "refactor"
#1561068166
git push origin master 
#1561068833
cd ..
#1561068834
ll
#1561068860
cd organizacao-e-arquitetura/
#1561068876
code .
#1561071790
ll
#1561071806
code .
#1561084684
cd ..
#1561084689
cd artificial_inteligence/
#1561084690
ll
#1561084692
cd data-science/
#1561084692
ll
#1561084694
git status
#1561084698
git add --all
#1561084711
git commit -m "refator"
#1561084714
git push origin master 
#1561084732
git pull origin master 
#1561084744
git push origin master 
#1561085085
ll
#1561085088
df .
#1561085102
df --all
#1561085111
df ..
#1561099183
cd ..
#1561099191
cd challenges/challenge-keyrus/
#1561099192
ll
#1561099198
git status
#1561099205
git add --all
#1561099247
git commit -m "feat: add method to remove columns without importance and without corr"
#1561099251
git push origin master 
#1561105514
cd ..
#1561105519
cd challenge-softplan-data-science/
#1561105519
ll
#1561105526
python3 caixa_eletronico.py 
#1561118747
cd ..
#1561118750
ll
#1561118755
cd challenge-
#1561118760
cd challenge-softplan-data-science/
#1561118762
git init
#1561118779
git remote add origin git@github.com:brunocampos01/challenge-softplan.git
#1561118782
git remote -v
#1561118792
git pull origin 
#1561118812
git pull origin master
#1561118827
code .
#1561118982
git status
#1561119012
git add --all
#1561119030
git commit -m "feat: initial commit"
#1561119034
git push origin master 
#1561119316
code .
#1561121291
python3 withdraw.py 
#1561122124
git pull origin master 
#1561122146
git add --all
#1561122174
git commit -m "refactor: variable's name"
#1561122179
git push origin master 
#1561149762
cd ..
#1561149764
ll
#1561149777
cd challenge-aawz/
#1561149778
ll
#1561149781
git status
#1561151800
pip3 freeze | grep req
#1561152076
cd ..
#1561152079
code .
#1561152107
source /home/campos/projetos/venv_global/bin/activate
#1561152108
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pep8
#1561152110
/home/campos/projetos/venv_global/bin/python3 -m pip install -U prospector
#1561152121
/home/campos/projetos/venv_global/bin/python3 -m pip install -U flake8
#1561152216
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pep8/home/campos/projetos/venv_global/bin/python3 -m pip install -U pep8
#1561152328
cd artificial_inteligence/data-science/steps_data_science/
#1561152328
ll
#1561152331
cd src/
#1561152331
ll
#1561152334
make
#1561153824
source venv_global/bin/activate
#1561153834
pwd
#1561153840
cd /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src
#1561153848
make
#1561154536
cd /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src
#1561154539
make
#1561155448
sudo apt install python3
#1561155940
make
#1561156029
ll
#1561156034
cd venv_/
#1561156035
ll
#1561156037
cd ..
#1561156041
rm -r venv_/
#1561156045
make
#1561156069
rm -r venv_/
#1561156071
make
#1561156112
ll
#1561156115
rm -r venv_/
#1561156116
make
#1561156147
ll
#1561156162
rm -r venv_/
#1561156166
rm -r venv_default/
#1561156170
make
#1561156205
rm -r venv_default/
#1561156206
make
#1561156212
ll
#1561156215
rm -r venv_default/
#1561156235
make
#1561156632
rm -r venv_default/
#1561159060
sudo apt install shfmt
#1561159072
nap install shfmt
#1561159076
snap install shfmt
#1561159195
shfmt -h
#1561159306
cd ..
#1561159312
code .
#1561162736
cd artificial_inteligence/
#1561162740
cd data-science/
#1561162741
ll
#1561162749
git status
#1561162765
git add --all
#1561162772
git commit -m "refactor"
#1561163688
deactivate
#1561163691
ll
#1561163700
cd enviroment/
#1561163701
ll
#1561163707
./run_virtual_env.sh 
#1561163753
/bin/bash  /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src/enviroment/run_virtual_env.sh 
#1561164029
source venv/bin/activate
#1561164033
deactivate
#1561164073
./run_virtual_env.sh 
#1561164583
ll
#1561164604
./run_virtual_env.sh 
#1561164819
ll
#1561164822
rm -r venv/
#1561164827
./run_virtual_env.sh 
#1561162776
git push origin master 
#1561164889
git status
#1561164932
source venv/bin/activate
#1561164937
deactivate
#1561165130
source venv/bin/activate
#1561165136
deactivate
#1561165140
source venv/bin/activate
#1561165147
deactivate
#1561165153
rm -r venv/
#1561165162
./run_virtual_env.sh 
#1561165178
ll
#1561165232
./run_virtual_env.sh 
#1561165309
cd venv/
#1561165310
ll
#1561165314
cd bin/
#1561165315
ll
#1561165354
cd ..
#1561165359
./run_virtual_env.sh 
#1561165591
source run_virtual_env.sh 
#1561165624
cd ..
#1561165639
cp data-science/ /home/campos/
#1561165646
cp -r data-science/ /home/campos/
#1561166199
cd data-science/
#1561166201
ll
#1561166217
git reset --soft HEAD~1
#1561166220
ll
#1561166260
git status
#1561166270
gitk --all &
#1561166331
git add steps_data_science/src/setup.py steps_data_science/src/enviroment/run_virtual_env.sh steps_data_science/src/enviroment/makefile steps_data_science/src/dump_data/dump_data.py steps_data_science/notebooks/1-prepare-environment.ipynb
#1561166339
git commit -m "refator"
#1561166344
git push origin ma
#1561166603
cd steps_data_science/src/enviroment/
#1561166604
ll
#1561166614
bash run_virtual_env.sh 
#1561166346
git push origin master 
#1561166630
git reset --soft HEAD~1
#1561166653
git reset --soft -h
#1561166680
git reset --soft HEAD~4
#1561166698
git status
#1561166725
git pull origin master 
#1561166854
git status
#1561166878
git reset venv_data_science/lib/python3.7/sre_parse.py
#1561166882
git status
#1561166889
git reset 
#1561166894
git status
#1561166921
git add --all
#1561166932
git commit -m "refactor"
#1561166936
git push origin master 
#1561167792
git reset 
#1561167798
git status
#1561174137
make
#1561175120
python3 -m preparede_environment.py
#1561175126
python3 -m preparede_environment
#1561175136
python3 -m prepare_environment
#1561175154
python3 -m prepare_environment create_virtualenv()
#1561175158
python3 -m prepare_environment create_virtualenv
#1561175298
python3 -c 'import prepare_environment'
#1561175319
python3 -c 'import prepare_environment; create_virtualenv()'
#1561175357
python3 -c 'from prepare_environment import *; create_virtualenv()'
#1561175439
cd ..
#1561175450
python3 -c 'from prepare_environment import *; create_virtualenv()'
#1561175520
cd enviroment/
#1561175532
./create_virtual_env.sh 
#1561175573
python3 -c 'from prepare_environment import *; create_virtualenv()'
#1561176162
./create_virtual_env.sh 
#1561176212
ll
#1561176221
bash create_virtual_env.sh
#1561176225
ll
#1561176229
rm -r venv/
#1561176233
bash create_virtual_env.sh
#1561176638
ll
#1561176640
virtualenv -p python3 venv_keyrus
#1561176907
code .
#1561177134
./create_virtual_env.sh 
#1561178524
make
#1561179186
ll
#1561179269
make
#1561179735
make test_environment 
#1561179747
make clean 
#1561179775
make 
#1561179793
make create_environment 
#1561179884
make 
#1561179890
make clean 
#1561180192
make 
#1561180320
make clean 
#1561180354
make 
#1561180461
make requirements 
#1561180498
make test_environment 
#1561180543
make
#1561181553
cd ..
#1561181557
code .
#1561182508
cd 
#1561182527
cd projetos/artificial_inteligence/
#1561182528
code .
#1561185070
du -h
#1561185082
du -h .
#1561185309
du ---help
#1561185317
du --help
#1561185367
du -h -s
#1561185396
du -h -x .git
#1561185400
du -h -x .git/
#1561185406
du -h -x=.git/
#1561185430
du -h -X .git
#1561185432
du -h -X .git/
#1561185479
ll
#1561185487
du -h -X .vscode/
#1561185552
du --help
#1561007366
jupyter-notebook 
#1561212691
ll
#1561212695
cd Downloads/
#1561212696
ll
#1561212715
cd ..
#1561212718
cd projetos/
#1561212718
ll
#1561212767
charme .
#1561213021
source venv_global/bin/activate
#1561214996
cd artificial_inteligence/data-science/steps_data_science/
#1561214998
ll
#1561215003
git clone https://github.com/daler/matplotlibrc.git
#1561215021
ll
#1561215027
cd matplotlibrc/
#1561215027
ll
#1561215050
./showstyle.py rc/probpro 
#1561215062
pip3 install python-tk
#1561215069
pip3 install --user python-tk
#1561215124
cd
#1561215129
cd .config/
#1561215130
ll
#1561215135
cd matplotlib/
#1561215136
ll
#1561215146
ll
#1561215148
cd rc/
#1561215149
ll
#1561215170
mv probpro /home//campos/.config/matplotlib/
#1561215213
code .
#1561213030
jupyter-notebook 
#1561236803
cd ;;
#1561236805
cd ..
#1561237162
cd /etc/matplotlibrc
#1561237317
cd ..
#1561237332
ipython profile create
#1561237335
ll
#1561237350
ipython profile create
#1561237361
cd ..
#1561237362
ll
#1561237377
cd .ipython/
#1561237378
ll
#1561237382
cd profile_default/
#1561237383
ll
#1561237389
code .
#1561236814
jupyter-notebook 
#1561239940
code /home/campos/projetos/venv_global/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc
#1561256991
cd ..
#1561256997
cd .config/matplotlib/
#1561256999
code .
#1561258146
cd artificial_inteligence/data-science/
#1561258150
code .
#1561259347
cd ..
#1561259353
jupyter-notebook 
#1561271697
cd ..
#1561271705
jupyter-notebook 
#1561274813
cd ..
#1561284974
ll
#1561284981
cd seguranca/
#1561284982
ll
#1561285278
mv trabalho_01_kali_OWASP_nmap/ trabalho_kali_OWASP_nmap/
#1561285290
mv trabalho_02_chaves_certificados/ trabalho_chaves_certificados/
#1561285303
mv trabalho_03_SSL/ trabalho_SSL/
#1561285305
ll
#1561285319
mv /home/campos/Downloads/ .
#1561285320
ll
#1561285332
rm -r Downloads/
#1561285339
rm -rf Downloads/
#1561285343
sudo rm -rf Downloads/
#1561285348
ll
#1561285406
mv /home/campos/Downloads/tarefaJava2-20191.zip .
#1561285407
ll
#1561285435
mkdir trabalho_02_implementacao
#1561285438
ll
#1561285446
mv tarefaJava2-20191.zip trabalho_02_implementacao/
#1561285452
ll
#1561285466
cd trabalho_02_implementacao/
#1561285469
ll
#1561285475
unzip tarefaJava2-20191.zip 
#1561285477
ll
#1561285522
code .
#1561320244
cd
#1561320253
cd projetos/challenges/challenge-keyrus/
#1561320254
ll
#1561320257
git status
#1561320279
git add --all
#1561320313
git commit -m "refactor: new structure project"
#1561320318
git push origin master 
#1561326200
git pull origin master 
#1561326237
idea . &
#1561326242
idea .
#1561326209
git push origin master 
#1561326324
cd ..
#1561326325
ll
#1561326330
cd challenge-indicium/
#1561326334
git add --all
#1561326341
git commit -m "refactor"
#1561326347
git push origin master 
#1561326360
git pull origin master 
#1561326371
git push origin master 
#1561326489
cd ..
#1561326491
ll
#1561326494
cd kaggle/
#1561326495
ll
#1561326500
cd porto-seguro-safe-driver-prediction/
#1561326503
git add --all
#1561326514
git commit -m "refactor"
#1561326520
git push origin master 
#1561326552
git pull origin master 
#1561274814
jupyter-notebook 
#1561326567
git push origin master 
#1561327876
ll
#1561327878
cd
#1561327880
cd projetos/seguranca/
#1561327881
ll
#1561327931
mvn
#1561327942
ant
#1561327949
sudo apt install ant
#1561328255
ll
#1561328315
cd Sockets/
#1561328334
ant 
#1561328400
ll
#1561328402
cd ..
#1561328402
ll
#1561328412
unzip tarefaJava2-20191.zip 
#1561328496
cd Sockets/
#1561328497
ant
#1561328512
cd ..
#1561328634
cd Sockets/build/
#1561328634
ll
#1561328643
cd ..
#1561328646
cd dist/
#1561328646
ll
#1561329093
giut clone https://github.com/jcmorais/Diffie-Hellman-Station-to-Station-Protocol.git
#1561329098
git clone https://github.com/jcmorais/Diffie-Hellman-Station-to-Station-Protocol.git
#1561329291
ll
#1561328656
java -jar Sockets.jar 
#1561329307
pwd
#1561329309
cd ..
#1561329312
pwd
#1561329317
mv Diffie-Hellman-Station-to-Station-Protocol/ /home/campos/projetos/seguranca/trabalho_02_implementacao
#1561329319
ll
#1561331314
ll
#1561331326
cd testeOAEPRSA/
#1561331327
ll
#1561331364
cd src/
#1561331366
cd ..
#1561331367
ant
#1561331619
cd ..
#1561331641
ll
#1561331643
cd ..
#1561331644
ll
#1561331700
mkdir bkp 
#1561331706
mv tarefaJava2-20191.zip bkp/
#1561331708
cd bkp/
#1561331709
ll
#1561331712
unzip tarefaJava2-20191.zip 
#1561331761
ll
#1561331763
java -jar "testeOAEPRSA.jar" 
#1561331780
java -jar dist/testeOAEPRSA.jar
#1561337679
..
#1561337681
ll
#1561337695
zip -xvf protocolSTS/
#1561337700
zip protocolSTS/
#1561337714
zip ll
#1561337716
ll
#1561337719
zip
#1561337769
zip -xvf trabalho_02_bruno_caio.zip protocolSTS/*
#1561337771
ll
#1561337807
rm -r trabalho_02_bruno_caio.zip 
#1561337814
zip trabalho_02_bruno_caio.zip protocolSTS/*
#1561337834
zip trabalho_02_bruno_caio.zip protocolSTS/
#1561337848
cd protocolSTS/
#1561337849
ll
#1561337851
cd src/
#1561337852
ll
#1561337896
cd ..
#1561337913
zip -r trabalho_02_bruno_caio.zip protocolSTS/
#1561338491
ll
#1561338494
cd ..
#1561338494
ll
#1561338500
cd Sockets/
#1561338501
ll
#1561338519
pwd
#1561338523
ant
#1561340404
ll
#1561340406
cd ..
#1561340407
ll
#1561340415
cd protocolSTS/
#1561340417
ant
#1561372528
cd ..
#1561372528
ll
#1561372541
cd Sockets/
#1561372542
ll
#1561372595
ant
#1561372713
cd dist/
#1561372713
ll
#1561372731
cd trabalho_02_implementacao/
#1561372732
ll
#1561372752
cd Sockets/
#1561372754
ll
#1561372773
nmap 
#1561372782
dig 13245
#1561372800
ll
#1561372807
cd dist/
#1561372808
ll
#1561372813
java -jar Sockets.jar 
#1561372953
cd ..
#1561372959
ant run
#1561372979
ant javadoc-build
#1561372721
java -jar Sockets.jar 
#1561373079
cd ..
#1561373091
java -cp package Client;
#1561373091
import Cipher.DiffieHellman;
#1561373094
import java.io.BufferedReader;
#1561373094
import java.io.IOException;
#1561373094
import java.io.InputStreamReader;
#1561373094
import java.io.PrintWriter;
#1561373095
import java.net.Socket;
#1561373095
import java.security.InvalidAlgorithmParameterException;
#1561373095
import java.security.InvalidKeyException;
#1561373095
import java.security.NoSuchAlgorithmException;
#1561373096
import java.security.spec.InvalidKeySpecException;
#1561373096
import java.util.Base64;
#1561373096
public class Client {
#1561373110
java -cp /home/campos/projetos/seguranca/trabalho_02_implementacao/Sockets/src/sockets/Servidor.java
#1561373129
java -cp dist/Sockets.jar 
#1561373159
cd
#1561373160
cd projetos/
#1561373161
ll
#1561373163
code .
#1561376429
cd ..
#1561376431
code .
#1561376454
cd ..
#1561376457
code .
#1561376469
cd programacao-paralela-e-distribuida/
#1561376471
code .
#1561376591
cd "/home/campos/projetos/programacao-paralela-e-distribuida/trabalho04_socket/src/Client"
#1561376591
mvn archetype:generate -DarchetypeArtifactId="maven-archetype-quickstart" -DarchetypeGroupId="org.apache.maven.archetypes"
#1561376596
sudo apt install maven
#1561376732
ll
#1561376736
cd dist/
#1561376736
ll
#1561376771
cd ,,
#1561376774
ant
#1561376664
mvn archetype:generate -DarchetypeArtifactId="maven-archetype-quickstart" -DarchetypeGroupId="org.apache.maven.archetypes"
#1561377270
cd ..
#1561377272
ll
#1561377277
cd ..
#1561377277
ll
#1561377293
mv -r prof/ trabalho_02_implementacao/
#1561377299
mv prof/ trabalho_02_implementacao/
#1561378920
cd trabalho_02_implementacao/
#1561378920
ll
#1561378923
cd Sockets/
#1561378924
ll
#1561378927
cd dist/
#1561378927
ll
#1561379434
cd challenges/challenge-keyrus/
#1561379436
ll
#1561379438
code .
#1561379447
cd ..
#1561379450
code .
#1561379556
code ,
#1561378934
java -jar Sockets.jar 
#1561379568
code .
#1561379603
git status
#1561379608
pwd
#1561379615
cd challenge-keyrus/
#1561379615
ll
#1561379619
git status
#1561379626
git add --all
#1561379648
git commit -m "feat: add code preparing environment"
#1561379652
git push origin master 
#1561381478
cd trabalho04_socket/
#1561381478
ll
#1561381482
ant
#1561381515
cd trabalho04_socket/
#1561381516
ll
#1561381519
ant 
#1561381642
ant
#1561382080
cd trabalho_02_implementacao/
#1561382081
ll
#1561382084
cd Sockets/
#1561382084
ll
#1561382087
ant
#1561382738
jshell
#1561382784
ll
#1561382786
cd ..
#1561382787
ll
#1561382793
cd src/
#1561382803
javac sockets/Cliente.java 
#1561382805
ll
#1561382809
cd sockets/
#1561382810
ll
#1561382917
javac Servidor.java 
#1561382921
ll
#1561382981
java Cliente.java
#1561383003
cd ..
#1561383005
ll
#1561383010
cd Sockets/
#1561383011
ll
#1561383015
cd src/
#1561383016
ll
#1561383019
cd sockets/
#1561383019
ll
#1561383025
java Servidor 
#1561383038
java Servidor.java
#1561385281
cd ..
#1561385282
ll
#1561385284
cd ..
#1561385284
kk
#1561385285
ll
#1561385286
cd ..
#1561385294
cd trabalho_02_implementacao/
#1561385294
ll
#1561385297
cd pro
#1561385307
ll
#1561385315
pwd
#1561385317
cd ..
#1561385322
cd protocolSTS/
#1561385322
ll
#1561385324
cd src/
#1561385325
ll
#1561385328
cd Client/
#1561385329
ll
#1561385334
javac Client.java 
#1561385431
cd ..
#1561385432
ll
#1561385435
cd Server/
#1561385437
ll
#1561385444
javac ClientHandler.java
#1561385454
cd ..
#1561385455
kk
#1561385456
ll
#1561385467
javac Server/Server.java
#1561385497
ll
#1561385506
javac Cipher/DiffieHellman.java 
#1561385529
cd ..
#1561385536
code .
#1561385777
javac --version
#1561386013
cd
#1561386020
cd Do
#1561386020
ll
#1561386024
cd Downloads/
#1561386024
ll
#1561386042
cd ..
#1561386042
ll
#1561386051
lll
#1561386051
ll
#1561386053
cd ..
#1561386054
ll
#1561386072
ll
#1561386073
cd ..
#1561386074
ll
#1561386076
cd ..
#1561386077
ll
#1561386078
cd ..
#1561386079
ll
#1561386086
git clone https://github.com/jcmorais/Diffie-Hellman-Station-to-Station-Protocol.git
#1561386092
ll
#1561386119
cd Diffie-Hellman-Station-to-Station-Protocol/
#1561386120
ll
#1561386124
cd SimplifiedDH/
#1561386125
ll
#1561386133
cd src/
#1561386133
ll
#1561386141
cd Cipher/
#1561386141
ll
#1561386155
java DiffieHellman.java
#1561386161
cd ..
#1561386162
pwd
#1561386168
cd /home/campos/projetos/seguranca/trabalho_02_implementacao/Diffie-Hellman-Station-to-Station-Protocol/SimplifiedDH/src
#1561386173
cd ..
#1561386174
ll
#1561386297
code .
#1561386370
ll
#1561386380
javac src/*
#1561386386
javac src/
#1561386394
javac -h
#1561386397
javac --help
#1561386448
javac
#1561386458
javac src/Client/Client.java 
#1561386475
code .
#1561386501
cd "/home/campos/projetos/seguranca/trabalho_02_implementacao/Diffie-Hellman-Station-to-Station-Protocol/SimplifiedDH/src"
#1561386501
mvn archetype:generate -DarchetypeArtifactId="maven-archetype-quickstart" -DarchetypeGroupId="org.apache.maven.archetypes"
#1561386579
ll
#1561386660
ll
#1561386670
cd ..
#1561386671
ll
#1561386675
cd ..
#1561386676
ll
#1561386682
cd ..
#1561386697
rm -r Diffie-Hellman-Station-to-Station-Protocol/
#1561386702
rm -rf Diffie-Hellman-Station-to-Station-Protocol/
#1561386704
ll
#1561386720
cd ..
#1561386721
ll
#1561386725
cd projetos/
#1561386726
ll
#1561386728
cd programacao-paralela-e-distribuida/
#1561386729
ll
#1561386734
git status
#1561386741
code .
#1561386763
git status
#1561386771
code .
#1561386783
git status
#1561386789
code .
#1561386806
git status
#1561386809
git add --all
#1561386819
git commit -m "socket update"
#1561386823
git push origin master 
#1561386831
git pull origin master 
#1561386838
git push origin master 
#1561386878
code .
#1561386946
git add --all
#1561386950
git commit -m "socket update"
#1561386952
git push origin master 
#1561387153
cd
#1561387172
cd projetos/artificial_inteligence/data-science/
#1561387174
code .
#1561387239
./create_virtual_env.sh 
#1561387617
cd projetos/compiladores/
#1561387617
ll
#1561387648
mkdir trabalho_03-arvore_sintatica
#1561387655
cd trabalho_03-arvore_sintatica/
#1561387656
ll
#1561387696
cd ..
#1561387697
ll
#1561387723
mv trabalho_03-arvore_sintatica/ trabalho_parte_03-arvore_sintatica/
#1561387725
ll
#1561388780
cd trabalho_parte_03-arvore_sintatica/
#1561388781
ll
#1561388827
java parser.langX -print_tree ../livro_como_construir_compilador/ssamples/bintree.x 
#1561389470
ll
#1561389499
javacc parser/langX+++.jj 
#1561389520
javac parser/langX.java 
#1561390628
javacc parser/langX+++.jj 
#1561390630
javac parser/langX.java 
#1561390680
java parser.langX -print_tree ../livro_como_construir_compilador/ssamples/bintree.x 
#1561391054
javacc parser/langX+++.jj 
#1561391060
javac parser/langX.java 
#1561391214
javacc parser/langX+++.jj 
#1561391216
javac parser/langX.java 
#1561391251
javacc parser/langX+++.jj 
#1561391252
javac parser/langX.java 
#1561391419
cd ..
#1561391431
cd livro_como_construir_compilador/cap06/
#1561391432
ll
#1561391445
javac parser/langX.java
#1561391458
javacc parser/langX++.jj 
#1561391475
ll
#1561391562
javac parser/langX++.jj 
#1561391575
javacc parser/langX+++.jj 
#1561391581
javac parser.langX.java 
#1561391599
javac langX.java 
#1561391606
javac parser.langX.java 
#1561391631
javac langX.java 
#1561391664
cd parser/
#1561391664
ll
#1561391671
javac langX.java 
#1561391702
cd ..
#1561391711
javac parser/langX.java 
#1561391719
cd ..
#1561391734
javac cap06/langX.java 
#1561391747
cd cap06/
#1561391747
ll
#1561391751
cd parser/
#1561391752
ll
#1561391757
javacc langX++.jj 
#1561391759
cd ..
#1561391772
javac parser/langX.java 
#1561392163
javacc parser/langX+++.jj 
#1561392170
javac parser/langX.java 
#1561392246
javacc parser/langX+++.jj 
#1561392247
javac parser/langX.java 
#1561392267
javacc parser/langX+++.jj 
#1561392268
javac parser/langX.java 
#1561393384
ping www.google.com
#1561396381
javacc parser/langX+++.jj 
#1561396383
javac parser/langX.java 
#1561396414
java parser.langX -print_tree ../livro_como_construir_compilador/ssamples/bintree.x
#1561397313
ll
#1561397347
javacc parser/langX+++.jj 
#1561397350
javac parser/langX.java 
#1561397370
java parser.langX -print_tree ../livro_como_construir_compilador/ssamples/bintree.x
#1561398084
java parser.langX -h
#1561398088
java parser.langX --help
#1561398117
java parser.langX -print_tree
#1561398128
java parser.langX
#1561398184
java parser.langX  ../livro_como_construir_compilador/ssamples/bintree.x
#1561398244
java parser.langX  
#1561398257
java parser.langX
#1561398260
java parser.langX -
#1561398271
ll
#1561398304
java parser.langX
#1561398436
javacc parser/langX+++.jj 
#1561398441
javac parser/langX.java 
#1561398448
java parser.langX  
#1561399635
javacc parser/langX+++.jj 
#1561399638
javac parser/langX.java 
#1561399647
java parser.langX -print_tree ../livro_como_construir_compilador/ssamples/bintree.x
#1561399680
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561401122
javacc parser/langX+++.jj 
#1561401124
javac parser/langX.java 
#1561401158
javacc parser/langX+++.jj 
#1561401165
javac parser/langX.java 
#1561401193
cd ..
#1561401197
cd trabalho_parte_02-analisador_sintatico/
#1561401197
ll
#1561401285
javacc parser/langX++.jj 
#1561402317
javacc parser/langX+++.jj 
#1561402319
javac parser/langX.java 
#1561402458
javacc parser/langX+++.jj 
#1561402486
javac parser/langX.java 
#1561402590
javacc parser/langX+++.jj 
#1561402591
javac parser/langX.java 
#1561402622
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1561402632
java parser.langX testes_e_logs/teste_com_erro_classbody.x
#1561402847
javacc parser/langX+++.jj 
#1561402848
javac parser/langX.java 
#1561403016
javacc parser/langX+++.jj 
#1561403017
javac parser/langX.java 
#1561404025
javacc parser/langX+++.jj 
#1561404026
javac parser/langX.java 
#1561404035
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561406917
git staus
#1561406925
git status
#1561407005
cd ..
#1561407009
cd data-science/
#1561407010
ll
#1561407012
git status
#1561407016
git add --all
#1561407027
git pull origin master 
#1561407041
git commit -m "refactor"
#1561407046
git push origin master 
#1561408480
git status
#1561408505
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561408514
javacc parser/langX+++.jj 
#1561408517
javac parser/langX.java 
#1561408640
git add --ll
#1561408646
git add --all
#1561408701
git commit -m "tree syntactic: intial"
#1561408706
git push origin master 
#1561408484
git push origin master 
#1561408938
cp . /home/campos/Downloads/
#1561408945
cd ..
#1561408947
cp . /home/campos/Downloads/
#1561408955
cp -r data-science/ /home/campos/Downloads/
#1561408992
cd data-science/
#1561408992
kk
#1561408995
ll
#1561409068
git reset 
#1561409070
ll
#1561409092
git reset HEAD~10
#1561409099
gitk --all &
#1561409113
git status
#1561409124
git pull origin master 
#1561409182
git add steps_data_science/data/README.md steps_data_science/data/callcenter_descricao.txt steps_data_science/data/cleansing/ steps_data_science/data/dump/ steps_data_science/data/raw/ steps_data_science/notebooks/README.md steps_data_science/references/ steps_data_science/reports/callcenter_marketing_clenning.csv steps_data_science/src/README.md steps_data_science/src/dump_data/ steps_data_science/src/environment/ steps_data_science/src/models/ steps_data_science/src/pyanalytics/ steps_data_science/src/setup.py steps_data_science/src/visualization/ tutorials_libraries/
#1561409187
git status
#1561409199
git commit -m "go"
#1561409203
git push origin master 
#1561409212
git pull
#1561409227
git push origin master --force
#1561409287
git status
#1561409294
code .
#1561409673
git status
#1561409683
git add --all
#1561409698
git commit -m "refactor"
#1561410689
javacc parser/langX+++.jj 
#1561410692
javac parser/langX.java 
#1561410712
javacc parser/langX+++.jj 
#1561410713
javac parser/langX.java 
#1561410723
javacc parser/langX+++.jj 
#1561410724
javac parser/langX.java 
#1561410789
javacc parser/langX+++.jj 
#1561410791
javac parser/langX.java 
#1561411091
javacc parser/langX+++.jj 
#1561411093
javac parser/langX.java 
#1561411103
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561411185
javacc parser/langX+++.jj 
#1561411187
javac parser/langX.java 
#1561411284
javacc parser/langX+++.jj 
#1561411285
javac parser/langX.java 
#1561411414
javacc parser/langX+++.jj 
#1561411416
javac parser/langX.java 
#1561411442
javacc parser/langX+++.jj 
#1561411444
javac parser/langX.java 
#1561411447
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561411922
javacc parser/langX+++.jj 
#1561411923
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561411926
javac parser/langX.java 
#1561411929
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561411994
javacc parser/langX+++.jj 
#1561411998
javac parser/langX.java 
#1561412001
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561412019
javacc parser/langX+++.jj 
#1561412021
javac parser/langX.java 
#1561412024
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561409702
git push origin master 
#1561412590
javacc parser/langX+++.jj 
#1561412592
javac parser/langX.java 
#1561413071
javacc parser/langX+++.jj 
#1561413073
javac parser/langX.java 
#1561413090
javacc parser/langX+++.jj 
#1561413092
javac parser/langX.java 
#1561413167
javacc parser/langX+++.jj 
#1561413169
javac parser/langX.java 
#1561413238
javacc parser/langX+++.jj 
#1561413239
javac parser/langX.java 
#1561413462
javacc parser/langX+++.jj 
#1561413463
javac parser/langX.java 
#1561413565
javacc parser/langX+++.jj 
#1561413567
javac parser/langX.java 
#1561413943
javacc parser/langX+++.jj 
#1561413944
javac parser/langX.java 
#1561413964
javacc parser/langX+++.jj 
#1561413965
javac parser/langX.java 
#1561414080
javacc parser/langX+++.jj 
#1561414081
javac parser/langX.java 
#1561414282
javacc parser/langX+++.jj 
#1561414283
javac parser/langX.java 
#1561414421
javacc parser/langX+++.jj 
#1561414423
javac parser/langX.java 
#1561414445
javacc parser/langX+++.jj 
#1561414446
javac parser/langX.java 
#1561414500
javacc parser/langX+++.jj 
#1561414501
javac parser/langX.java 
#1561414506
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414732
javacc parser/langX+++.jj 
#1561414733
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414735
javac parser/langX.java 
#1561414738
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414783
javacc parser/langX+++.jj 
#1561414784
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414786
javac parser/langX.java 
#1561414789
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414800
javacc parser/langX+++.jj 
#1561414801
javac parser/langX.java 
#1561414804
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414825
javacc parser/langX+++.jj 
#1561414828
javac parser/langX.java 
#1561414831
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561414848
javacc parser/langX+++.jj 
#1561414850
javac parser/langX.java 
#1561414853
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561417618
javacc parser/langX+++.jj 
#1561417621
javac parser/langX.java 
#1561417624
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561417863
javacc parser/langX+++.jj 
#1561417866
javac parser/langX.java 
#1561417869
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561417927
javacc parser/langX+++.jj 
#1561417928
javac parser/langX.java 
#1561417932
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561417997
javacc parser/langX+++.jj 
#1561418058
javac parser/langX.java 
#1561418068
javacc parser/langX+++.jj 
#1561418070
javac parser/langX.java 
#1561418503
javacc parser/langX+++.jj 
#1561418505
javac parser/langX.java 
#1561418508
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561418575
javacc parser/langX+++.jj 
#1561418576
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561418579
javac parser/langX.java 
#1561418581
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561418707
javacc parser/langX+++.jj 
#1561418709
javac parser/langX.java 
#1561418712
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561418825
javacc parser/langX+++.jj 
#1561418827
javac parser/langX.java 
#1561418831
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419310
javacc parser/langX+++.jj 
#1561419312
javac parser/langX.java 
#1561419315
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419393
javacc parser/langX+++.jj 
#1561419395
javac parser/langX.java 
#1561419398
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419427
javacc parser/langX+++.jj 
#1561419429
javac parser/langX.java 
#1561419432
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419470
javacc parser/langX+++.jj 
#1561419472
javac parser/langX.java 
#1561419475
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419503
javacc parser/langX+++.jj 
#1561419505
javac parser/langX.java 
#1561419508
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419522
javacc parser/langX+++.jj 
#1561419524
javac parser/langX.java 
#1561419527
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419555
javacc parser/langX+++.jj 
#1561419557
javac parser/langX.java 
#1561419560
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419655
javacc parser/langX+++.jj 
#1561419657
javac parser/langX.java 
#1561419659
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419681
javacc parser/langX+++.jj 
#1561419683
javac parser/langX.java 
#1561419685
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419702
javacc parser/langX+++.jj 
#1561419703
javac parser/langX.java 
#1561419706
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419750
javacc parser/langX+++.jj 
#1561419752
javac parser/langX.java 
#1561419755
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561419953
javacc parser/langX+++.jj 
#1561419955
javac parser/langX.java 
#1561420027
javacc parser/langX+++.jj 
#1561420029
javac parser/langX.java 
#1561421608
javacc parser/langX+++.jj 
#1561421610
javac parser/langX.java 
#1561428443
javacc parser/langX+++.jj 
#1561428445
javac parser/langX.java 
#1561428542
javacc parser/langX+++.jj 
#1561428543
javac parser/langX.java 
#1561428637
javacc parser/langX+++.jj 
#1561428638
javac parser/langX.java 
#1561428649
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561429719
git reset --soft HEAD~1
#1561429723
git status
#1561429737
code .
#1561429778
cd probabilit_and_statistics/
#1561429780
ll
#1561429783
cd probabilidade-e-estatistica/
#1561429785
ll
#1561429790
cd aulas/
#1561429791
ll
#1561429794
cd ..
#1561429798
ll
#1561429800
cd exercícios/
#1561429801
ll
#1561429806
cd ..
#1561429809
ll
#1561429814
cd tecnicas_estatisticas_de_predicao/
#1561429815
ll
#1561429820
cd curso_predicao_usp/
#1561429821
ll
#1561429842
rm -r A_M10_U10_2_WA1.tar.xz 'Regressão Linear Múltipla - Introdução_HD.mp4'*
#1561429845
ll
#1561429852
git status
#1561429857
git add --all
#1561429868
git commit -m "refactor"
#1561429874
git push origin master 
#1561429890
git pull origin master 
#1561429915
ll
#1561429926
rm -r A_M10_U10_2_WA1.tar.xz 'Regressão Linear Múltipla - Introdução_HD.mp4'*
#1561429933
du .
#1561429939
du -h .
#1561429957
git status
#1561429964
git add --all
#1561429979
git reset --soft HEAD~1
#1561429981
ll
#1561429986
cd ..
#1561429988
ll
#1561430007
git add --all
#1561430011
git commit -m "refactor"
#1561430014
git pull origin master 
#1561430055
git push origin master 
#1561430459
java parser.langX -print_tree testes_e_logs/teste_com_erro_classbody.x 
#1561430067
git push origin master --force
#1561430919
git reset --soft HEAD~1
#1561430921
ll
#1561430924
git status
#1561430929
git reset --soft HEAD~1
#1561430932
git reset --soft HEAD~2
#1561430935
git status
#1561430957
git reset --soft HEAD~4
#1561430972
git merge --abort
#1561430976
git reset --soft HEAD~4
#1561430985
git status
#1561431046
git reset -HEAD 
#1561431052
git status
#1561431057
cd ..
#1561431059
ll
#1561431064
cd ..
#1561431075
cd data-science/
#1561431079
git status
#1561431089
git add --all
#1561431098
git commit -m "refactor"
#1561431104
git push origin master 
#1561431120
git push origin master --force
#1561431404
git reset --soft HEAD~4
#1561431406
ll
#1561431458
git status
#1561431474
git add --all
#1561431487
git commit -m "refactor"
#1561431494
git push origin master --force
#1561431942
git add --all
#1561431944
git commit -m "refactor"
#1561431946
git push origin master --force
#1561432098
git add --all
#1561432101
git commit -m "refactor"
#1561432103
git push origin master --force
#1561432302
git add --all
#1561432308
git commit -m "refactor"
#1561432311
git push origin master --force
#1561432805
cd ..
#1561432991
cd projetos/
#1561432994
cd compiladores/
#1561432995
ll
#1561433002
cd trabalho_parte_03-arvore_sintatica/
#1561433002
ll
#1561434444
git status
#1561434463
git diff parser/langX+++.jj
#1561434483
git add --all
#1561434513
git commit -m "tree: handler variables"
#1561434517
git push origin ma
#1561434518
git push origin master 
#1561434733
ll
#1561434734
cd parser/
#1561434735
l
#1561434747
rm -r 'langX$LookaheadSuccess.class' 'langX$JJCalls.class'
#1561434808
cd ..
#1561434810
code .
#1561434899
javacc parser/langX+++.jj 
#1561435088
javac parser/langX.java 
#1561435100
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561435343
javacc parser/langX+++.jj 
#1561435356
javac parser/langX.java 
#1561435359
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561435397
javac parser/langX.java 
#1561435400
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561435417
code .
#1561435615
javacc parser/langX+++.jj 
#1561435635
javac parser/langX.java 
#1561435639
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561435994
javacc parser/langX+++.jj 
#1561435995
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561435997
javac parser/langX.java 
#1561435999
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561436577
ll
#1561436710
javacc parser/langX+++.jj 
#1561436712
javac parser/langX.java 
#1561436716
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561437110
javacc parser/langX+++.jj 
#1561437112
javac parser/langX.java 
#1561437115
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561437612
javacc parser/langX+++.jj 
#1561437614
javac parser/langX.java 
#1561437618
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561437645
javacc parser/langX+++.jj 
#1561437647
javac parser/langX.java 
#1561437650
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561437823
javacc parser/langX+++.jj 
#1561437852
javac parser/langX.java 
#1561437936
javacc parser/langX+++.jj 
#1561437938
javac parser/langX.java 
#1561437941
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438069
javacc parser/langX+++.jj 
#1561438071
javac parser/langX.java 
#1561438074
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438276
javacc parser/langX+++.jj 
#1561438278
javac parser/langX.java 
#1561438299
javacc parser/langX+++.jj 
#1561438300
javac parser/langX.java 
#1561438303
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438327
javacc parser/langX+++.jj 
#1561438328
javac parser/langX.java 
#1561438331
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438642
javacc parser/langX+++.jj 
#1561438644
javac parser/langX.java 
#1561438646
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438664
javacc parser/langX+++.jj 
#1561438667
javac parser/langX.java 
#1561438670
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561438727
git status
#1561458142
cd ..
#1561458144
ll
#1561458145
cd ..
#1561458251
cd artificial_inteligence/
#1561458252
ll
#1561458257
cd data-science/
#1561458275
cd ..
#1561458284
source venv_global/bin/activate
#1561458321
code .
#1561458563
cat /etc/lsb-release
#1561458569
lsb_reaslease
#1561458573
lsb_release 
#1561458600
sudo apt install lsb_release
#1561458606
lsb_release 
#1561458622
sudo apt install LSB
#1561458796
systemctl --status docker
#1561458815
systemctl docker
#1561458831
systemctl --statedocker
#1561458834
systemctl --state docker
#1561458845
systemctl state docker
#1561458856
systemctl start docker
#1561458861
ll
#1561458864
systemctl state docker
#1561458866
systemctl --state docker
#1561458878
systemctl enable docker
#1561458889
systemctl state docker
#1561459865
cd artificial_inteligence/data-science/steps_data_science/src/environment/
#1561459866
ll
#1561459885
sudo docker build dockfile
#1561459894
sudo docker build dockerfile
#1561459924
mkdir docker
#1561459936
mv dockerfile docker/
#1561459939
cd docker/
#1561459939
ll
#1561459950
sudo docker build .
#1561460039
ll
#1561460079
sudo docker build .
#1561460737
ll
#1561460771
sudo docker build --no-cache .
#1561460779
doscker ps
#1561460784
docker ps
#1561460788
sudo docker ps
#1561460792
sudo docker image
#1561460798
sudo docker iages
#1561460801
sudo docker images
#1561460831
sudo docker prune 00fc7c7ddfd9 afb58ce7f455 34a518642c76 029fd3e52059
#1561460853
sudo docker prune 00fc7c7ddfd9
#1561460858
sudo docker --help
#1561460891
sudo docker -rm 00fc7c7ddfd9 afb58ce7f455 34a518642c76 029fd3e52059
#1561460899
sudo docker rm 00fc7c7ddfd9 afb58ce7f455 34a518642c76 029fd3e52059
#1561460909
docker images
#1561460914
sudo docker images
#1561460929
sudo docker rm 00fc7c7ddfd9 
#1561460948
sudo docker rm --0help
#1561460950
sudo docker rm --help
#1561460967
sudo docker --help
#1561461011
sudo docker rmi 00fc7c7ddfd9 afb58ce7f455 34a518642c76 029fd3e52059
#1561461025
sudo docker images
#1561461035
sudo docker rmi 029fd3e52059
#1561461040
sudo docker rmi 029fd3e52059 --force
#1561461043
sudo docker images
#1561461053
sudo docker build .
#1561461398
cat ../../requirements.txt
#1561461442
sudo docker images
#1561461458
sudo docker rmi d07325fdd807 34a518642c76
#1561461463
sudo docker build .
#1561461725
cat ../../../requirements.txt 
#1561462281
sudo docker images
#1561462294
sudo docker rmi 1f958b47386e 34a518642c76
#1561462297
cat ../../../requirements.txt 
#1561462301
sudo docker build .
#1561462523
cat /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/requirements.txt
#1561470518
cd projetos/
#1561470520
cd compiladores/
#1561470521
ll
#1561470539
git status
#1561470545
git add --all
#1561470569
git commit -m "syntatic tree- variables"
#1561470573
git push origin master 
#1561470704
ll
#1561470713
cd trabalho_parte_03-arvore_sintatica/
#1561470715
code .
#1561470745
javacc parser/langX+++.jj 
#1561470749
javac parser/langX.java 
#1561470906
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561470913
code .
#1561470920
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561471309
cd ..
#1561471315
cd artificial_inteligence/data-science/
#1561471316
ll
#1561471322
cd ..
#1561471323
cd .
#1561471324
cd ..
#1561471331
source venv_global/bin/activate
#1561471407
cd artificial_inteligence/data-science/
#1561471408
kk
#1561471409
ll
#1561471411
cd ..
#1561509992
cd artificial_inteligence/data-science/
#1561509993
ll
#1561510001
cd steps_data_science/
#1561510006
git clone https://github.com/tanujjain/deploy-ml-model.git
#1561471421
jupyter-notebook 
#1561510111
cd challenges/
#1561510111
ll
#1561510115
cd challenge-aawz/
#1561510116
ll
#1561510119
git status
#1561510128
git add --all
#1561510146
git commit -m "feat: create environment"
#1561510149
git push origin master 
#1561510167
git pull origin master 
#1561510173
code .
#1561510207
git add --all
#1561510221
git commit -m "feat: add environment"
#1561510227
git push origin master 
#1561510445
/usr/bin/python3 /home/campos/projetos/challenges/challenge-aawz/src/environment/test_environment.py
#1561510467
code .
#1561511167
/usr/bin/python3 /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src/environment/test_environment.py
#1561510578
python3
#1561513460
cd ..
#1561513461
l
#1561513469
cd challenge-indicium/
#1561513469
ll
#1561513472
code .
#1561513508
code .
#1561513641
/usr/bin/python3 /home/campos/projetos/challenges/challenge-indicium/src/environment/prepare_env.py
#1561513675
cd ..
#1561513676
ll
#1561513681
cd challenge-aawz/
#1561513682
code .
#1561513695
cd ..
#1561513697
ll
#1561513704
cd challenge-keyrus/
#1561513706
code .
#1561513761
cd ..
#1561513762
ll
#1561513768
cd kaggle/
#1561513769
ll
#1561513771
code .
#1561513857
cd ..
#1561513857
ll
#1561513870
cd challenge-indicium/
#1561513871
ll
#1561513874
git status
#1561513882
git add --all
#1561513886
git push origin master 
#1561513893
git pull origin master 
#1561513918
git push origin master 
#1561513924
git add --all
#1561513933
git commit -m "refactor"
#1561513936
git push origin master 
#1561568551
cd projetos/
#1561568552
ll
#1561568561
cha
#1561568565
cd challenges/
#1561568566
ll
#1561568571
cd challenge-aawz/
#1561568572
ll
#1561568575
git status
#1561568578
git add--all
#1561568583
git commit -m "refactor"
#1561568588
git push origin master 
#1561568633
git add--all
#1561568639
git add --all
#1561568642
git commit -m "refactor"
#1561568644
git push origin master 
#1561568659
cd ..
#1561568660
ll
#1561568670
cd challenge-indicium/
#1561568671
ll
#1561568673
git status
#1561568686
cd ..
#1561568687
ll
#1561568697
cd kaggle/
#1561568699
ll
#1561568701
cd allstate-claims-severity/
#1561568703
ll
#1561568707
git status
#1561568725
git add --all
#1561568735
git commit -m "refactor"
#1561568739
git push origin master 
#1561568770
git pull origin master 
#1561568777
code .
#1561568858
cd ..
#1561568862
code .
#1561569334
cd kaggle/allstate-claims-severity/
#1561569335
ll
#1561569338
git status
#1561569342
git add --all
#1561569348
git commit -m "refactor"
#1561569352
git push origin master 
#1561569479
code .
#1561569558
cd ..
#1561569561
cd porto-seguro-safe-driver-prediction/
#1561569561
ll
#1561569563
code .
#1561569590
cd ..
#1561569592
code .
#1561569819
cd ..
#1561569820
code .
#1561595314
ll
#1561595318
cd projetos/
#1561595319
ll
#1561595331
cd challenges/
#1561595332
ll
#1561595336
code .
#1561642678
cd kaggle/
#1561642679
ll
#1561642681
cd allstate-claims-severity/
#1561642681
ll
#1561642684
git status
#1561642692
git add --all
#1561642696
git commit -m "refactor"
#1561642699
git push origin master 
#1561642712
cd ..
#1561642713
ll
#1561642715
cd porto-seguro-safe-driver-prediction/
#1561642716
ll
#1561642722
git status
#1561642733
git add --all
#1561642757
git commit -m "refactor"
#1561642762
git push origin master 
#1561645190
cd ..
#1561645191
ll
#1561645192
cd ..
#1561645194
lll
#1561645195
ll
#1561645206
cd ar
#1561645213
cd arduino-e-hardware/
#1561645213
ll
#1561645215
code .
#1561645262
cd ..
#1561645263
code .
#1561645367
cd arduino-e-hardware/
#1561645368
ll
#1561645441
git init
#1561645445
git add --all
#1561645511
git remote add origin git@github.com:brunocampos01/arduino_and_hardware.git
#1561645517
git remote -V
#1561645520
git remote -v
#1561645529
git pull origin ma
#1561645532
git pull origin master
#1561645539
git stauts
#1561645541
ll
#1561645556
git commit -m "intial commit"
#1561645562
git push origin master
#1561652805
cd ..
#1561652806
ll
#1561652811
cd analysing/
#1561652812
ll
#1561652815
git status
#1561652823
git remote -v
#1561652882
du .
#1561652888
du -h .
#1561652894
cd ..
#1561652895
ll
#1561660439
cd projetos/
#1561660440
kk
#1561660441
ll
#1561663579
cd cd web_development/
#1561663580
ll
#1561663583
cd web_development/
#1561663583
ll
#1561663587
git status
#1561663589
cd ..
#1561663590
ll
#1561663596
cd sistemas-operacionais/
#1561663596
çç
#1561663598
ll
#1561663603
code .
#1561663680
git init
#1561663688
git add --all
#1561663713
git coomit -m "initial commit"
#1561663720
git commit -m "initial commit"
#1561663792
git remote add origin git@github.com:brunocampos01/sistemas-peracionais.git
#1561663795
git remote -v
#1561663797
ll
#1561663802
git status
#1561663809
git pull origin master
#1561663821
git push origin master
#1561663852
git pull origin master
#1561663860
git status
#1561663864
git add --all
#1561663867
git push origin master
#1561663883
code .
#1561663896
ll
#1561663905
git push origin master --force
#1561664135
cd ..
#1561664135
ll
#1561664153
cd data-mining/
#1561664154
kk
#1561664155
ll
#1561667587
cd ..
#1561667589
ll
#1561667596
cd ..
#1561667598
ll
#1561667611
rm -r data-science/
#1561667616
rm -rf data-science/
#1561667618
ll
#1561667623
ls - lt
#1561667628
ls -lt
#1561667654
cd snap/
#1561667654
ll
#1561667662
cd ..
#1561667663
ll
#1561667680
cat .viminfo 
#1561678464
ll
#1561678476
cd projetos/
#1561678476
ll
#1561678484
cd desenvolvimento-de-sistemas/
#1561678485
ll
#1561678496
git status
#1561678502
cd ..
#1561678502
ll
#1561678544
source venv_global/bin/activate
#1561678546
ll
#1561678603
cd challenges/
#1561678605
ll
#1561678643
cd ..
#1561678653
jupyter-notebook --port=8888
#1561679618
htop
#1561678670
jupyter-notebook --port=8833
#1561723812
ll
#1561724247
cd projetos/seguranca/
#1561724248
ll
#1561724253
cd trabalho_02_implementacao/
#1561724253
ll
#1561724266
cd projetos/seguranca/trabalho_02_implementacao/
#1561724267
ll
#1561724326
cd protocolSTS/src/Server/
#1561724327
ll
#1561724480
cd ..
#1561724481
ll
#1561724483
cd ..
#1561724484
ll
#1561724487
cd ..
#1561724488
ll
#1561724491
cd STS/
#1561724491
ll
#1561724495
pwd
#1561724502
cd /home/campos/projetos/seguranca/trabalho_02_implementacao/STS
#1561724512
ll
#1561724531
ll
#1561724520
java GreetingServer.java
#1561724536
java GreetingClient.java
#1561727037
java Servidor.java
#1561727054
java Client.java
#1561727046
java Server.java
#1561727140
cd projetos/seguranca/
#1561727140
ll
#1561727143
git status
#1561727218
git add trabalho_02_implementacao/STS/
#1561727233
git add .editorconfig 
#1561727303
git commit -m "Implementation (Station-to-Station): Socket client and server"
#1561727307
git push origin master 
#1561727974
cd Server/
#1561727975
ll
#1561727980
java MainServer.java
#1561728443
java Server.java
#1561728526
java MainServer.java
#1561728603
cd Client/
#1561728605
java Client.java
#1561728594
java Server.java
#1561729452
java MainServer.java
#1561730131
java Server.java
#1561730182
git add trabalho_02_implementacao/STS/
#1561730200
git commit -m "refactor (Station-to-Station): Socket client and server"
#1561730204
git push origin master 
#1561732671
cd /home/campos/projetos/seguranca/trabalho_02_implementacao/testeOAEPRSA
#1561732673
ll
#1561732676
cd src/
#1561732677
ll
#1561732684
java OAEPPaddedRSAExample.java
#1561732775
code .
#1561732802
cd "/home/campos/projetos/seguranca/trabalho_02_implementacao/testeOAEPRSA/src"
#1561732803
mvn archetype:generate -DarchetypeArtifactId="archetype-quickstart-jdk8" -DarchetypeGroupId="com.github.ngeor"
#1561732857
cd ..
#1561732858
ll
#1561732869
cd src/
#1561732870
ll
#1561732872
cd 1/
#1561732872
ll
#1561732882
mvn clean install
#1561732910
ll
#1561732919
cd src/
#1561732922
cd ..
#1561732924
cd target/
#1561732925
ll
#1561732933
java -jar 1-1.jar
#1561733064
cd ..
#1561733068
ll
#1561733071
cd src/
#1561733071
ll
#1561733078
javac OAEPPaddedRSAExample.java
#1561733209
cd ..
#1561733211
ant
#1561733250
ant -source 8
#1561733279
ant 
#1561733298
java -V
#1561733303
java -version
#1561733374
cd ..
#1561733377
cd STS/
#1561733378
ll
#1561733383
mvn
#1561733390
mvn --help
#1561733629
mvn -B archetype:generate -DarchetypeGroupId=STS
#1561733679
mvn compile
#1561733719
mvn -B archetype:generate -DarchetypeGroupId=STS -DgroupId=brunocampos01 -DartifactId=STS
#1561733739
code .
#1561733771
cd "/home/campos/projetos/seguranca/trabalho_02_implementacao/STS"
#1561733771
mvn archetype:generate -DarchetypeArtifactId="archetype-quickstart-jdk8" -DarchetypeGroupId="com.github.ngeor"
#1561733871
mvn compile
#1561733882
cd  artifactor/
#1561733882
ll
#1561733887
mvn compile
#1561733897
cd target/
#1561733898
ll
#1561733913
cd artifactor/target/
#1561733914
ll
#1561733919
cd ..
#1561733920
ll
#1561733930
mvn clean install
#1561733934
ll
#1561733938
cd target/
#1561733940
l
#1561733953
java -jar artifactor-1.0.jar 
#1561733961
cd ..
#1561733961
ll
#1561733965
cd ..
#1561733967
ll
#1561734083
mvn clean install
#1561734096
cd target/
#1561734097
ll
#1561734104
java -jar artifactor-1.0.jar
#1561734128
cd..
#1561734131
mvn clean install
#1561734139
cd target/
#1561734139
ll
#1561734145
java -jar artifactor-1.0.jar
#1561735205
cd ..
#1561735208
code .
#1561735388
cd ..
#1561735391
ll
#1561735395
cd protocoloSTS/
#1561735396
ll
#1561735449
cd src/main/java/Server/
#1561735450
ll
#1561735455
java Server.java
#1561735464
pwd
#1561735470
cd /home/campos/projetos/seguranca/trabalho_02_implementacao/protocoloSTS/src/main/java/Server
#1561735472
cd ..
#1561735474
ll
#1561735476
cd Client/
#1561735477
ll
#1561735481
java Client.java
#1561735485
java Server.java
#1561736041
sudo apt-get install openjdk-8-jre
#1561736091
java -version
#1561736127
sudo update-alternatives --config java
#1561736136
java -version
#1561736282
ll
#1561736284
java Server.java
#1561736296
java -version
#1561736298
java Server.java
#1561736481
sudo apt-get install openjdk-8-jdk
#1561736516
java -version
#1561736981
cd ..
#1561736982
ll
#1561736984
cd ..
#1561736986
ll
#1561736988
cd ..
#1561736990
ll
#1561736998
cd ..
#1561737003
cd ../../..
#1561737008
cd trabalho_02_implementacao/
#1561737009
ll
#1561737019
rm -rf protocoloSTS/
#1561737046
cd STS/
#1561737046
ll
#1561737051
cd Server/
#1561737052
ll
#1561737061
java Server.java
#1561737124
javac Server.java
#1561737126
java Server.java
#1561737128
ll
#1561737136
sudo update-alternatives --config java
#1561737164
cd STS/
#1561737164
ll
#1561737169
cd Client/
#1561737170
ll
#1561737174
java Client.java
#1561737142
java Server.java
#1561737253
cd protocolSTS/
#1561737254
ll
#1561737262
cd src/Server/
#1561737264
ll
#1561737269
java Server.java
#1561745303
cd ..
#1561745306
ll
#1561745309
cd
#1561745313
pwd
#1561745320
cd /home/campos/projetos/seguranca/trabalho_02_implementacao/STS
#1561745322
ll
#1561745342
java GenRSA.java
#1561745567
java GenerateRSA.java
#1561745576
ll
#1561745579
java generateRSA.java
#1561745855
keytool -genkeypair -alias mykey -storepass s3cr3t -keypass s3cr3t -keyalg RSA -keystore keystore.jks
#1561745934
java generateRSA.java
#1561746551
java Client.java
#1561750166
git status
#1561750170
git add --all
#1561750193
git commit -m "refactor (Station-to-Station): diffie-hell"
#1561750197
git push origin master 
#1561756418
ll
#1561756622
cd projetos/seguranca/trabalho_02_implementacao/
#1561756623
ll
#1561756638
cd STS/
#1561756639
ll
#1561756665
cd Server/
#1561756670
cd Client/
#1561756671
ll
#1561756674
ll
#1561756684
java Server.java
#1561757031
java Client.java
#1561795233
ll
#1561795238
cd projetos/seguranca/
#1561795239
ll
#1561795242
code .
#1561795400
cd trabalho_02_implementacao/
#1561795401
ll
#1561795405
cd STS/
#1561795405
ll
#1561795431
cd Client/
#1561795432
ll
#1561795449
cd Server/
#1561795456
java Server.java
#1561795459
java Client.java
#1561798051
cd ..
#1561798054
ll
#1561798056
git status
#1561798059
git add --all
#1561798065
git commit -m "refactor"
#1561798069
git push origin master 
#1561798081
git pull origin master 
#1561798100
code .
#1561798117
git add --all
#1561798120
git commit -m "refactor"
#1561798123
git push origin master 
#1561798419
ll
#1561798423
cd code .
#1561798431
code .
#1561798543
cd
#1561798546
cd projetos/
#1561798546
ll
#1561798554
source venv_global/bin/activate
#1561798556
ll
#1561798565
cd
#1561798566
cd projetos/
#1561798567
kk
#1561798568
ll
#1561800610
cd artificial_inteligence/data-science/
#1561800610
ll
#1561800613
git status
#1561800615
git add --all
#1561800659
git commit -m "refactor"
#1561800664
git push origin master 
#1561800674
git pull origin master 
#1561800681
git push origin master 
#1561800824
git add --all
#1561800827
git commit -m "refactor"
#1561800829
git push origin master 
#1561801009
git add --all
#1561801011
git commit -m "refactor"
#1561801013
git push origin master 
#1561801083
git add --all
#1561801085
git commit -m "refactor"
#1561801088
git push origin master 
#1561801201
git add --all
#1561801203
git commit -m "refactor"
#1561801206
git push origin master 
#1561810161
cd ..
#1561810168
cd challenges/challenge-keyrus/
#1561810168
ll
#1561810175
coide .
#1561810178
code .
#1561811698
git add --all
#1561811723
git commit -m "refactor: Apply sugestion"
#1561811727
git push origin master 
#1561811734
git pull origin master 
#1561811744
git push origin master 
#1561813243
cd ..
#1561813244
ll
#1561813249
cd ..
#1561813250
code .
#1561813637
sudo apt autoclean
#1561813645
sudo apt autoremove 
#1561813678
docker ps
#1561813682
sudo docker ps
#1561813691
sudo docker images
#1561813781
cd /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src/environment/
#1561813782
ll
#1561813812
sudo docker rmi 34a518642c76
#1561813826
sudo docker rmi 7a44a988555b
#1561813829
sudo docker rmi 34a518642c76
#1561813841
sudo docker images
#1561813851
sudo docker build
#1561813856
sudo docker build .
#1561813880
sudo docker run
#1561813904
sudo docker build .
#1561813945
sudo docker run .
#1561813955
docker run .
#1561813967
docker run python3
#1561814001
ll
#1561814015
rm -r docker/
#1561814018
ll
#1561814021
docker run .
#1561814027
sudo docker build .
#1561814441
sudo docker images
#1561814453
sudo docker run 34a518642c76
#1561814460
sudo docker ps
#1561814510
sudo docker build .
#1561814867
sudo docker -f build .
#1561814873
sudo docker build . -f
#1561814900
docker build -f ../Dockerfile .
#1561814913
cd ..
#1561815000
ll
#1561815012
sudo docker build -f ../Dockerfile .
#1561815188
sudo docker build -f .
#1561815199
cd src/environment/
#1561815201
sudo docker build -f .
#1561815204
sudo docker build .
#1561815602
sudo docker images
#1561815621
sudo docker run e07c4833bbae
#1561798561
jupyter-notebook 
#1561904175
cd projetos/
#1561904175
ll
#1561904370
cd compiladores/
#1561904371
ll
#1561904514
cd ..
#1561904519
cd artificial_inteligence/
#1561904521
cd ..
#1561904809
cd artificial_inteligence/data-science/
#1561904809
ll
#1561904813
cd steps_data_science/
#1561904814
ll
#1561904817
cd src/
#1561904818
ll
#1561904821
cd environment/
#1561904822
ll
#1561904831
sudo docker imanges
#1561904842
sudo docker images
#1561904855
sudo docker -rm -r e07c4833bbae
#1561904862
sudo docker -rm e07c4833bbae
#1561904868
sudo docker -rmi e07c4833bbae
#1561904873
sudo docker rmi e07c4833bbae
#1561904882
sudo docker ps
#1561904906
sudo docker stop e07c4833bbae
#1561904936
sudo docker rm e07c4833bbae
#1561904941
sudo docker ps
#1561904969
sudo docker rm e07c4833bbae -f
#1561904985
sudo docker ps
#1561904999
sudo docker rm e07c4833bbae
#1561905005
sudo docker rmi e07c4833bbae
#1561905021
sudo docker stop e07c4833bbae
#1561905063
sudo docker images
#1561905079
sudo docker rmi 34a518642c76
#1561905088
sudo docker rmi e07c4833bbae
#1561905093
sudo docker rmi 449a5f585bc2
#1561905121
docker system prune
#1561905128
sudo docker system prune
#1561905146
sudo docker images -a
#1561905161
docker images -f dangling=true
#1561905166
sudo docker images -f dangling=true
#1561905179
sudo docker images purge
#1561905187
sudo docker images
#1561905198
sudo docker rmi e07c4833bbae
#1561905220
sudo docker images -a
#1561905229
sudo docker rmi $(docker images -a -q)
#1561905242
docker ps -a
#1561905246
sudo docker ps -a
#1561905258
sudo docker rm e07c4833bbae
#1561905268
sudo docker rm 3bda22e87839
#1561905299
sudo docker run --rm 3bda22e87839
#1561905314
sudo docker ps -a -f status=exited
#1561905321
sudo docker rm $(docker ps -a -f status=exited -q)
#1561905335
sudo docker volume ls
#1561905372
ll
#1561905378
sudo docker build
#1561905381
sudo docker build .
#1561906042
sudo docker build -f
#1561906336
sudo docker build -f ../Dockerfile
#1561906519
cd ..
#1561906523
sudo docker build .
#1561907049
mkdir myproject && cd myproject
#1561907051
ll
#1561907057
echo "hello" > hello
#1561907061
echo -e "FROM busybox\nCOPY /hello /\nRUN cat /hello" > Dockerfile
#1561907064
docker build -t helloapp:v1 .
#1561907068
sudo docker build -t helloapp:v1 .
#1561907079
ll
#1561907119
mkdir -p dockerfiles context
#1561907125
mv Dockerfile dockerfiles && mv hello context
#1561907136
sudo mv Dockerfile dockerfiles && mv hello context
#1561907142
sudo docker build --no-cache -t helloapp:v2 -f dockerfiles/Dockerfile context
#1561907146
ll
#1561907188
cd ..
#1561907189
ll
#1561907210
cd myproject/
#1561907211
ll
#1561907213
cd dockerfiles/
#1561907214
ll
#1561907218
cd ..
#1561907220
ll
#1561907222
cd context/
#1561907223
ll
#1561907225
cd ..
#1561907230
ll
#1561907294
sudo docker build --no-cache -t data_science -f environment/Dockerfile
#1561907298
sudo docker build --no-cache -t data_science -f environment/Dockerfile .
#1561907313
ll
#1561907361
sudo docker build --no-cache -t data_science -f environment/Dockerfile .
#1561907408
cd ..
#1561907417
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561907655
çç
#1561907657
ll
#1561907672
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561907937
jupyter notebook list
#1561907985
cat /home/USERNAME/.jupyter/jupyter_notebook_config.py
#1561908020
cat $HOME/.jupyter/jupyter_notebook_config.py
#1561908029
cat /home/campos/.jupyter/
#1561908080
jupyter notebook --generate-config
#1561908085
cat $HOME/.jupyter/jupyter_notebook_config.py
#1561908133
cat $HOME/.jupyter/jupyter_notebook_config.py | grep allow_pa
#1561908395
cat $HOME/.jupyter/jupyter_notebook_config.py | grep allow_pa
#1561908428
jupyter notebook list
#1561908449
cat $HOME/.jupyter/jupyter_notebook_config.py | grep NotebookApp.password
#1561908549
echo c.NotebookApp.password = ''
#1561908561
echo c.NotebookApp.password = '' > $HOME/.jupyter/jupyter_notebook_config.py
#1561908603
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561908922
curl
#1561908930
wget
#1561908939
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561908977
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .[
#1561908979
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561909245
sudo docker run
#1561909248
sudo docker run .
#1561909255
sudo docker images
#1561909383
sudo docker ps -a -f status=exited
#1561909395
sudo docker rm $(docker ps -a -f status=exited -q)
#1561909450
sudo docker rm b3986ece6118
#1561909467
sudo docker rm ea08e84febe0 6d2f4beafcc8 0f37407c1784 93e180f5dba4 1c59e197314d fa5d916deb6a 10fdbeb93806 bd084c7d326d 49fe0faacd54 65c2f0f1902a
#1561909474
sudo docker ps -a
#1561909508
sudo docker run --rm a2711a8a1507 3bda22e87839
#1561909269
sudo docker run 62c9fdd904d7
#1561909523
ll
#1561909573
sudo docker build --no-cache -t data_science -f src/environment/Dockerfile .
#1561909666
echo #dirname
#1561909671
echo $dirname
#1561909676
echo dirname
#1561909696
echo $(dirname $(readlink -f $0))
#1561909707
echo $(dirname)
#1561909712
echo $dirname
#1561909721
echo $readlink
#1561909736
PROJECT_DIR="$(dirname $(readlink -f $0))"
#1561909742
echo PROJECT_DIR
#1561909747
echo $PROJECT_DIR
#1561909858
dir=$(pwd -P)
#1561909863
echo $dir
#1561909956
basename "$(dirname "/from/here/to/there.txt")"
#1561909978
basename "$(dirname $($pwd))"
#1561909984
basename "$(dirname $(pwd))"
#1561910022
basename "$(pwd)"
#1561910086
name_project=$(basename "$(pwd)")
#1561910102
echo $name_project
#1561910128
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561910391
ll
#1561910400
sudo docker build ,
#1561910401
sudo docker build 
#1561910409
sudo docker build f8731d3804ee
#1561910426
sudo docker images
#1561910580
cd ..
#1561910584
git status
#1561910588
git add --all
#1561910612
git commit -m "feat: create dockerfile default"
#1561910617
git push origin master 
#1561910442
sudo docker run f8731d3804ee
#1561910932
kk
#1561910933
ll
#1561910949
cd projetos/
#1561910950
ll
#1561910973
sudo docker ps
#1561910983
duso docker images
#1561910991
sudo  docker images
#1561911017
sudo docker rmi f8731d3804ee 1eb63571a80c 62c9fdd904d7 a8adb05e396b 886fea982fd0 830c9115056a 4f5e829fe280 5782d68fd570 1b6f3a5e66f9 36cd4db274c6 be1cfcabe8e7 5e4ef6b29506 a61bf7ae2037 
#1561911021
sudo  docker images
#1561911052
sudo  docker rmi f8731d3804ee 62c9fdd904d7 2d5168d4575e 22d9fc6faf25 b48809f3623d d7b1f0d40af4 676f3f85f804 dc6d1a94ae80 0c69d041c147 27725abd19c2
#1561911056
sudo  docker images
#1561911067
sudo  docker rmi 34a518642c76
#1561911077
sudo  docker rmi e4db68de4ff2
#1561911082
sudo  docker rmi e07c4833bbae
#1561911089
sudo  docker rmi -a
#1561911093
sudo  docker rmi --all
#1561911099
sudo  docker rmi -h
#1561911125
sudo  docker rmi -f f8731d3804ee 62c9fdd904d7 04d13b732ba6 0c1d623e3e3a 4803191c3691 2c050a40d356 b77fdf29cd42 2578c64e7cf2 dd48f2669959 d03aad05fbc4 
#1561911130
sudo  docker images
#1561911151
sudo  docker rmi -f 7b678eb8ca4a ee79a0f0bf3f 9ba87a338f79 c5bf9e8a05b1 7cd8c76abb1c 1a6b847653bf cf797174fb51 f34d90f291a8 9e40edc8d466 e07c4833bbae e4db68de4ff2 34a518642c76
#1561911153
sudo  docker images
#1561911155
ll
#1561911162
cd artificial_inteligence/data-science/steps_data_science/
#1561911163
ll
#1561911179
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561911217
code .
#1561911257
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561911273
sudo docker build --no-cache --tag $name_project -f src/environment/Dockerfile .
#1561911287
ll
#1561911300
catsrc/environment/Dockerfile
#1561911303
cat src/environment/Dockerfile
#1561911310
sudo docker build --no-cache --tag $name_project -f src/environment/Dockerfile .
#1561911321
sudo docker build --no-cache --tag $name_project src/environment/Dockerfile .
#1561911346
sudo docker build --no-cache --tag $name_project -f src/environment/ .
#1561911357
sudo docker build --no-cache --tag $name_project src/environment/Dockerfile
#1561911408
name_project=$(basename "$(pwd)")
#1561911414
sudo docker build --no-cache --tag $name_project src/environment/Dockerfile .
#1561911428
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561911694
sudo docker run
#1561911828
docker run jupyter/minimal-notebook
#1561912178
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561912201
name_project=$(basename "$(pwd)")
#1561912204
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561912516
docker run jupyter/minimal-notebook
#1561913511
name_project=$(basename "$(pwd)")
#1561913516
sudo docker build --no-cache -t $name_project -f src/environment/Dockerfile .
#1561913544
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561913917
ls /$HOME/jupyter/
#1561913924
ls $HOME/jupyter/
#1561913930
ls $HOME/.jupyter/
#1561913960
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561919328
sudo socker run 37ed35d8f29a
#1561919338
sudo docker run 37ed35d8f29a
#1561919375
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561919515
sudo docker run 531fb4ba2017
#1561920032
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561920109
sudo docker run 531fb4ba2017
#1561920117
sudo docker run fad59d337b25
#1561920187
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561920295
sudo docker run 9dd6653e648d
#1561920320
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561920410
sudo docker run 5deda7cb2a17
#1561920439
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1561920528
sudo docker run 46d0739bfa14
#1561911700
sudo docker run 16b26f751f30
#1561911832
sudo docker run jupyter/minimal-notebook
#1561912519
sudo docker run jupyter/minimal-notebook
#1561927261
ll
#1561927973
sudo apt-get install openvpn
#1561927983
cd /etc/openvpn
#1561927984
ll
#1561927992
sudo wget https://downloads.nordcdn.com/configs/archives/servers/ovpn.zip
#1561928009
sudo apt-get install unzip
#1561928016
sudo unzip ovpn.zip
#1561928020
sudo rm ovpn.zip
#1561928031
cd /etc/openvpn/ovpn_udp/
#1561928033
ll
#1561928045
ls -al
#1561928086
ls -al | grep br
#1561928100
sudo openvpn br13.nordvpn.com.udp.ovpn
#1561928439
ls -al
#1561928648
sudo apt update
#1561928667
sudo apt dist-upgrade 
#1561928674
sudo apt upgrade 
#1561928682
ll
#1561928733
cat .bash_eternal_history 
#1561928806
cd /etc/openvpn/ovpn_udp/
#1561929383
cd
#1561929392
ll
#1561929403
mkdir test_git
#1561929405
cd te
#1561929407
cd test_git/
#1561929408
ll
#1561929427
export Y = 2000
#1561929432
export Y=2000
#1561929448
export Y=2014
#1561929824
crontab -e
#1561930195
code .
#1561930215
cd ..
#1561930217
cd projetos/
#1561930218
ll
#1561930236
mkdir daily_commit
#1561930240
cd daily_commit/
#1561930242
ll
#1561930246
code .
#1561930290
cd ..
#1561930292
code .
#1561930372
ll
#1561930408
git clone git@github.com:brunocampos01/learning-prolog.git
#1561930442
cd learning-prolog/
#1561930812
cd ..
#1561930818
cd daily_commit/
#1561930819
ll
#1561930824
bash prolog.sh 
#1561931181
DOW=$(date +%u)
#1561931188
echo $DOW
#1561931204
DATE=`date +%Y-%m-%d`
#1561931212
echo $DATE
#1561931265
bash prolog.sh 
#1561931276
ll
#1561931289
bash prolog.sh 
#1561931293
ll
#1561931320
bash prolog.sh 
#1561931322
ll
#1561931451
bash prolog.sh 
#1561931571
cat /home/campos/projetos/daily_commit/prolog_script-2019-06-30.pl
#1561931631
bash prolog.sh 
#1561931637
cat /home/campos/projetos/daily_commit/prolog_script-2019-06-30.pl
#1561931644
bash prolog.sh 
#1561931645
cat /home/campos/projetos/daily_commit/prolog_script-2019-06-30.pl
#1561931960
bash prolog.sh 
#1561931977
bash prolog_create_new_file.sh
#1561932486
< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-10};
#1561932533
< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-10}
#1561932546
bash prolog_create_new_file.sh
#1561932917
bash prolog_change_file.sh 
#1561933211
bash prolog_create_new_file.sh 
#1561933459
docker pull jenkins/jenkins
#1561933572
PROJECT_DIR="$(dirname $(readlink -f $0))"
#1561933576
echo -e $PROJECT_DIR
#1561933464
sudo docker pull jenkins/jenkins
#1561933594
PROJECT_DIR="$(pwd)"
#1561933596
echo -e $PROJECT_DIR
#1561933610
bash prolog_create_new_file.sh 
#1561933674
sudo docker images
#1561933699
sudo docker run ff8ec5c51385
#1561933791
docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts
#1561933860
sudo apt-get update
#1561933879
wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add -
#1561933890
deb https://pkg.jenkins.io/debian-stable binary/
#1561933914
vim /etc/apt/sources.list
#1561933950
sudo vim /etc/apt/sources.list
#1561933970
sudo apt-get update
#1561933794
sudo docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts
#1561934149
sudo apt-get install jenkins
#1561934281
ll
#1561934299
java -jar jenkins.war --httpPort=8080.
#1561934502
netstat -a -n -o | grep "8080"
#1561934586
wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war
#1561934589
ll
#1561938024
cd prolog/
#1561938025
ll
#1561938042
sudo chmod 777 prolog_append_file.sh
#1561938052
sudo chmod 777 prolog_create_new_file.sh
#1561938053
ll
#1561938072
cd ..lll
#1561938074
cd ..
#1561938074
ll
#1561938078
rm -r database_date.pl
#1561938080
ll
#1561938116
cat /home/campos/projetos/daily_commit/prolog/commits.sh
#1561938133
cd prolog/
#1561938133
ll
#1561938137
pwd
#1561938159
sudo chmod 777 commit.sh
#1561938390
DATE=$(+%Y-%m-%d)
#1561938395
DATE=$(%Y-%m-%d)
#1561938402
DATE=$(date +%Y-%m-%d)
#1561938534
echo $date
#1561938538
echo $ date
#1561938555
d=`date +%m-%d-%Y`
#1561938560
echo $d
#1561938741
printf '%(%Y-%m-%d)T\n' -1
#1561938760
DATE=$(printf '%(%Y-%m-%d)T\n' -1)
#1561938768
echo $DATE
#1561939693
cat /home/campos/projetos/daily_commit/prolog/commits.sh
#1561941136
cd ..
#1561941138
code .
#1561941238
which git
#1561941471
cd ..
#1561941482
cd learning-
#1561941484
cd learning-prolog/
#1561941485
kk
#1561941486
ll
#1561941489
git status
#1561941496
git add --all
#1561941505
git commit -m "feat"
#1561941511
git pull
#1561941516
git commit -m "feat"
#1561941524
git push origin master 
#1561941603
apt-get install openssh-server
#1561941607
sudo apt-get install openssh-server
#1561941633
sudo apt-get install openssh-client
#1561941706
sudo apt-get install ssh-client
#1561941898
git status
#1561942208
cat ~/.ssh/id_rsa
#1561942261
GIT_SSH_COMMAND="ssh -i ~/.ssh/id_rsa"
#1561942269
echo $GIT_SSH_COMMAND
#1561942278
ssh -i ~/.ssh/id_rsa
#1561942305
export GIT_SSH_COMMAND="cat ~/.ssh/id_rsa"
#1561942309
echo $GIT_SSH_COMMAND
#1561942315
cat ~/.ssh/id_rsa
#1561942374
export GIT_SSH_COMMAND=$(cat $HOME.ssh/id_rsa)
#1561942386
export GIT_SSH_COMMAND=$(cat $HOME/.ssh/id_rsa)
#1561942390
echo $GIT_SSH_COMMAND
#1561942464
cat $HOME/.ssh/id_rsa
#1561942492
cat /home/campos/.ssh/id_rsa
#1561942744
ssh -i avell
#1561942759
ssh -i $HOME/.ssh/id_rsa
#1561942932
which ssh 
#1561942994
export ssh=/usr/bin/ssh
#1561943001
echo $ssh
#1561934520
java -jar jenkins.war --httpPort=8090
#1561928816
sudo openvpn br13.nordvpn.com.udp.ovpn
#1561978716
cd projetos/compiladores/
#1561978716
ll
#1561978721
cd trabalho_parte_03-arvore_sintatica/
#1561978722
ll
#1561978855
javacc parser/langX+++.jj 
#1561978863
javac parser/langX.java 
#1561979087
cd projetos/compiladores/
#1561979088
ll
#1561979116
javacc parser/langX+++.jj 
#1561979126
javac parser/langX.java 
#1561979158
ll
#1561979167
cd trabalho_parte_03-arvore_sintatica/
#1561979171
javacc parser/langX+++.jj 
#1561979174
javac parser/langX.java 
#1561979447
javacc parser/langX+++.jj 
#1561979448
javac parser/langX.java 
#1561979476
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561979739
javacc parser/langX+++.jj 
#1561979740
javac parser/langX.java 
#1561979743
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561979792
javacc parser/langX+++.jj 
#1561979794
javac parser/langX.java 
#1561979797
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561979877
cd ..
#1561979883
cd trabalho_parte_02-analisador_sintatico/
#1561979885
ll
#1561979889
javacc parser/langX+++.jj 
#1561979898
javac parser/langX.java 
#1561980170
javacc parser/langX+++.jj 
#1561980171
javac parser/langX.java 
#1561980227
javacc parser/langX+++.jj 
#1561980228
javac parser/langX.java 
#1561980637
javacc parser/langX+++.jj 
#1561980639
javac parser/langX.java 
#1561980864
javacc parser/langX+++.jj 
#1561980865
javac parser/langX.java 
#1561980881
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561980948
javacc parser/langX+++.jj 
#1561980950
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561980952
javac parser/langX.java 
#1561980956
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561981153
cd ..
#1561981158
cd trabalho_parte_03-arvore_sintatica/
#1561981205
javacc parser/langX+++.jj 
#1561981221
javac parser/langX.java 
#1561981224
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561982118
javacc parser/langX+++.jj 
#1561982120
javac parser/langX.java 
#1561982123
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561982173
javacc parser/langX+++.jj 
#1561982175
javac parser/langX.java 
#1561982179
java parser.langX testes_e_logs/teste_expressoes_logicas.x 
#1561982653
cd ..
#1561982662
cd livro_como_construir_compilador/cap07/
#1561982663
ll
#1561982667
javacc parser/langX+++.jj 
#1561982677
cd parser/
#1561982679
ll
#1561982682
cd ..
#1561982688
javacc parser/langX++.jj 
#1561982696
ll
#1561982703
cd parser/
#1561982705
javacc parser/langX++.jj 
#1561982713
javacc langX++.jj 
#1561982715
cd ..
#1561982720
javac parser/langX.java 
#1561982878
cd parser/
#1561982882
javacc langX++.jj 
#1561982884
cd ..
#1561982887
javac parser/langX.java 
#1561982920
cd parser/
#1561982922
javacc langX++.jj 
#1561982927
cd
#1561982942
cd projetos/compiladores/livro_como_construir_compilador/cap07/
#1561982943
ll
#1561982950
javac parser/langX.java 
#1561983074
java parser.langX ../ssamples/classbody2.x 
#1561983160
java parser.langX ../ssamples/methoddecl.x 
#1561983237
java parser.langX ../ssamples/SClass.x 
#1561983269
java parser.langX -print_tree ../ssamples/SClass.x 
#1561984505
cd ..
#1561984512
cd trabalho_parte_03-arvore_sintatica/
#1561984513
ll
#1561984517
javacc langX++.jj 
#1561984525
javacc parser/langX++.jj 
#1561984531
javac parser/langX.java 
#1561984547
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561984594
javacc parser/langX++.jj 
#1561984596
javac parser/langX.java 
#1561984599
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561984637
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561984695
java parser.langX ../ssamples/methoddecl.x 
#1561984715
java parser.langX -print_tree ../ssamples/SClass.x 
#1561984830
javacc parser/langX++.jj 
#1561984834
javac parser/langX.java 
#1561984837
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985285
javacc parser/langX++.jj 
#1561985287
javac parser/langX.java 
#1561985290
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985319
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985368
javacc parser/langX++.jj 
#1561985370
javac parser/langX.java 
#1561985373
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985443
javacc parser/langX++.jj 
#1561985445
javac parser/langX.java 
#1561985449
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985526
javacc parser/langX++.jj 
#1561985528
javac parser/langX.java 
#1561985530
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985559
javacc parser/langX++.jj 
#1561985561
javac parser/langX.java 
#1561985563
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985577
javacc parser/langX++.jj 
#1561985579
javac parser/langX.java 
#1561985582
java parser.langX /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561985655
java parser.langX ../ssamples/SClass.x 
#1561985674
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561986121
ll
#1561986124
cd parser/
#1561986124
ll
#1561986140
rm -r 'langX$JJCalls.class' 'langX$LookaheadSuccess.class'
#1561986144
cd ..
#1561986145
ll
#1561986189
javacc parser/langX++.jj 
#1561986193
javac parser/langX.java 
#1561986206
ll
#1561986210
cd parser/
#1561986211
ll
#1561986214
cd ..
#1561986217
ll
#1561986222
cd parser/
#1561986237
javacc langX+++.jj 
#1561986245
ll
#1561986247
cd ..
#1561986251
javac parser/langX.java 
#1561986258
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561986278
ll
#1561986285
javac parser/langX.java 
#1561986307
javacc parser/langX+++.jj 
#1561986316
javac parser/langX.java 
#1561986320
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561986358
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561986573
java parser.langX -print_tree /home/campos/projetos/compiladores/livro_como_construir_compilador/ssamples/SClass.x
#1561986691
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561986846
javacc parser/langX+++.jj 
#1561986849
javac parser/langX.java 
#1561986853
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561988014
git status
#1561988021
git add --all
#1561988177
git commit -m "feat - tree syntatic with test"
#1561988182
git push origin master 
#1561988194
git pull origin master 
#1561988354
git push origin master 
#1561988627
ll
#1561988634
javacc parser/langX+++.jj 
#1561988646
javac parser/langX.java 
#1561988689
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x 
#1561988698
code .
#1561988855
ll
#1561988860
cd testes_e_logs/
#1561988861
ll
#1561988874
java parser.langX -print_tree teste_expressoes_logicas.x 
#1561988883
java ../parser.langX -print_tree teste_expressoes_logicas.x 
#1561988891
cd ..
#1561988904
cd ..
#1561988904
ll
#1561988906
cd ..
#1561988907
ll
#1561988911
cd trabalho_parte_02-analisador_sintatico/
#1561988912
ll
#1561988914
cd testes_e_logs/
#1561988917
ll
#1561988937
java ../parser.langX -print_tree teste_expressoes_logicas.x > log_sem_erro.txt
#1561989084
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1561989099
sudo java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1561989115
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1561989130
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561989140
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x >> log_sem_erro.txt
#1561989253
java parser.langX -print_tree testes_e_logs/debugAS.x 
#1561989290
java parser.langX -print_tree testes_e_logs/debugAS.x > log_debugA.txt
#1561989313
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x >> log_teste_expressoes_logicas.txt
#1561989315
ll
#1561989745
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x >> log_teste_expressoes_logicas.txt
#1561989750
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561989824
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561990497
cd ..
#1561990497
ll
#1561990502
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561990512
cd testes_e_logs/
#1561990513
ll
#1561990524
cat log_sem_erro.txt
#1561990569
rm -r teste_com_erro_classbody.x teste_expressoes_logicas.x
#1561990575
cd ..
#1561990609
ll
#1561990612
cd testes_e_logs/
#1561990612
ll
#1561990637
cd testes_e_logs/
#1561990638
pwd
#1561990644
cp *.x /home/campos/projetos/compiladores/trabalho_parte_02-analisador_sintatico/testes_e_logs 
#1561990654
ll
#1561990656
cd ..
#1561990662
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561991165
javacc parser/langX++.jj 
#1561991171
ll
#1561991191
javacc parser/langX+++.jj 
#1561991201
javac parser/langX.java 
#1561991207
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561991343
javacc parser/langX+++.jj 
#1561991345
javac parser/langX.java 
#1561991349
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561991416
javacc parser/langX+++.jj 
#1561991417
javac parser/langX.java 
#1561991420
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561991775
javacc parser/langX+++.jj 
#1561991858
javac parser/langX.java 
#1561991861
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561991931
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1561992005
javacc parser/langX+++.jj 
#1561992010
javac parser/langX.java 
#1561992036
javacc parser/langX+++.jj 
#1561992037
javac parser/langX.java 
#1561992172
javacc parser/langX+++.jj 
#1561992173
javac parser/langX.java 
#1561992189
javacc parser/langX+++.jj 
#1561992190
javac parser/langX.java 
#1561992251
javacc parser/langX+++.jj 
#1561992252
javac parser/langX.java 
#1561992296
javacc parser/langX+++.jj 
#1561992297
javac parser/langX.java 
#1561992393
javacc parser/langX+++.jj 
#1561992395
javac parser/langX.java 
#1561992401
java parser.langX testes_e_logs/teste_expressoes_logicas.x
#1561992408
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561992476
java parser.langX -debug_AS testes_e_logs/debugAS.x
#1561992485
java parser.langX -debug_AS testes_e_logs/teste_com_erro_classbody.x
#1561992557
code .
#1561992897
javacc parser/langX+++.jj 
#1561992901
javac parser/langX.java 
#1561992963
javacc parser/langX+++.jj 
#1561992965
javac parser/langX.java 
#1561992970
java parser.langX -debug_AS testes_e_logs/teste_com_erro_classbody.x
#1561992976
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561993293
ll testes_e_logs/
#1561993308
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x > log_sem_erro.txt
#1561993352
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x > log_sem_erro_debug.txt
#1561993370
java parser.langX -debug_AS testes_e_logs/teste_com_erro_classbody.x > log_erro_debug.txt
#1561993403
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561993766
code .
#1561993878
ll
#1561993902
cd ..
#1561993936
zip -r trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1561993938
ll
#1561993964
mv trabalho_ic2.zip trabalho_parte_02-analisador_sintatico/
#1561993969
cd trabalho_parte_02-analisador_sintatico/
#1561993970
ll
#1561994223
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561996665
git add --all
#1561996699
git commit -m "refactor: mode debug in test"
#1561996704
git push origin master 
#1561999185
javacc parser/langX+++.jj 
#1561999191
cd ..
#1561999192
javacc parser/langX+++.jj 
#1561999196
javac parser/langX.java 
#1561999202
java parser.langX -debug_AS testes_e_logs/teste_expressoes_logicas.x
#1561999262
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561999336
javacc parser/langX+++.jj 
#1561999338
javac parser/langX.java 
#1561999341
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561999360
javacc parser/langX+++.jj 
#1561999363
javac parser/langX.java 
#1561999365
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561999467
javacc parser/langX+++.jj 
#1561999468
javac parser/langX.java 
#1561999470
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1561999679
javacc parser/langX+++.jj 
#1561999681
javac parser/langX.java 
#1561999684
javacc parser/langX+++.jj 
#1561999687
javac parser/langX.java 
#1561999689
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1562004262
ll
#1562004264
cd ..
#1562004265
ll
#1562004267
cd ..
#1562004269
ll
#1562016713
cd algoritms/
#1562016714
ll
#1562016718
git status
#1562016722
code .
#1562016735
cd ..
#1562016735
ll
#1562016741
cd ar
#1562016745
cd artificial_inteligence/
#1562016746
ll
#1562016749
cd data-science/
#1562016749
ll
#1562016755
git status
#1562016760
git add --all
#1562016777
git commit -m "container"
#1562016781
git push origin master 
#1562016790
cd ..
#1562016791
kk
#1562016792
ll
#1562016798
cd projects/
#1562016798
ll
#1562016801
cd analise_despesas_senadores/
#1562016802
ll
#1562016804
git status
#1562016808
code .
#1562016859
git add --all
#1562016867
git commit -m "refactor"
#1562111463
cd projetos/
#1562111464
ll
#1562111595
cd devops/
#1562111596
ll
#1562111600
git status
#1562111607
git add --all
#1562111623
git commit -m "docker"
#1562111627
git push origin master 
#1562111638
cd ..
#1562111655
cd challenges/ke
#1562111663
cd challenges/kaggle/
#1562111664
ll
#1562111668
cd allstate-claims-severity/
#1562111669
ll
#1562111671
cd ..
#1562111677
cd porto-seguro-safe-driver-prediction/
#1562111679
ll
#1562111682
git status
#1562111823
cd ..
#1562111828
kk
#1562111829
ll
#1562111833
cd artificial_inteligence/
#1562111833
kk
#1562111835
ll
#1562111837
cd projects/
#1562111838
kk
#1562111839
ll
#1562111846
cd analise_despesas_senadores/
#1562111847
ll
#1562111851
git status
#1562111859
cd ..
#1562111860
ll
#1562111865
cd ..
#1562111869
cd data-science/
#1562111870
ll
#1562111873
git status
#1562111875
cd ..
#1562111879
ll
#1562111886
cd compiladores/
#1562111889
cd ..
#1562111906
cd personal_config/
#1562111908
ll
#1562111910
git status
#1562111915
git diff
#1562111950
git add --all
#1562111690
git push origin master 
#1562155326
cd ..
#1562155326
ll
#1562155329
cd allstate-claims-severity/
#1562155338
cd ..
#1562155352
source venv_global/bin/activate
#1562155503
code .
#1562156395
cd ..
#1562156406
cd artificial_inteligence/data-science/
#1562156407
code .
#1562156807
cd steps_data_science/src/environment/
#1562156809
ll
#1562156814
make
#1562156821
make requirements 
#1562160132
cd ..
#1562160134
code .
#1562160465
cd
#1562162491
cd projetos/data-mining/
#1562162495
code .
#1562166543
nmap
#1562166555
sudo apt  install nmap
#1562166586
nmap http://ptolomeu.io/
#1562166596
nmap -h
#1562166711
nmap http://ptolomeu.io/
#1562166719
host http://ptolomeu.io/
#1562166729
ping http://ptolomeu.io/
#1562166732
ping http://ptolomeu.io
#1562166737
ping ptolomeu.io
#1562166753
nmap ptolomeu.io
#1562166952
nmap -3306 ptolomeu.io
#1562166959
nmap -p3306 ptolomeu.io
#1562167050
ssh admin@ptolomeu.io
#1562167149
mysql -u admin -h ptolomeu.io -p3306
#1562167160
mysql -u admin -h ptolomeu.io -p
#1562167179
mysql -u admin -h ptolomeu.com.br -p
#1562167193
mysql -u admin -h ptolomeddddu.com.br -p
#1562170353
mysql -u admin -h ptolomeu.io -p
#1562170384
nmap ptolomeu.io
#1562160477
jupyter-notebook 
#1562155359
jupyter-notebook 
#1562170895
ll
#1562170926
cd projetos/challenges/kaggle/
#1562170927
ll
#1562170929
cd allstate-claims-severity/
#1562170930
ll
#1562170934
git status
#1562170938
git add --all
#1562170981
git commit -m "feat: new structure to notebooks"
#1562170986
git push origin master 
#1562173239
mysql -u root -h ptolomeu.io -p
#1562173247
mysql -u root -h ptolomeu.io
#1562173255
mysql -u admin -h ptolomeu.io
#1562173455
mysql -u root -h ptolomeu.io -proot
#1562173552
nmap -3306 ptolomeu.io
#1562173558
nmap -p3306 ptolomeu.io
#1562173646
nmap -v -p3306 ptolomeu.io
#1562173689
nmap -sT ptolomeu.io
#1562173723
nmap --script=mysql-ifo ptolomeu.io
#1562173729
nmap --script=mysql-info ptolomeu.io
#1562173814
nmap --script=mysql-users ptolomeu.io
#1562173862
nmap --script=mysql-users ptolomeu.io --script-args mysqluser=root,mysqlpass=toor
#1562173895
nmap -p3306 ptolomeu.io --script=mysql-info
#1562173917
nmap -p3306 ptolomeu.io --script=mysql-databases
#1562173931
nmap -p3306 ptolomeu.io --script=mysql-users
#1562173948
nmap -p3306 ptolomeu.io --script=mysql-users --script-args mysqluser=root,mysqlpass=toor
#1562173980
mysql -u root -h ptolomeu.io -ptoor
#1562174066
nmap -p3306 ptolomeu.io --script=mysql-databases
#1562174141
mysql -u root -h ptolomeu.io
#1562174635
cd ..
#1562174642
cd ..
#1562176628
nmap -p3306 ptolomeu.io --script=mysql
#1562176633
nmap -p3306 ptolomeu.io
#1562176640
nmap ptolomeu.io
#1562237853
ll
#1562241896
cd projetos/
#1562241898
ll
#1562241919
cd challenges/
#1562241919
ll
#1562241923
cd ..
#1562241930
cd challenges/
#1562241930
ll
#1562241940
cd challenge-aawz/
#1562241942
ll
#1562242162
cd ..
#1562242163
ll
#1562242364
source ../venv_global/bin/activate
#1562242419
cd ..
#1562242423
cd artificial_inteligence/
#1562242424
code .
#1562251079
ping www.google.com
#1562266225
cd ..
#1562266245
cd challenges/kaggle/
#1562266245
ll
#1562266248
cd allstate-claims-severity/
#1562266248
ll
#1562266253
git status
#1562266271
git add --all
#1562267273
cd ..
#1562267281
cd artificial_inteligence/
#1562267283
cd data-science/
#1562267284
ll
#1562267289
code .
#1562242369
jupyter-notebook 
#1562329377
cd projetos/
#1562329379
ll
#1562331112
code .
#1562331289
sudo docker pull jupyter/all-spark-notebook
#1562332710
sudo docker run -it --rm -p 8888:8888 -p 4040:4040 -v ~:/home/jovyan/workspace jupyter/all-spark-notebook
#1562333483
sudo docker images
#1562333521
sudo docker rmi 46d0739bfa14
#1562333529
sudo docker rm 46d0739bfa14
#1562333554
sudo docker rmi e4ddd8fe8654 95bf220e341a 34a518642c76 ff8ec5c51385 16b26f751f30 
#1562333672
sudo docker rmi $(docker images -a -q)
#1562333681
sudo docker rmi $(sudo docker images -a -q)
#1562333693
sudo docker images
#1562333713
sudo docker ps
#1562333747
sudo docker container 
#1562333752
sudo docker container ls
#1562333761
docker ps -a
#1562333767
sudo docker ps -a
#1562333843
sudo docker ps
#1562333845
sudo docker ps -a
#1562333966
sudo docker rm $(sudo docker ps -a)
#1562333972
sudo docker ps -a
#1562333979
sudo docker ps
#1562333981
sudo docker ps -a
#1562334056
cd artificial_inteligence/data-science/
#1562334056
ll
#1562334090
sudo docker rm | grep sudo docker ps -a
#1562334119
grep sudo docker ps -a | grep sudo docker rm
#1562334128
sudo docker ps -a | grep sudo docker rm
#1562334216
cd steps_data_science/
#1562334217
ll
#1562334227
cd src/environment/container/
#1562334228
ll
#1562334344
sudo docker build
#1562334350
sudo docker build .
#1562334792
sudo docker ps -a
#1562335179
name_project=$(basename "$(pwd)")
#1562335188
cd ..
#1562335204
sudo docker rm $(sudo docker ps -a)
#1562335199
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562335321
sudo docker ps -a
#1562335328
sudo docker images
#1562335341
sudo docker run -p 8888:8888 container
#1562335539
sudo docker run -it -p 8888:8888 container
#1562335617
sudo docker rm $(sudo docker ps -a)
#1562335625
sudo docker rmi $(sudo docker ps -a)
#1562335637
sudo docker rmi $(sudo docker images -a)
#1562335647
sudo docker images
#1562335663
sudo docker rmi b87f95c86abb e55e2c8eb1ef 34a518642c76
#1562335676
sudo docker rmi -f 34a518642c76
#1562335680
sudo docker rmi 34a518642c76
#1562335689
sudo docker rm 34a518642c76
#1562335703
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562335844
docker run -it -p 8888:8888 bf44532c3aec
#1562335851
docker run -it -p 8888:8888 container:latest
#1562335859
sudo docker run -it -p 8888:8888 bf44532c3aec
#1562336341
sudo docker ps -a
#1562336343
sudo docker ps
#1562338157
docker rm `docker ps -aq`
#1562338379
sudo docker ps -a
#1562338392
sudo docker images
#1562338400
sudo docker commit bf44532c3aec
#1562338419
sudo docker run ubuntu apt-get install -y ping
#1562338451
sudo docker commit bf44532c3aec
#1562338464
sudo docker ps -l
#1562338475
sudo docker commit 27cc7eef5783
#1562338487
docker run -it -p 8888:8888 container:latest
#1562338491
sudo docker run -it -p 8888:8888 container:latest
#1562340514
docker rm `docker ps -aq`
#1562340519
sudo docker rm `docker ps -aq`
#1562340539
sudo docker rm $(docker ps -a)
#1562340544
sudo docker rmi $(docker ps -a)
#1562340557
sudo docker rmi $(sudo docker ps -a)
#1562340567
duso docker images
#1562340574
sudo docker images
#1562340589
sudo docker rmi 5b7cb7d6c959
#1562340606
sudo docker rmi $(sudo docker images)
#1562340612
ll
#1562340615
sudo docker images
#1562340629
sudo docker rmi $(sudo docker images -a)
#1562340641
sudo docker images
#1562340644
sudo docker images -a
#1562340668
sudo docker rmi $(sudo docker images -a -q)
#1562340673
sudo docker images -a -q
#1562340678
sudo docker rmi $(sudo docker images -a -q)
#1562340693
sudo docker images -a -q
#1562340706
sudo docker ps -a
#1562340726
sudo docker rm f41c1002f4ba 5a3a4746664d 27cc7eef5783 3d2f62e2b5c4 6705232ec881 5bec1fc3075a c8f9002070bd 811a1cff5c4f
#1562340730
sudo docker ps -a
#1562340737
sudo docker images -a -q
#1562340741
sudo docker rmi $(sudo docker images -a -q)
#1562340746
sudo docker images -a -q
#1562340793
name_project=$(basename "$(pwd)")
#1562340807
echo $name_project 
#1562340827
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562342500
sudo docker images -a
#1562342853
source /home/campos/projetos/venv_global/bin/activate
#1562342853
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pytest
#1562342989
ll
#1562343000
python3 prepare_env.py 
#1562343015
cat src/environment/create_virtual_env.sh:
#1562343046
cd ..
#1562343055
cat src/environment/create_virtual_env.sh:
#1562343057
cat src/environment/create_virtual_env.sh
#1562343064
python3 prepare_env.py 
#1562343086
python3 src/environment/prepare_env.py 
#1562345463
/bin/bash  /home/campos/projetos/artificial_inteligence/data-science/steps_data_science/src/environment/create_requirements.sh 
#1562345604
code ../.jupyter/
#1562345898
jupyter notebook --generate-config
#1562345946
jupyter notebook --help
#1562345961
jupyter notebook --list
#1562346175
pip install jupyter_contrib_nbextensions
#1562346186
pip install --user jupyter_contrib_nbextensions
#1562346473
cd artificial_inteligence/
#1562346476
cd data-science/
#1562346480
git clone https://github.com/twosigma/beakerx.git
#1562346540
pip install ipywidgets beakerx
#1562346549
pip3 install --user ipywidgets beakerx
#1562346561
jupyter-notebook 
#1562346655
cd beakerx/
#1562346656
ll
#1562346671
docker run -p 8888:8888 beakerx/beakerx
#1562347463
jupyter-notebook 
#1562347506
ll
#1562347510
cd beakerx
#1562347511
ll
#1562347520
python3 setup.py install
#1562347532
cd ..
#1562347545
code .
#1562348099
cd ..
#1562348107
cd..
#1562348163
cd challenges/challenge-aawz/
#1562348164
ll
#1562348169
cd src/
#1562348169
ll
#1562348171
cd environment/
#1562348173
ll
#1562348182
cd ..
#1562348243
cd src/environment/
#1562348243
ll
#1562348249
bash create_virtual_env.sh
#1562348257
ll
#1562348262
source venv/bin/activate
#1562348268
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562348286
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562348298
jupyter-notebook 
#1562348335
cd ..
#1562348342
pwd
#1562346675
sudo docker run -p 8888:8888 beakerx/beakerx
#1562348346
jupyter-notebook 
#1562353182
cd ..
#1562353184
ll
#1562353190
cd challenge-aawz/
#1562353191
ll
#1562353245
git status
#1562353251
git add --all
#1562353300
git commit -m "refactor: update scripts and notebooks"
#1562353303
git push origin master 
#1562353959
name_project=$(basename "$(pwd)")
#1562353966
echo $name_project
#1562353971
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562354435
sudo docker ps
#1562354442
sudo docker ps -a
#1562354573
sudo docker rmi $(sudo docker images -a -q)
#1562354586
sudo docker rmi $(sudo docker images -a)
#1562354590
sudo docker ps -a
#1562354610
sudo docker rm 7200acc89b81
#1562354200
sudo docker run $name_project
#1562354619
sudo docker rm 7200acc89b81 --force
#1562354788
sudo docker ps -a
#1562354637
sudo docker run -it -p 8888:8888 $name_project
#1562354799
sudo docker rm 58d5e23d9f3b c6f78f0c863a --force
#1562354812
git pull origin master 
#1562354832
sudo docker run -it -p 8888:8888 $name_project
#1562354956
git add --all
#1562354972
git commit -m "fix: add line in readme"
#1562354976
git push origin master 
#1562355001
sudo docker ps -a
#1562378639
cd projetos/
#1562378640
ll
#1562378642
cd challenges/
#1562378643
ll
#1562378651
cd challenge-indicium/
#1562378654
git statis
#1562378657
git status
#1562378665
git add --all
#1562378698
git commit -m "refactor: environment"
#1562378702
git push origin master 
#1562379642
cd ..
#1562379835
cd challenge-indicium/
#1562379836
ll
#1562379841
cd src/
#1562379841
ll
#1562379844
cd environment/
#1562379845
ll
#1562379856
sudo make
#1562379924
sudo make requirements 
#1562379938
sudo make test_environment 
#1562379949
sudo make clean 
#1562379956
ll
#1562379972
cd ..
#1562379985
code .
#1562380028
basename
#1562380034
$basename
#1562380042
echo $basename
#1562380663
bash create_virtual_env.sh
#1562380671
cd src/environment/
#1562380673
bash create_virtual_env.sh
#1562380678
source venv/bin/activate
#1562380685
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562380699
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562380718
cd ..
#1562380723
jupyter-notebook 
#1562383087
name_project=$(basename "$(pwd)")
#1562383092
echo $name_project
#1562383104
basename "$(pwd)"
#1562383117
basename "bruno aurelio"
#1562383124
pwd
#1562383131
basename "bruno/aurelio"
#1562383144
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562383344
sudo docker run -it -p 8888:8888 $name_project
#1562383591
jupyter-notebook 
#1562383703
git status
#1562383724
git add --all
#1562383741
git commit -m "refactor: create environment"
#1562383745
git push origin master 
#1562384305
deactivate
#1562384307
cd ..
#1562384316
cd challenge-keyrus/
#1562384316
ll
#1562384326
rm -r venv_keyrus/
#1562384333
code .
#1562384361
cd src/environment/
#1562384362
ll
#1562384363
bash create_virtual_env.sh
#1562384367
source venv/bin/activate
#1562384381
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562384397
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562384442
ll
#1562384446
cd ..
#1562384454
jupyter-notebook 
#1562386423
name_project=$(basename "$(pwd)")
#1562386425
echo $name_project
#1562386430
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562386600
sudo docker run -it -p 8888:8888 $name_project
#1562386692
sudo docker ps -a
#1562387020
deactivate
#1562387022
cd ..
#1562387026
cd kaggle/
#1562387026
ll
#1562387029
cd allstate-claims-severity/
#1562387030
ll
#1562387042
cd src/
#1562387042
ll
#1562387045
cd environment/
#1562387046
kk
#1562387047
ll
#1562387059
./create_virtual_env.sh
#1562387081
source venv/bin/activate
#1562387083
ll
#1562387097
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562387108
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562387114
jupyter-notebook 
#1562387140
cd ..
#1562396707
pip3 install kaggle --upgrade
#1562396722
pip3 install --user kaggle --upgrade
#1562396745
vim ~/.bashrc
#1562396806
source ~/.bashrc
#1562396824
kaggle config
#1562396830
kaggle config {view, set, unset}
#1562396839
kaggle
#1562397072
ll
#1562397077
cd data/
#1562397077
ll
#1562397115
kaggle competitions submit -c allstate-claims-severity -f submissions-kaggle/random_forest_submission.csv -m "second random forest"
#1562419721
kaggle competitions submit -c allstate-claims-severity -f submissions-kaggle/xgb_submission.csv -m "xgb"
#1562426894
cd ..
#1562426896
git status
#1562426900
git add --all
#1562426908
git push origin master 
#1562426943
git commit -m "refactor: add environment and new cleaning in data"
#1562426949
git push origin master 
#1562426973
git push origin master --force
#1562428513
git add --all
#1562428529
git commit -m "fix: proposal"
#1562387145
jupyter-notebook 
#1562428571
deacitvate
#1562428582
deactivate
#1562428538
git push origin master
#1562429089
git pull origin master 
#1562429364
cd ..
#1562429365
ll
#1562429368
cd porto-seguro-safe-driver-prediction/
#1562429368
ll
#1562429374
cd src/environment/
#1562429375
ll
#1562429384
./create_virtual_env.sh
#1562429406
source venv/bin/activate
#1562429410
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562429422
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562429528
jupyter-notebook 
#1562429579
cd ..
#1562432155
cd ..
#1562432158
cd porto-seguro-safe-driver-prediction/
#1562432158
ll
#1562432162
cd data/
#1562432162
ll
#1562432169
cat kaggle_submission.csv
#1562432256
ps 
#1562432258
ps aux
#1562432268
ps aux | grep pycharm
#1562432283
sudo kill -9 7447
#1562432298
sudo kill -9 31102
#1562432312
sudo kill -9 7447
#1562432319
sudo kill -9 2568
#1562432322
ps aux | grep pycharm
#1562432360
cat kaggle_submission.csv
#1562429582
jupyter-notebook 
#1562432785
git status
#1562432790
git add --all
#1562432809
git commit -m "refactor: structure"
#1562432843
deactivate
#1562432866
pwd
#1562432868
name_project=$(basename "$(pwd)")
#1562432872
echo $name_project
#1562432875
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562432816
git push origin master 
#1562433886
git reset --soft HEAD--1
#1562433891
git reset --soft HEAD~1
#1562433895
git add --all
#1562433899
git commit -m "refactor: structure"
#1562433581
sudo docker run -it -p 8888:8888 $name_project
#1562434127
jupyter-notebook 
#1562434235
source src/environment/venv/bin/activate
#1562434240
jupyter-notebook 
#1562433904
git push origin master 
#1562434452
ll
#1562434455
cd ..
#1562434456
ll
#1562434462
git reset --soft HEAD~1
#1562434465
git status
#1562434537
git add .gitignore README.md data/kaggle_submission.csv data/raw/datasets.zip data/raw/sample_submission.csv notebooks/porto_seguro_safe_driver.ipynb references/porto-seguro-vector-logo.png requirements.txt src/environment/README.md src/environment/config_environment.txt src/environment/container/.dockerignore src/environment/container/Dockerfile src/environment/create_requirements.sh src/environment/create_virtual_env.sh src/environment/jupyter_notebook_config.py src/environment/prepare_env.py src/environment/requirements.txt src/environment/show_config_environment.sh src/environment/struture_project.txt src/environment/test_environment.py notebooks/porto_seguro_safe_driver.ipynb src/environment/container/.dockerignore src/environment/requirements.txt
#1562434543
git commit -m "refactor: structure"
#1562434651
deactivate
#1562434657
sudo docker build --no-cache -t $name_project -f src/environment/container/Dockerfile .
#1562435071
sudo docker run -it -p 8888:8888 $name_project
#1562435371
sudo docker ps -a
#1562434548
git push origin master 
#1562435443
git reset --soft HEAD~1
#1562435452
git status
#1562435486
git add .gitignore README.md src/environment/test_environment.py src/environment/struture_project.txt src/environment/show_config_environment.sh src/environment/requirements.txt src/environment/prepare_env.py src/environment/jupyter_notebook_config.py src/environment/create_virtual_env.sh src/environment/create_requirements.sh src/environment/container/Dockerfile src/environment/container/.dockerignore src/environment/config_environment.txt src/environment/README.md requirements.txt
#1562435494
git add .gitignore README.md src/environment/test_environment.py src/environment/struture_project.txt src/environment/show_config_environment.sh src/environment/requirements.txt src/environment/prepare_env.py src/environment/jupyter_notebook_config.py src/environment/create_virtual_env.sh src/environment/create_requirements.sh src/environment/container/Dockerfile src/environment/container/.dockerignore src/environment/config_environment.txt src/environment/README.md
#1562435499
git commit -m "refactor: structure"
#1562435505
git push origin master 
#1562435610
gitk --all &
#1562435631
git reset --soft HEAD~1
#1562435655
git status
#1562435660
git add src/environment/show_config_environment.sh
#1562435667
git commit -m "refactor: structure"
#1562435688
git reset --soft HEAD~4
#1562435727
git status
#1562435734
git add src/environment/show_config_environment.sh
#1562435738
git commit -m "refactor: structure"
#1562435750
git status
#1562435819
git reset ed08880e8469f0746bb0b63a4e74743a68707840
#1562435823
git status
#1562435868
git add .gitignore README.md notebooks/porto_seguro_safe_driver.ipynb requirements.txt src/environment/README.md src/environment/config_environment.txt src/environment/create_requirements.sh src/environment/create_virtual_env.sh src/environment/prepare_env.py src/environment/show_config_environment.sh src/environment/struture_project.txt src/environment/test_environment.py
#1562435872
git commit -m "refactor: structure"
#1562435876
git push origin master 
#1562435380
sudo docker run -it -p 8888:8888 challenge-keyrus
#1562435891
git status
#1562435907
git add data/datasets.zip data/kaggle_submission.csv src/environment/container/ references/ src/environment/jupyter_notebook_config.py src/environment/requirements.txt
#1562435910
git commit -m "refactor: structure"
#1562435914
git push origin master 
#1562436030
git add --all
#1562436033
git commit -m "refactor: structure"
#1562436037
git push origin master 
#1562437387
git reset --soft HEAD~1
#1562437391
git status
#1562437395
git add --all
#1562437399
git commit -m "refactor: structure"
#1562437413
gitk --all
#1562437480
git reset /data/raw/test.csv
#1562437485
gitk --all
#1562437503
git reset /data/raw/test.csv
#1562437511
gitk --all &
#1562437529
git reset 1a0852d0232a80762f83f86f217e1ab7f4f34f03
#1562437550
git stauts
#1562437553
git status
#1562437564
git add .gitignore README.md
#1562437569
git commit -m "refactor: structure"
#1562437574
git push origin master 
#1562437634
git add --all
#1562437638
git status
#1562437644
git commit -m "refactor: structure"
#1562438017
cd ..
#1562438027
cd artificial_inteligence/
#1562438027
ll
#1562438030
cd projects/
#1562438030
ll
#1562438033
cd analise_despesas_senadores/
#1562438033
ll
#1562438052
cd src/environment/
#1562438053
ll
#1562438095
./create_virtual_env.sh
#1562438109
source venv/bin/activate
#1562438111
cd ..
#1562438140
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562438150
cd src/environment/
#1562438151
pip3 install -r virtualenv_requirements.txt # libs necessary to prepare virtual environment
#1562438230
pip3 install -r requirements.txt            # libs necessary in notebooks
#1562437646
git push origin master 
#1562438291
jupyter-notebook 
#1562438316
cd ..
#1562446182
cd
#1562446187
cd projetos/artificial_inteligence/projects/
#1562446188
ll
#1562446191
cd analise_despesas_senadores/
#1562446195
cd data/
#1562446196
ll
#1562446198
cd dumps/
#1562446199
ll
#1562438319
jupyter-notebook 
#1562453738
cd ..
#1562453755
jupyter-notebook 
#1562453766
cd ..
#1562515476
cd
#1562515479
cd projetos/compiladores/
#1562515480
ll
#1562515489
cd trabalho_parte_03-arvore_sintatica/
#1562515490
ll
#1562515503
java parser.langX -print_tree testes_e_logs/bintree.x 
#1562515525
java -version
#1562515537
javac -version
#1562515630
java parser.langX -print_tree testes_e_logs/bintree.x > testes_e_logs/log_bintree.x
#1562515865
code .
#1562517986
ps aux | grep pycharm
#1562517998
sudo kill -9 2568
#1562518007
sudo kill -9 8745
#1562518012
ps aux | grep pycharm
#1562518021
sudo kill -9 8805
#1562519404
java parser.langX -print_tree testes_e_logs/teste_expressoes_logicas.x
#1562519409
java parser.langX -print_tree testes_e_logs/teste_com_erro_classbody.x
#1562519415
java parser.langX -print_tree testes_e_logs/bintree.x
#1562519453
cd ..
#1562519455
git status
#1562519462
git add --all
#1562519550
git commit -m "test: add new test and create report"
#1562519555
git push origin master 
#1562520561
zip -r trabalho_ic3.zip trabalho_parte_03-arvore_sintatica/
#1562520562
ll
#1562520592
mv trabalho_ic3.zip trabalho_parte_03-arvore_sintatica/
#1562520597
cd trabalho_parte_03-arvore_sintatica/
#1562520598
ll
#1562553583
git status
#1562553586
git add --all
#1562553621
git commit -m "refactor: create environment, refactor notebooks"
#1562553628
git push origin master 
#1562553640
git pull
#1562553646
git pull origin master 
#1562553653
code .
#1562553659
cd ..
#1562553663
code .
#1562553707
git add --all
#1562553711
git commit -m "refactor: create environment, refactor notebooks"
#1562553715
git push origin master 
#1562453769
jupyter-notebook 
#1562382214
jupyter-notebook 
#1562558761
git pull origin master 
#1562558810
code .
#1562558843
git add --all
#1562558847
git commit -m "refactor: create environment, refactor notebooks"
#1562558850
git push origin master 
#1562719247
git status
#1562719250
cd ..
#1562719259
cd challenges/
#1562719260
ll
#1562719263
cd challenge-aawz/
#1562719265
ll
#1562719268
git status
#1562719272
git add --all
#1562719297
git diff src/environment/show_config_environment.sh
#1562719306
git diff README.md
#1562719312
git diff 
#1562719330
git commit -m "documentation"
#1562719333
git push origin master 
#1562719429
cd ..
#1562719432
git status
#1562719435
ll
#1562719445
cd challenge-indicium/
#1562719448
git status
#1562719451
git add --all
#1562719463
git commit -m "documentation"
#1562719467
git push origin master 
#1562719481
cd ..
#1562719483
ll
#1562719492
cd challenge-keyrus/
#1562719494
git status
#1562719499
git add --all
#1562719541
git commit -m "refactor: new environment to deploy"
#1562719545
git push origin master 
#1562719884
code .
#1562725610
cd
#1562725612
cd projetos/
#1562725618
ll
#1562725625
source venv_global/bin/activate
#1562725814
cd artificial_inteligence/
#1562725815
code .
#1562725859
cd ..
#1562725860
code .
#1562726983
cd data-warehouse/
#1562726984
code .
#1562733227
python -m pip install featuretools
#1562733270
jupyter-notebook 
#1562733476
sudo apt-get install graphviz
#1562738366
for (( i=0; i<10; i=i+1 )); do
echo $i
done
#1562773786
source /home/campos/projetos/venv_global/bin/activate
#1562773786
/home/campos/projetos/venv_global/bin/python3 -m pip install -U pytest
#1562782531
for(i=0; i<10; i=i+1;); do
#1562782544
for((i=0; i<10; i=i+1;)); do
echo $i
done
#1562782591
for((i=0; i<10; i=i+1)); do
echo $i
done
#1562782601
for((i=0; i<10 i=i+1)); do
echo $i
done
#1562782606
for((i=0 i<10 i=i+1)); do
echo $i
done
#1562782613
for((i=0; i<10; i=i+1)); do
echo $i
done
#1562783329
cd ..
#1562783343
cd challenges/challenge-aawz/
#1562783345
git status
#1562783348
git add --all
#1562783359
git commit -m "fix"
#1562783366
git push origin master 
#1562783381
cd ..
#1562783383
ll
#1562783389
cd challenge-indicium/
#1562783391
git status
#1562783396
git add --all
#1562783401
git commit -m "fix"
#1562783405
git push origin master 
#1562783415
cd..
#1562783417
ll
#1562838577
cd ..
#1562838582
cd artificial_inteligence/data-science/
#1562838585
git status
#1562838589
git add --all
#1562838607
ll
#1562838615
rm -rf beakerx/
#1562838631
git reset --soft HEAD~1
#1562838637
git status
#1562838643
git add --all
#1562838649
git commit -m "refactor"
#1562838655
git push origin master 
#1562838668
git pull origin master 
#1562838804
git push origin master --force
#1562847910
cd
#1562847934
ps aux | grep mysql
#1562847938
ps -h
#1562847943
ps --help
#1562847963
ps -t 
#1562847966
ps -t aux
#1562848000
ps -f
#1562848003
ps -f aux
#1562848088
ps aux --help
#1562848093
man ps
#1562848215
ps forest aux
#1562848228
ps forest
#1562848232
ps --forest
#1562848239
ps --forest --aux
#1562848243
ps --forest aux
#1562848254
ps --forest aux | grep init
#1562848272
ps --forest aux | bin/bash
#1562848281
ps --forest aux | chrome
#1562848347
if (fork() && fork())
#1562848350
if (fork() && fork()) {
#1562848362
if (fork() && fork()); then
#1562848372
if (fork() && fork()) 
#1562848420
ps --forest aux
#1562848444
#include <stdio.h> 
#1562848444
#include <unistd.h> 
#1562848444
int main() 
#1562848444
{ 
    if (fork() || fork()) 
#1562848446
}
#1562895135
git add --all
#1562895140
git commit -m "refactor"
#1562895146
git push origin master
#1562907714
for name in Lucien Maurice Renald Johnson Alfred; do
    echo $name
done
#1562907726
for (( i=0; i<10; i=i+1 )); do
        echo $i
done
#1562957072
git add --all
#1562957090
git commit -m "refactor: fearute engineerinf"
#1562957095
git push origin master 
#1562969018
cd ..
#1562969019
ll
#1562969023
cd projects/
#1562969024
ll
#1562969027
cd analise_despesas_senadores/
#1562969030
git status
#1562969037
git add --ll
#1562969040
git add --all
#1562969048
git commit -m "fix"
#1562969054
git push origin master 
#1562969070
cd ..
#1562969075
git status
#1562969077
cd ..
#1562969081
cd challenges/
#1562969081
ll
#1562969091
cd kaggle/
#1562969092
ll
#1562969094
cd allstate-claims-severity/
#1562969097
git status
#1562969101
git add --all
#1562969112
git commit -m "refactor"
#1562969116
git push origin master 
#1562994918
cd ..
#1562994919
ll
#1562994923
git status
#1562994936
cd porto-seguro-safe-driver-prediction/
#1562994938
cd ..
#1562994949
cd challenges/
#1563005180
cd ..
#1563005185
ll
#1563005203
mkdir big_data
#1563005205
cd big_data/
#1563005206
ll
#1563005210
git init
#1563006731
mkdir samples
#1563006733
cd samples/
#1563006737
git clone https://github.com/words-sdsc/coursera.git
#1563006895
git clone https://github.com/Qian-Han/coursera-Big-Data-specialization.git
#1563052794
git remote add -h
#1563052805
git remote add origin git@github.com:brunocampos01/big-data-specialization.git
#1563052809
git remove -V
#1563052811
git remove -v
#1563052816
git remote -v
#1563053891
cd ..
#1563053896
git status
#1563053907
git add --all
#1563053923
git reset --soft HEAD~1
#1563053928
git reset --soft HEAD
#1563053937
git reset HEAD
#1563053945
git status
#1563053962
git rm --cached --all
#1563053965
git rm --cached *
#1563053976
git rm --cached -r *
#1563053979
git rm --cached 
#1563053999
git rm --cached .gitignore 
#1563054805
ll
#1563086742
cd samples/
#1563086748
git clone https://github.com/jingwen-z/bigdata-ucsd.git
#1563140423
cd ..
#1563140437
ll
#1563140441
cd seguranca/
#1563140443
git status
#1563140449
git add --all
#1563140455
code .
#1563140518
git status
#1563140684
git commit -m "doc: add auxiliar code provider by teacher"
#1563140688
git push origin master 
#1563140697
git pull origin master 
#1563140703
code .
#1563140778
git push origin master --force
#1563147334
cd ..
#1563147343
ll
#1563147364
cd redes/
#1563147365
ll
#1563147389
mkdir test_conexion
#1563147391
cd test_conexion/
#1563147392
ll
#1563147396
code .
#1562725630
jupyter-notebook 
#1563212940
cd ..
#1563212942
ll
#1563317712
cd artificial_inteligence/
#1563317715
cd data-science/
#1563317717
git status
#1563317721
git add --all
#1563317730
git commit -m "refactor"
#1563317736
git push origin master 
#1563342143
dig http://sajinsights.com.br
#1563342152
dig sajinsights.com.br
#1563342166
nmap sajinsights.com.br
#1563342450
cd
#1563342451
cd projetos/
#1563342462
cd challenges/challenge-softplan-data-engineer/
#1563342464
ll
#1563342467
code .
#1563386997
cd ..
#1563387002
cd artificial_inteligence/
#1563387003
ll
#1563387006
cd projects/
#1563387006
ll
#1563387008
code .
#1563451018
cd ..
#1563451022
ll
#1563451032
cd challenges/challenge-softplan-data-engineer/
#1563451032
ll
#1563451037
cd data/
#1563451037
ll
#1563451046
cd raw/
#1563451047
ll
#1563451051
cd ..
#1563451052
ll
#1563451060
rm -r raw/
#1563451061
ll
#1563451123
wget https://azuremlsampleexperiments.blob.core.windows.net/templatedata/Online%20Fraud-%20Test%2010.csv
#1563451126
ll
#1563452079
rm -r Online\ Fraud-\ Test\ 10.csv 
#1563452093
ll
#1563452124
file .
#1563452104
wget https://azuremlsampleexperiments.blob.core.windows.net/templatedata/Online%20Fraud-%20Untagged%20Transactions.csv
#1563453681
ll
#1563453707
mv 'Online Fraud- Untagged Transactions.csv' online-fraud-transactions.csv
#1563453710
ll
#1563453884
çç
#1563453886
ll
#1563453893
cat online-fraud-transactions-test-API.csv
#1563453919
;ll
#1563453920
ll
#1563453963
cd ..
#1563453970
git status
#1563453974
code .
#1563453990
cd ..
#1563453991
code .
#1563454042
ll
#1563454065
cd challenge-softplan-data-engineer/
#1563454066
ll
#1563454072
code .
#1563454217
git remote -V
#1563454221
git remote -v
#1563454230
git init
#1563454245
git remote add origin git@github.com:brunocampos01/challenge-softplan-data-engineer.git
#1563454249
git remote -v
#1563454252
ll
#1563454259
git add --all
#1563454264
code .
#1563454294
git add --all
#1563454302
git commit -m "initial commit"
#1563454306
git push origin master 
#1563455059
ll
#1563455062
cd data/
#1563455065
cd raw/
#1563455066
ll
#1563455072
wget -h
#1563455142
wget --verbose https://azuremlsampleexperiments.blob.core.windows.net/templatedata/Online%20Fraud-%20Fraud%20Transactions.csv
#1563455148
ll
#1563455154
code .
#1563458681
cd ..
#1563458683
code .
#1563459648
wget https://ussouthcentral.services.azureml.net/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999/execute?api-version=2.0&details=true
#1563459667
wget -POST https://ussouthcentral.services.azureml.net/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999/execute?api-version=2.0&details=true
#1563459678
curl -POST https://ussouthcentral.services.azureml.net/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999/execute?api-version=2.0&details=true
#1563459701
curl -XGET https://ussouthcentral.services.azureml.net/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999/execute?api-version=2.0&details=true
#1563459767
curl https://ussouthcentral.services.azureml.net/odata/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999
#1563459837
cd ..
#1563459849
vi test_post.py
#1563461005
code .
#1563461162
python3 post.py 
#1563461177
python3 post.py | jq
#1563461186
sudo apt install jq
#1563461199
python3 post.py | jq
#1563461207
python3 post.py
#1563461211
python3 post.py jq
#1563461221
python3 post.py | jq
#1563461248
python3 post.py > test.json
#1563461251
ll
#1563461256
cat test.json 
#1563461260
cat test.json | jq
#1563461833
python3 post.py > test.json
#1563463168
docker pull quintoandar/powerbi-dashboards
#1563463173
sudo docker pull quintoandar/powerbi-dashboards
#1563463361
ll
#1563463376
sudo docker images -a
#1563463407
sudo docker run -h
#1563463411
sudo docker run --help
#1563464091
cd challenges/challenge-
#1563464096
cd challenges/challenge-softplan-data-engineer/
#1563464100
code .
#1563468273
ps --forest aux
#1563471702
cd projetos/
#1563471703
ll
#1563471707
cd challenges/
#1563471707
ll
#1563471722
mkdir challenge-spinver
#1563471724
ll
#1563471727
cd challenge-spinver/
#1563471728
ll
#1563471797
vi README.md
#1563471947
ll
#1563471965
cat README.md 
#1563471974
vi README.md 
#1563471982
cat README.md 
#1563471986
ll
#1563472038
vi README.md 
#1563472061
ll
#1563472460
wget https://www.webmotors.com.br/comprar/mitsubishi/outlander/*
#1563472471
wget www.webmotors.com.br/comprar/mitsubishi/outlander/*
#1563472479
wget www.webmotors.com.br/comprar/
#1563472583
wget --verbose https://www.webmotors.com.br/carros-novos/estoque?tipoveiculo=carros-novos
#1563472595
wget https://www.webmotors.com.br/carros-novos/estoque?tipoveiculo=carros-novos
#1563472613
curl -XGET https://www.webmotors.com.br/carros-novos/estoque?tipoveiculo=carros-novos
#1563472720
curl -h
#1563472811
curl -XGET https://www.webmotors.com.br/carros-novos/estoque?tipoveiculo=carros-novos
#1563486710
curl -XGET https://www.webmotors.com.br/comprar/fiat/grand-siena/1-4-mpi-attractive-8v-flex-4p-manual/4-portas/2019/28566692?pos=d28566692m:&np=1
#1563486846
curl -XGET -c /tmp/cookies https://www.webmotors.com.br/comprar/fiat/grand-siena/1-4-mpi-attractive-8v-flex-4p-manual/4-portas/2019/28566692?pos=d28566692m:&np=1
#1563486889
man curl
#1563487064
curl -c /tmp/cookies https://www.webmotors.com.br/comprar/fiat/grand-siena/1-4-mpi-attractive-8v-flex-4p-manual/4-portas/2019/28566692?pos=d28566692m:&np=1
#1563487723
ssh 137.135.117.63
#1563487753
ssh --verbose 137.135.117.63
#1563487779
dig 137.135.117.63
#1563487854
ssh -v brunocampos01@137.135.117.63
#1563488088
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
#1563488103
sudo apt-get update
#1563488111
sudo apt-get install curl apt-transport-https lsb-release gnupg
#1563488116
curl -sL https://packages.microsoft.com/keys/microsoft.asc |     gpg --dearmor |     sudo tee /etc/apt/trusted.gpg.d/microsoft.asc.gpg > /dev/null
#1563488130
AZ_REPO=$(lsb_release -cs)
#1563488130
echo "deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main" |     sudo tee /etc/apt/sources.list.d/azure-cli.list
#1563488137
sudo apt-get update
#1563488146
sudo apt-get install azure-cli
#1563488309
az 
#1563488323
az login
#1563488370
az group create --name TutorialResources --location eastus
#1563488518
az vm create --resource-group TutorialResources   --name powerBI   --image Windows10   --generate-ssh-keys   --output json   --verbose
#1563490663
ssh brunocampos01@40.85.169.166
#1563490854
ssh brunocampos01@10.0.1.4
#1563491447
sudo docker pull mcr.microsoft.com/windows
#1563491812
ssh brunocampos01@10.0.1.4
#1563495444
curl -XGET https://ussouthcentral.services.azureml.net/workspaces/e4725335cbec4e6a9be0da10269e2482/services/8d1f2c10fa4f4fedbf4f9cd0de867999/execute?api-version=2.0&details=true
#1563495451
ll
#1563495456
python3 post.py 
#1563515782
cd data/raw/
#1563515783
ll
#1563515787
sed 's/ /,/g' german.data > german.csv  
#1563515789
ll
#1563523358
cd ..
#1563523362
python3 post.py 
#1563527548
az login
#1563527616
az group create     --name storage-resource-group     --location westus
#1563527813
az storage account create     --name container-ml     --resource-group storage-resource-group     --location westus     --sku Standard_RAGRS     --kind StorageV2
#1563527854
az storage account create     --name containerml     --resource-group storage-resource-group     --location westus     --sku Standard_RAGRS     --kind StorageV2
#1563527889
az storage account create     --name containerml     --resource-group storage-resource-group     --location westus     --sku Standard_RAGRS     --kind StorageV2
#1563528559
az storage container create --name mystoragecontainer
#1563528606
export AZURE_STORAGE_ACCOUNT="brunocampos01"
#1563528607
export AZURE_STORAGE_KEY="ST2Fp@76^Y1$"
#1563528625
az storage container create --name mystoragecontainer
#1563529553
az storage account check-name
#1563529574
az storage account conteiner
#1563529597
az storage account keys list
#1563567020
curl --include --request POST --header "Content-Type: application/json" --data-binary "[
{
\"Scored Labels\" :\"AAAAA555555\",
\"Scored Probabilities\" :\"AAAAA555555\"
}
]" "https://api.powerbi.com/beta/fa79531c-8ce5-4bd3-97ee-245e6ee266b8/datasets/45715c2a-bcb5-4ce2-8203-0742a0bbf059/rows?key=3gd%2BbU0Oes1qrzJ34GLuQFhXxU%2BUbU9Vr%2BhczH2RvB8sMI6%2BGbchBUH9EupyGP3v1AxVgpt3Z2vBSf2p5kXLsQ%3D%3D"
#1563596514
ssh brunocampos01@10.0.1.4
#1563609219
cd
#1563609221
cd Downloads/
#1563609223
ll
#1563609224
java -jar metabase.jar
#1563610351
sudo apt-get install build-essential libssl-dev libffi-dev python3.6-dev python-pip libsasl2-dev libldap2-dev
#1563610385
cd
#1563610395
cd projetos/
#1563610395
ll
#1563610406
cd challenges/challenge-softplan-data-engineer/
#1563610406
ll
#1563610438
virutalenv -p python3 venv
#1563610448
virtualenv -p python3 venv
#1563610457
source venv/bin/activate
#1563610459
ll
#1563610461
pip install superset
#1563610576
pip install --upgrade setuptools pip
#1563610583
superset db upgrade
#1563610597
export FLASK_APP=superset
#1563610600
flask fab create-admin
#1563610671
pip install pandas
#1563610676
flask fab create-admin
#1563610719
superset load_examples
#1563610729
pip freese
#1563610731
pip freeze
#1563610755
pip install --upgrade setuptools pip
#1563610760
pip install superset
#1563610764
superset db upgrade
#1563610819
deactivate
#1563610820
cd
#1563610823
cd Downloads/]
#1563610825
cd Downloads/
#1563610827
ll
#1563610836
java -jar metabase.jar
#1563622941
ssh brunocampos01@40.76.89.36
#1563623671
ssh brunocampos01@40.85.188.112
#1563758512
cd ..
#1563758514
cd projetos/
#1563758515
ll
#1563758519
cd artificial_inteligence/
#1563758519
ll
#1563758521
cd data-science/
#1563758521
ll
#1563758524
git status
#1563758531
git add --all
#1563758538
git commit -m "refactor"
#1563758541
git push origin master 
#1563758557
ll
#1563758562
cd steps_data_science/
#1563758563
ll
#1563758565
git status
#1563758568
cd ..
#1563758570
ll
#1563758574
cd machine_learning/
#1563758575
kk
#1563758576
ll
#1563758578
git status
#1563758586
git add --all
#1563758601
git commit -m "refactor"
#1563758605
git push origin master 
#1563463425
sudo docker run quintoandar/powerbi-dashboards
#1563464603
sudo docker run quintoandar/powerbi-dashboards
#1563759120
cd projetos/artificial_inteligence/
#1563759121
ll
#1563759124
cd machine_learning/
#1563759125
ll
#1563759128
git status
#1563759139
git push origin master 
#1563759158
git pull origin master 
#1563759165
git push origin master 
#1563763075
~
#1563791197
ll
#1563793658
cd projetos/
#1563793659
ll
#1563793661
cd challenges/
#1563793662
ll
#1563793670
cd sp
#1563793675
cd challenge-spinver/
#1563793675
ll
#1563793677
code .
#1563794061
mkdir samples
#1563794064
cd samples/
#1563794065
ll
#1563794068
mkdir https://github.com/guilhermemarson/webmotors.git
#1563794073
ll
#1563794083
rm -r https\:/
#1563794087
git clone https://github.com/guilhermemarson/webmotors.git
#1563794148
git clone https://github.com/EduBRK/scrapy-web-motors.git
#1563794244
git clone https://github.com/lfpll/parse_webmotors.git
#1563794316
wget https://www.webmotors.com.br/comprar/chevrolet/s10/2-5-lt-4x4-cd-16v-flex-4p-automatico/4-portas/2018/27521767?pos=a27521767m:&np=1&ct=1840172
#1563794326
curl -XGET https://www.webmotors.com.br/comprar/chevrolet/s10/2-5-lt-4x4-cd-16v-flex-4p-automatico/4-portas/2018/27521767?pos=a27521767m:&np=1&ct=1840172
#1563800288
docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563802343
mkdir ~/data
#1563802343
git clone git@github.com:scrapinghub/portia.git
#1563802362
cd portia/portiaui
#1563802362
npm install && bower install
#1563802362
cd node_modules/ember-cli && npm install && cd ../../
#1563802362
ember build
#1563802363
cd ..
#1563802419
sudo ./provision.sh install_deps
#1563802375
sudo apt install npm
#1563802464
cd node_modules/ember-cli && npm install && cd ../../
#1563802470
npm install && bower install
#1563802473
sudo snap install bower
#1563802484
npm install && bower install
#1563802491
npm install
#1563802494
ll
#1563802502
cd portia
#1563802514
cd portia/portiaui
#1563802530
cd portiaui/
#1563802534
npm install && bower install
#1563802559
cd node_modules/ember-cli && npm install && cd ../../
#1563802568
ll
#1563802580
npm install
#1563802615
cd ..
#1563802617
ember build
#1563802627
ll
#1563802642
cd portiaui/
#1563802644
ll
#1563802648
cd node_modules/
#1563802649
ll
#1563802654
cd ember-
#1563802660
cd ember-cli
#1563802661
ll
#1563802670
npm install
#1563802705
cd ..
#1563802712
ember build
#1563802716
docker build . -t portia
#1563802720
sudo docker build . -t portia
#1563802730
sudo docker run -i -t --rm -p 9001:9001     -v ~/data:/app/data/projects:rw     -v ~/portia/portiaui/dist:/app/portiaui/dist     -v ~/portia/slyd:/app/slyd     -v ~/portia/portia_server:/app/portia_server     portia
#1563802773
sudo docker run -i -t --rm -v testing:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563800292
sudo docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563876411
kk
#1563876412
ll
#1563876416
cd projetos/
#1563876417
ll
#1563876691
cd challenges/
#1563876692
ll
#1563876699
cd challenge-softplan-data-engineer/
#1563876701
ll
#1563876718
cd ..
#1563876719
ll
#1563876724
cd challenge-spinver/
#1563876725
ll
#1563876729
code .
#1563876807
virtualenv -p python3 venv
#1563876814
ll
#1563876821
source venv/bin/activate
#1563876822
ll
#1563876848
pip install shub
#1563876893
git clone https://github.com/scrapy/booksbot.git
#1563876902
pip3 install scrapy
#1563877127
scrapy startproject quotes_craler
#1563877142
tree
#1563877186
cp ../quotes_craler/ ./quotes_craler/spiders/
#1563877197
cp -r ../quotes_craler/ ./quotes_craler/spiders/
#1563877206
scrapy list
#1563877220
ll
#1563877230
cd ..
#1563877243
rm -r quotes_craler/
#1563877244
ll
#1563877248
scrapy -h
#1563877274
scrapy startproject quotes_crawler
#1563877282
ll
#1563877302
tree
#1563877325
cd ..
#1563877327
ll
#1563877332
cd samples/
#1563877333
ll
#1563877348
cd portia/
#1563877348
ll
#1563877355
cd ..
#1563877373
ll
#1563877533
#docker run -i -t --rm -v <PROJECTS_FOLDER>:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563877556
sudo docker run -i -t --rm -v /app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563877575
ll
#1563877587
sudo docker run -i -t --rm -v app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563877653
ll
#1563877666
tree
#1563877712
sudo docker run -i -t --rm -v . -p 9001:9001 scrapinghub/portia
#1563877762
sudo docker run -i -t --rm -v <PROJECTS_FOLDER>:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563877821
git clone https://github.com/scrapinghub/portia.git
#1563877940
ll
#1563877948
cd portia/
#1563877948
ll
#1563877996
sudo ./provision.sh install_deps install_splash install_python_deps
#1563878000
ll
#1563878002
cd doc
#1563878006
cd ..
#1563878017
cd docker/
#1563878019
sudo ./provision.sh install_deps install_splash install_python_deps
#1563878032
./provision.sh install_deps install_splash install_python_deps
#1563878044
cd ..
#1563878045
ll
#1563878078
cd portia/portiaui
#1563878081
cd ..
#1563878082
cd portia/portiaui
#1563878086
npm install && bower install
#1563878118
cd node_modules/ember-cli && npm install && cd ../../
#1563878168
sudo snap install bower
#1563878174
ember build
#1563878178
sudo apt install ember
#1563878516
cd ..
#1563878519
docker build . -t portia
#1563883340
cd ..
#1563883341
ll
#1563883344
cd quotes_crawler/
#1563883345
ll
#1563883732
tree
#1563883742
tree ll
#1563883747
tree -h
#1563883756
tree --help
#1563883818
tree -h
#1563883827
tree --human
#1563883835
tree -T
#1563883838
tree -t
#1563883857
tree -h
#1563884292
sudo docker pull postgres
#1563884999
cd ..
#1563885001
ll
#1563878523
sudo docker build . -t portia
#1563893551
sudo docker run -i -t --rm -p 9001:9001     -v ~/data:/app/data/projects:rw     -v ~/portia/portiaui/dist:/app/portiaui/dist     -v ~/portia/slyd:/app/slyd     -v ~/portia/portia_server:/app/portia_server     portia
#1563893562
ll
#1563893575
cd ..
#1563893576
ll
#1563893579
docker run -i -t --rm -p 9001:9001     -v ~/data:/app/data/projects:rw     -v ~/portia/portiaui/dist:/app/portiaui/dist     -v ~/portia/slyd:/app/slyd     -v ~/portia/portia_server:/app/portia_server     portia
#1563893585
sudo docker run -i -t --rm -p 9001:9001     -v ~/data:/app/data/projects:rw     -v ~/portia/portiaui/dist:/app/portiaui/dist     -v ~/portia/slyd:/app/slyd     -v ~/portia/portia_server:/app/portia_server     portia
#1563893611
ll
#1563893664
sudo docker run -i -t --rm -p 9001:9001 -v portia/portiaui/dist:/app/portiaui/dist     -v portia/slyd:/app/slyd     -v portia/portia_server:/app/portia_server     portia
#1563893687
docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563893789
source venv/bin/activate
#1563894095
pip install shub
#1563894100
shub login
#1563894110
shub deploy 401021
#1563894118
ll
#1563894444
scrapy -h
#1563894476
pip3 install quotes_crawler/requirements.txt 
#1563894644
ll
#1563894683
mkdir scrapping_web_motors
#1563894687
cd scrapping_web_motors/
#1563894687
ll
#1563894702
scrapy startproject tutorial
#1563894714
ll
#1563894717
tree
#1563894843
ll
#1563894973
scrapy crawl tutorial/tutorial/spiders/webmotors_com_br.py 
#1563895050
ll
#1563895055
pwd
#1563895061
cd Testing/
#1563895062
ll
#1563895075
scrapy crawl spiders/webmotors_com_br.py 
#1563895111
pip install dateparser
#1563895144
scrapy crawl spiders/webmotors_com_br.py 
#1563895189
ll
#1563895201
cd ..
#1563895202
ll
#1563895209
python3 setup.py install
#1563895214
ll
#1563895217
cd Testing/
#1563895217
ll
#1563895226
scrapy crawl spiders/webmotors_com_br.py 
#1563895570
ll
#1563895577
cd ..
#1563895578
ll
#1563895590
scrapy crawl Testing/spiders/webmotors_com_br.py 
#1563895599
scrapy crawl Testing/
#1563895607
scrapy crawl Testing/spiders
#1563895613
cd ..
#1563895614
ll
#1563895622
rm -r scrapping_web_motors/
#1563895754
ll
#1563895770
scrapy 
#1563895776
scrapy check
#1563895964
ll
#1563895982
portiacrawl
#1563896286
ll
#1563896302
rm -r docker-compose.yml scrapy.cfg setup.py Testing/
#1563896303
ll
#1563896314
mkdir tests
#1563896316
cd tests/
#1563896316
ll
#1563896322
scrapy startproject tutorial
#1563896333
ll
#1563896350
cd tutorial/spiders/
#1563896351
ll
#1563896362
cat example.py
#1563896678
vim example.py 
#1563896707
ll
#1563896725
scrapy crawl quotes
#1563896729
ll
#1563896813
vim example.py 
#1563896840
scrapy crawl quotes
#1563896855
vim example.py 
#1563896995
ll
#1563896998
cd ..
#1563896998
ll
#1563897002
cd ..
#1563897002
ll
#1563897007
cd ..
#1563897009
tree
#1563897024
pwd
#1563897028
cd ..
#1563897028
ll
#1563897047
mkdir portia_test_web_motors
#1563897048
ll
#1563897051
cd portia_test_web_motors/
#1563897052
ll
#1563897125
python3 setup.py install
#1563897127
ll
#1563897132
pip3 freeze
#1563897164
scrapy crawl quotes
#1563897201
ll
#1563897210
cd ..
#1563897210
ll
#1563897222
mkdir mais_test
#1563897224
cd mais_test/
#1563897225
ll
#1563897227
scrapy shell 'http://quotes.toscrape.com/page/1/'
#1563897236
pip3 install scrapy
#1563897250
pip3 install --user scrapy
#1563897310
kk
#1563897311
ll
#1563897323
cd Testing/
#1563897324
ll
#1563897331
scrapy crawl quotes
#1563897341
scrapy crawl spiders/webmotors_com_br.py 
#1563897349
cd ..
#1563897349
ll
#1563897358
cd ..
#1563897360
ll
#1563897364
cd portia_test_web_motors/
#1563897365
ll
#1563897470
scrapy crawl spiders/webmotors
#1563897475
scrapy crawl webmotors
#1563897481
ll
#1563897485
pwd
#1563897490
cd Testing/
#1563897490
ll
#1563897493
scrapy crawl webmotors
#1563897504
scrapy crawl spiders/webmotors
#1563918318
cd ..
#1563918318
ll
#1563918335
cd ..
#1563918336
ll
#1563918342
cd portia_test_web_motors/
#1563918343
ll
#1563918350
rm -r *
#1563918351
ll
#1563918599
cd ..
#1563918599
ll
#1563918619
pwd
#1563918655
mv -r tests/testing/* portia_test_web_motors/
#1563918663
mv  tests/testing/* portia_test_web_motors/
#1563918667
ll
#1563918669
cd tests/
#1563918669
kk
#1563918670
ll
#1563918673
cd testing/
#1563918674
ll
#1563918678
cd ..
#1563918679
ll
#1563918681
cd testing/
#1563918683
ll
#1563918685
tree
#1563918712
cd ..
#1563918716
ll
#1563918720
cd portia_test_web_motors/
#1563918720
ll
#1563918727
python setup.py install
#1563918730
tree
#1563918737
ll
#1563918739
tree
#1563918752
ll
#1563918800
cd Testing/
#1563918801
ll
#1563918913
/8999******--/-------------++++++.+-*/*/*-.+-*/*-+.
#1563918917
/*-+.
#1563918968
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////**************************************************************************************************************************************************************************************
#1563919008
9876543210
#1563919018
ts
#1563919027
ws
#1563919030
qwe
#1563919048
get
#1563919063
ls -h
#1563919072
ll
#1563919075
ll -h
#1563919103
cat pipelines.py
#1563919112
cat settings.py
#1563920367
pip install shub
#1563920371
shub login
#1563920384
shub
#1563920385
shub deploy 401021
#1563920396
ll
#1563920399
cd ..
#1563920400
ll
#1563920402
shub deploy 401021
#1563920482
cd ..
#1563920483
ll
#1563920485
cd ..
#1563920492
cd challenge-spinver/
#1563920493
ll
#1563920503
cd portia_webmotors/
#1563920504
ll
#1563920536
shub deploy 401021
#1563920780
cd ..
#1563920780
ll
#1563920785
cd portia_test_web_motors/
#1563920785
ll
#1563920792
scrapy 
#1563920800
scrapy list
#1563920892
cd ..
#1563920893
l
#1563920899
cd ..
#1563920900
ll
#1563920905
cd challenge-spinver/
#1563920906
ll
#1563920910
cd tests/
#1563920912
ll
#1563920919
cd tutorial/
#1563920923
scrapy list
#1563920973
scrapy crawl webmotors
#1563921067
scrapy crawl ($scrapy list)
#1563921074
scrapy crawl $(scrapy list)
#1563921100
ll
#1563921103
cd ..
#1563921138
ll
#1563921143
cd testing/
#1563921152
scrapy list
#1563921160
cd ..
#1563921164
ll
#1563921174
cd ..
#1563921175
ll
#1563921181
cd portia_webmotors/
#1563921181
ll
#1563921185
scrapy list
#1563921191
cd spiders/
#1563921192
ll
#1563921195
scrapy list
#1563921344
ll
#1563921432
cd ..
#1563921433
l
#1563921441
scrapy
#1563921444
scrapy list
#1563921453
cd ..
#1563921454
ll
#1563921462
cd portia_webmotors/
#1563921475
ll
#1563921480
cd..
#1563921481
ll
#1563921499
cd portia_test_web_motors/
#1563921500
ll
#1563921506
scrapy list
#1563921558
scrapy crawl www.webmotors.com.br
#1563921565
ll
#1563921578
cd Testing/
#1563921578
ll
#1563921582
cd spiders/
#1563921583
ll
#1563921657
cd ..
#1563921659
ll
#1563921662
cd ..
#1563921664
ll
#1563922741
pip install scrapy-splash
#1563923371
cd ..
#1563923373
pwd
#1563923382
sudo docker pull scrapinghub/splash
#1563923936
ll
#1563923960
mv portia_test_web_motors/ scrapy_portia_webmotors
#1563923961
ll
#1563923970
cd samples/
#1563923971
ll
#1563923979
cd ..
#1563923979
ll
#1563923992
rm -r mais_test/
#1563923993
ll
#1563924003
cd tests/
#1563924004
ll
#1563924031
scrapy startproject scrapy_splash
#1563924037
cd scrapy_splash/
#1563924038
ll
#1563924071
cd scrapy_splash/
#1563924072
ll
#1563924080
cd spiders/
#1563924081
ll
#1563924257
vim splashSpider.py
#1563924527
ll
#1563924532
scrapy list
#1563924550
scrapy crawl splashSpider
#1563924928
cd ..
#1563924931
ll
#1563924934
cd ..
#1563924935
ll
#1563924939
cd testing/
#1563924940
ll
#1563924949
cd ..
#1563924954
rm -r testing/
#1563924955
ll
#1563924963
scrapy list
#1563924972
cd tutorial/
#1563924973
l
#1563924981
scrapy lis
#1563924983
scrapy list
#1563924987
cd ..
#1563924988
ll
#1563924990
cd ..
#1563924990
ll
#1563924993
cd scrapy_portia_webmotors/
#1563924994
ll
#1563925004
cd Testing/
#1563925005
ll
#1563925014
scrapy list
#1563925023
cd ..
#1563925035
source ../venv/bin/activate
#1563925037
ll
#1563925041
scrapy list
#1563925052
scrapy crawl www.webmotors.com.br
#1563925060
ll
#1563925362
cd ..
#1563925363
ll
#1563926197
scrapy crawl www.webmotors.com.br
#1563926202
scrapy list
#1563926209
cd scrapy_portia_webmotors/
#1563926210
ll
#1563926236
scrapy list
#1563926247
scrapy crawl www.webmotors.com.br
#1563926361
scrapy list
#1563926376
scrapy crawl quotes
#1563926499
cd ..
#1563926501
ll
#1563926507
rm -r scrapy_portia_webmotors/
#1563926518
portia
#1563926643
ll
#1563926649
scrapy list
#1563926659
scrapy crawl www.webmotors.com.br
#1563926665
ll
#1563926712
rm -r scrapy.cfg setup.py Webmotors/
#1563930765
ll
#1563930770
cd ..
#1563930771
ll
#1563930777
ll
#1563897261
scrapy shell 'http://quotes.toscrape.com/page/1/'
#1563930874
sudo docker ps
#1563923838
sudo docker run -it -p 8050:8050 scrapinghub/splash
#1563930895
sudo docker kill 40d221b8712d
#1563930900
sudo docker ps
#1563930908
sudo docker kill 74d999411fb2
#1563893692
sudo docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563930915
ll
#1563930974
cd portia_webmotors/
#1563930974
ll
#1563930979
rm -r *
#1563931184
sudo docker ps
#1563931192
sudo docker kill 364dabc42e3e
#1563930919
sudo docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563931198
docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 siegfried415/portia-dashboard start-dev 
#1563931419
wget www.webmotors.com.br
#1563931442
wget www.webmotors.com.br --user-agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36'
#1563931467
ll
#1563931470
cd tests/
#1563931471
ll
#1563931474
wget http://example.org/ --user-agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36'
#1563931477
ll
#1563931482
rm index.html 
#1563931504
wget www.webmotors.com.br --user-agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36'
#1563931555
wget -h
#1563931618
cd ..
#1563931622
ll
#1563931625
cd ..
#1563931625
ll
#1563931653
cd devops/
#1563931654
ll
#1563931657
git status
#1563931691
git add -all
#1563931697
git status
#1563931711
git add containers/.dockerignore
#1563931716
git status
#1563931760
git commit -m "refator"
#1563931765
git push origin master 
#1563932213
sudo docker ps
#1563932230
sudo docker kill 19acaf981707
#1563931202
sudo docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 siegfried415/portia-dashboard start-dev 
#1563932234
ll
#1563932238
cd portia_webmotors/
#1563932239
ll
#1563932241
cd ..
#1563932242
ll
#1563932486
cd portia_webmotors/
#1563932487
ll
#1563932620
python setup.py isntall
#1563932623
python setup.py install
#1563932626
ll
#1563932636
pip3 freeze
#1563932644
pip3 freeze | grep pro
#1563932646
ll
#1563932651
scrapy list
#1563932666
scrapy crawl www.webmotors.com.br
#1563932673
ll
#1563932696
code .
#1563932827
portiacrawl
#1563933241
scrapy
#1563933243
ll
#1563933249
rm -r scrapy_splash/
#1563933251
ll
#1563933253
cd tutorial/
#1563933254
ll
#1563933256
scrapy
#1563933272
scrapy list
#1563933283
scrapy crawl quotes
#1563933293
ll
#1563933750
cd ..
#1563933750
ll
#1563933767
mkdir tutorial_scrappinghub
#1563933772
cd tutorial_scrappinghub/
#1563933773
ll
#1563933781
pip install shub
#1563933791
pip install --user shub
#1563933800
git clone https://github.com/scrapy/booksbot.git
#1563933807
ll
#1563933809
cd booksbot
#1563933814
shub login
#1563933824
shub login c104a5fe1fb54854b10a8ff3e3c8c12a
#1563933832
shub deploy 401021
#1563934156
ll
#1563934159
cd ..
#1563934160
ll
#1563934162
cd ..
#1563934169
ll
#1563934170
cd portia_webmotors/
#1563934171
ll
#1563934180
rm -r *
#1563934299
cd ..
#1563934299
ll
#1563934305
cd tests/
#1563934306
ll
#1563934310
cd tutorialsc
#1563934315
cd tutorial_scrappinghub/
#1563934315
ll
#1563934318
cd booksbot/
#1563934319
ll
#1563934323
ll
#1563934328
pwd
#1563934360
cd books/
#1563934361
ll
#1563934373
scrapy list
#1563934378
scrapy list
#1563934388
cat requirements.txt 
#1563934401
pip3 install -r requirements.txt 
#1563934417
pip3 install --user -r requirements.txt 
#1563934436
python3 setup.py install
#1563934449
sudo python3 setup.py install
#1563934454
pip3 install --user -r requirements.txt 
#1563934468
ll
#1563934597
scrapy list
#1563934604
cd ..
#1563934606
scrapy list
#1563934613
cd portia_webmotors/
#1563934615
ll
#1563934622
cd spiders/
#1563934623
ll
#1563934638
cat www.webmotors.com.br.json | jq
#1563934669
scrapy list
#1563934672
cd ..
#1563934674
ll
#1563934680
cd ..
#1563934704
shub deploy 401021
#1563934709
cd portia_webmotors/
#1563934711
shub deploy 401021
#1563934717
ll
#1563934731
rm -r *
#1563934744
sudo rm -r *
#1563934745
ll
#1563934747
cd ..
#1563934763
ll
#1563934766
cd portia_webmotors/
#1563934767
ll
#1563934769
shub deploy 401021
#1563934793
ll
#1563934797
cd ..
#1563934799
ll
#1563934833
ll
#1563934930
cd ..
#1563934930
ll
#1563934939
scrapy list
#1563934965
cd portia_webmotors/
#1563934965
ll
#1563934977
shub deploy 401021
#1563935506
ll
#1563935512
scrapy list
#1563935524
pip3 install --user dateparser
#1563934812
grep slybot.spidermanager
#1563935534
ll
#1563935541
scrapy list
#1563935556
scrapy list
#1563935573
scrapy crawl books
#1563935623
ll
#1563935645
cd books/
#1563935645
ll
#1563935653
cd spiders/
#1563935654
ll
#1563935657
cd ..
#1563935658
ll
#1563935671
scrapy crawl www.webmotors.com.br
#1563935808
ll
#1563935823
deploy 401021
#1563935827
ll
#1563935831
cd Webmotors/
#1563935832
ll
#1563935834
deploy 401021
#1563935840
cd ..
#1563935842
shub deploy 401021
#1563935879
cd books/
#1563935881
ll
#1563935889
cd spiders/
#1563935890
ll
#1563935908
cat books.py | grep date
#1563935913
ll
#1563935917
ll
#1563935957
ll
#1563935959
cd
#1563935960
ll
#1563935965
cd portia
#1563935966
ll
#1563935970
cd slyd/
#1563935970
ll
#1563935972
tree
#1563935973
cd ..
#1563935976
tree
#1563935980
cd ..
#1563935984
cd portia_projects/
#1563935984
ll
#1563935987
tre
#1563935989
tree
#1563936010
extractors.json
#1563936019
code .
#1563936215
scrapy crawl www.webmotors.com.br
#1563936230
ll
#1563936237
tree
#1563936353
shub deploy 401021
#1563936403
source ../venv/bin/activate
#1563936406
shub deploy 401021
#1563936431
python --version
#1563936479
sudo pip install python-dateutil
#1563936491
sudo pip3 install python-dateutil
#1563936508
python setup.py install
#1563936512
shub deploy 401021
#1563936530
pip install pycrypto==2.6.1
#1563936549
shub deploy 401021
#1563936562
sudo apt-get install python3-dateutil
#1563936603
pip freeze
#1563936608
pip freeze | grep dat
#1563936638
pip install python-dateutil 
#1563936641
pip freeze | grep dat
#1563936658
pip freeze | grep dat
#1563936679
pip install parsedatetime
#1563936684
shub deploy 401021
#1563936880
ll
#1563936944
code .
#1563937070
scrapy crawl www.webmotors.com.br
#1563937094
shub deploy 401021
#1563937312
scrapy crawl www.webmotors.com.br
#1563937327
ll
#1563937334
cd Webmotors/
#1563937334
ll
#1563937358
cd spiders/
#1563937358
ll
#1563937363
cd ..
#1563937365
ll
#1563937375
cd utils/
#1563937376
ll
#1563937378
cd ..
#1563937604
scrapy crawl www.webmotors.com.br
#1563937610
ll
#1563937623
scrapy crawl www.webmotors.com.br
#1563937627
ll
#1563937684
scrapy crawl www.webmotors.com.br
#1563937753
ll
#1563937760
cd spiders/
#1563937761
ll
#1563937769
cat webmotors_com_br.py
#1563937935
ll
#1563937937
cd ..
#1563937938
ll
#1563937941
cd ..l
#1563937942
cd ..
#1563937943
ll
#1563937950
cd portia_webmotors/
#1563937951
ll
#1563938793
portiacrawl
#1563938796
portiacrawl
#1563939151
curl http://your_scrapyd_host:6800/schedule.json -d project=your_project_name -d spider=your_spider_name
#1563939248
cd ll
#1563939250
cd ..
#1563939254
ll
#1563939260
cd ..
#1563939261
ll
#1563939263
cd ..
#1563939264
ll
#1563939269
cd ..
#1563939269
lkl
#1563939270
ll
#1563939276
cd tests/
#1563939276
ll
#1563939282
cd ..
#1563939283
ll
#1563939285
cd samples/
#1563939286
ll
#1563939292
cd parse_webmotors/
#1563939293
ll
#1563939300
scrapy
#1563939303
scrapy list
#1563939305
cd ..
#1563939306
ll
#1563939310
cd scrapy-web-motors/
#1563939314
scrapy list
#1563939317
ll
#1563939322
cd env/
#1563939323
ll
#1563939325
cd ..
#1563939327
ll
#1563939330
cd webmotors/
#1563939332
ll
#1563939338
cd gather_cars/
#1563939339
ll
#1563939345
scrapy list
#1563939351
cd gather_cars/
#1563939352
ll
#1563939356
scrapy list
#1563939368
cd ..
#1563939371
cd ../..
#1563939374
cd ..
#1563939376
ll
#1563939381
rm -r samples/
#1563939385
sudo rm -r samples/
#1563939393
ll
#1563939423
ll
#1563939544
scrapy crawl $(scrapy list)
#1563939649
cd tests/
#1563939650
ll
#1563939655
cd tutorial_scrappinghub/
#1563939656
ll
#1563939660
cd booksbot/
#1563939660
ll
#1563939663
scrapy list
#1563940110
wget www.webmotors.com.br
#1563940127
wget -h
#1563940199
wget -h | grep user
#1563940254
wget  --header="Accept: text/html" --user-agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:21.0) Gecko/20100101 Firefox/21.0" www.webmotors.com.br
#1563940431
scrapy list
#1563940436
cd ..
#1563940437
ll
#1563940441
scrapy list
#1563940444
cd booksbot/
#1563940445
ll
#1563940447
cd booksbot/
#1563940450
scrapy list
#1563940465
scrapy crawl books
#1563940966
ll
#1563940973
python3 setup.py install
#1563940975
scrapy crawl $(scrapy list)
#1563941049
python3 setup.py install
#1563941050
scrapy crawl $(scrapy list)
#1563941555
scrapy runspider $(scrapy list)
#1563941568
scrapy list
#1563941579
scrapy runspider $(scrapy list)
#1563941586
python3 setup.py install
#1563941589
scrapy list
#1563941827
sudo docker ps
#1563941840
sudo docker kill 641baab31cbb
#1563932255
sudo docker run -v ~/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563941852
cd ..
#1563941874
docker run -i -t --rm -v <PROJECTS_FOLDER>:/app/data/projects:rw -v <OUPUT_FOLDER>:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/PROJECT_NAME SPIDER_NAME -o /mnt/SPIDER_NAME.jl
#1563941907
pwd
#1563941926
docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/PROJECT_NAME SPIDER_NAME -o /mnt/SPIDER_NAME.jl
#1563941931
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/PROJECT_NAME SPIDER_NAME -o /mnt/SPIDER_NAME.jl
#1563941973
sudo docker run -i -t --rm -v /home/campos:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/PROJECT_NAME SPIDER_NAME -o /mnt/SPIDER_NAME.jl
#1563941987
sudo docker run -i -t --rm -v /home/campos:/app/data/projects:rw -v /home/campos:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/PROJECT_NAME SPIDER_NAME -o /mnt/SPIDER_NAME.jl
#1563942064
sudo docker run -i -t --rm -v /home/campos:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver:/mnt:rw -p 9001:9001 scrapinghub/portia     portiacrawl /app/data/projects/ -o /mnt/SPIDER_NAME.jl
#1563942408
ll
#1563942413
cd ..
#1563942414
ll
#1563942417
cd portia_webmotors/
#1563942418
ll
#1563942421
rm -r *
#1563942423
cd ..
#1563942444
pwd
#1563942450
ll
#1563942602
cd portia_
#1563942612
cd portia_projects/
#1563942613
ll
#1563942615
cd webmotors/
#1563942616
ll
#1563942627
spider list
#1563942638
cd spiders/
#1563942639
ll
#1563942647
cd ..
#1563942652
scrapy list
#1563942659
ll
#1563942660
cd ..
#1563942661
ll
#1563942665
cd portia_webmotors/
#1563942666
ll
#1563942672
cd ..
#1563942675
ll
#1563942685
sudo docker ps
#1563942487
sudo docker run -v /home/campos/projetos/challenges/challenge-spinver/portia_projects:/app/data/projects:rw -p 9001:9001 scrapinghub/portia
#1563942695
sudo docker kill e7bde7bfa7cc
#1563942707
rm -r portia_projects/
#1563942711
sudo rm -r portia_projects/
#1563942715
ll
#1563942720
rm -r portia_webmotors/
#1563942722
ll
#1563942768
pwd
#1563942792
mkdir input
#1563942822
mkdir output
#1563942836
docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia
#1563942899
ll
#1563942973
cd input/
#1563942974
ll
#1563942977
cd webmotors/
#1563942977
ll
#1563942985
cd spiders/
#1563942986
ll
#1563942992
cd ..
#1563942997
spider list
#1563943005
spyder list
#1563943010
cd ..
#1563943011
ll
#1563943013
cd ..
#1563943014
ll
#1563943016
cd output/
#1563943017
ll
#1563943019
cd ..
#1563943021
ll
#1563943139
cd output/
#1563943139
ll
#1563943141
cd ..
#1563943147
sudo docker ps
#1563942869
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia
#1563943152
sudo docker kill bc4acb008f88
#1563943202
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia portiacrawl /app/data/projects/ webmotors -o /mnt/webmotors.jl
#1563943329
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia portiacrawl /app/data/projects/nao_sei webmotors -o /mnt/webmotors.jl
#1563943559
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia portiacrawl /home/campos/projetos/challenges/challenge-spinver/output webmotors -o /mnt/webmotors.jl
#1563943744
ll
#1563943748
cd input/
#1563943748
ll
#1563943756
rm -r *
#1563943760
sudo rm -r *
#1563943762
ll
#1563943770
git clone https://github.com/scrapinghub/portia.git
#1563943813
cd portia
#1563943815
ll
#1563943831
tree
#1563943842
fing provision
#1563943847
finf provision
#1563943850
find provision
#1563943852
ll
#1563943874
sudo ./provision.sh install_deps install_splash install_python_deps
#1563943888
find provision .
#1563943900
ll
#1563943904
cd bin/
#1563943905
ll
#1563943907
cd ..
#1563943908
ll
#1563943910
cd data/
#1563943911
ll
#1563943913
cd projects/
#1563943914
ll
#1563943916
cd ..
#1563943916
ll
#1563943918
cd ..
#1563943919
ll
#1563943929
cd splash_utils/
#1563943929
ll
#1563943935
cd filters/
#1563943935
ll
#1563943937
cd ..
#1563943937
cd..
#1563943940
cd ..
#1563943941
ll
#1563943943
cd ..
#1563943948
cd input/portia/
#1563943950
ll
#1563943954
cd sly
#1563943959
cd slyd/
#1563943960
ll
#1563943999
cd ..
#1563944001
ll
#1563944002
cd doc
#1563944003
ll
#1563944005
cd ..
#1563944007
cd docker/
#1563944008
ll
#1563944015
└─▪  
#1563944019
sudo ./provision.sh install_deps install_splash install_python_deps
#1563944029
ll
#1563944040
./run-tests.sh 
#1563944097
cd ..
#1563944099
PYTHONPATH='/vagrant/portia_server:/vagrant/slyd:/vagrant/slybot'
#1563944102
slyd/bin/slyd -p 9002 -r portiaui/dist &
#1563944108
ll
#1563944121
cd slyd/bin/
#1563944121
ll
#1563944137
./slyd -p 9200
#1563944157
cd ..
#1563944162
cd docker/
#1563944163
ll
#1563944169
./provision.sh 
#1563944175
./provision.sh -h
#1563944184
./provision.sh --help
#1563944193
./provision.sh usage
#1563944211
./provision.sh install_pyqt5
#1563944260
echo deb http://nginx.org/packages/ubuntu/ trusty nginx > /etc/apt/sources.list.d/nginx.list
#1563944269
sudo echo deb http://nginx.org/packages/ubuntu/ trusty nginx > /etc/apt/sources.list.d/nginx.list
#1563944279
sudo ./provision.sh install_pyqt5
#1563944285
sudo ./provision.sh
#1563944317
sudo     apt-get install -y --no-install-recommends         python3         python3-dev         python3-pip         build-essential         libre2-dev         liblua5.2-dev         libsqlite3-dev         zlib1g         zlib1g-dev         netbase         ca-certificates         pkg-config         nodejs         libmysqlclient-dev         python-mysql.connector         python-numpy         python-openssl         python-pip         nginx
#1563944375
sudo apt-get install -y --no-install-recommends         xvfb         libjpeg-turbo8-dev         libgl1-mesa-dev         libglu1-mesa-dev         mesa-common-dev         libfontconfig1-dev         libicu-dev         libpng12-dev         libxslt1-dev         libxml2-dev         libhyphen-dev         libgbm1         libxcb-image0         libxcb-icccm4         libxcb-keysyms1         libxcb-render-util0         libxi6         libxcomposite-dev         libxrender-dev         libgstreamer1.0-dev         libgstreamer-plugins-base1.0-dev         libgstreamer-plugins-good1.0-dev         gstreamer1.0-plugins-good         gstreamer1.0-x         gstreamer1.0-libav         webp         rsync
#1563944414
sudo apt-get install -y --no-install-recommends         xvfb         libjpeg-turbo8-dev         libgl1-mesa-dev         libglu1-mesa-dev         mesa-common-dev         libfontconfig1-dev         libicu-dev         libxslt1-dev         libxml2-dev         libhyphen-dev         libgbm1         libxcb-image0         libxcb-icccm4         libxcb-keysyms1         libxcb-render-util0         libxi6         libxcomposite-dev         libxrender-dev         libgstreamer1.0-dev         libgstreamer-plugins-base1.0-dev         libgstreamer-plugins-good1.0-dev         gstreamer1.0-plugins-good         gstreamer1.0-x         gstreamer1.0-libav         webp         rsync
#1563944534
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia portiacrawl /home/campos/projetos/challenges/challenge-spinver/output.zip webmotors -o /mnt/webmotors.jl
#1563944583
sudo docker ps
#1563944590
sudo docker kill 69185ce33a96
#1563944542
sudo docker run -i -t --rm -v /home/campos/projetos/challenges/challenge-spinver/input:/app/data/projects:rw -v /home/campos/projetos/challenges/challenge-spinver/output:/mnt:rw -p 9001:9001 scrapinghub/portia
#1563944687
ll
#1563944691
cd ..
#1563944692
ll
#1563944698
cd ..
#1563944701
pwd
#1563944719
cd ..
#1563944720
ll
#1563944723
cd output/
#1563944725
ll
#1563944776
python3 setup.py install
#1563944778
ll
#1563944784
scrapy
#1563944786
scrapy list
#1563944793
scrapy crawl www.webmotors.com.br
#1563944908
l
#1563944915
cd ..
#1563944920
code .
#1563944984
scrapy crawl www.webmotors.com.br
#1563944991
ll
#1563945001
cd output/
#1563945002
ll
#1563945034
python setup.py install
#1563945038
scrapy crawl www.webmotors.com.br
#1563945047
code .
#1563945073
cd ..
#1563945074
ll
#1563945076
cd input/
#1563945076
ll
#1563945083
cd agora_vai/
#1563945085
ll
#1563945089
code .
#1563945193
scrapy list
#1563945200
cd ..
#1563945203
cd output/
#1563945204
ll
#1563945211
rm -r *
#1563945239
ll
#1563945243
scrapy list
#1563945249
code .
#1563945271
ll
#1563945283
python3 setup.py install
#1563945287
scrapy list
#1563945290
ll
#1563945302
cat extractors.json | jq
#1563945304
ll
#1563945310
cd spiders/
#1563945311
ll
#1563945316
code .
#1563945394
cd ..
#1563945395
ll
#1563945397
cd ..
#1563945399
ll
#1563945420
rm -r .idea/ input/ portia_webmotors/ output/ tests/ .vscode/ 
#1563945424
sudo rm -r .idea/ input/ portia_webmotors/ output/ tests/ .vscode/ 
#1563945428
ll
#1563945623
rm -rf java_error_in_PYCHARM.hprof .mysql_history portia/ portia_projects/
#1563945626
sudo rm -rf java_error_in_PYCHARM.hprof .mysql_history portia/ portia_projects/
#1563945630
ll
#1563945666
sudo apt-get purge code
#1563945679
sudo dpkg --remove visual-studio-code
#1563945716
which code
#1563945747
sudo snap remove /snap/bin/code
#1563945752
sudo snap remove code
#1563945758
code .
#1563945767
ll
#1563945790
rm -r .vscode/
#1563945795
cd .config/
#1563945796
ll
#1563945929
code .
#1563947455
cd ..
#1563947455
ll
#1563947460
cd projetos/
#1563947461
ll
#1563947462
code .
#1563947498
cd crawler-and-scrapping/
#1563947499
ll
#1563947508
code .
#1563947539
cd ..
#1563947540
ll
#1563947544
cd challenges/
#1563947544
ll
#1563947551
cd challenge-spinver/
#1563947552
ll
#1563947571
scrapy startproject webmotors
#1563947574
cd webmotors/
#1563947575
ll
#1563947601
cd ..
#1563947604
code .
#1563947621
charm .
#1563947627
sudo snap install charm
#1563947635
charm .
#1563947654
ll
#1563947741
scrapy genspider cars
#1563947751
scrapy genspider cars www.webmotors.com.br
#1563947989
scrapy runspider quotes.py
#1563947995
ll
#1563947998
cd webmotors/
#1563947998
ll
#1563948003
cd webmotors/
#1563948004
ll
#1563948012
scrapy runspider spiders/quotes.py
#1563948019
tree
#1563948031
scrapy runspider spiders/cars.py
#1563948204
ll
#1563948235
scrapy runspider spiders/cars.py
#1563948361
scrapy 
#1563948365
scrapy  shell
#1563948388
source ../../venv/bin/activate
#1563948389
ll
#1563948397
scrapy
#1563948416
scrapy shell
#1563948492
scrapy
#1563948568
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563948624
quit()
quit()
#1563948630
ll
#1563948780
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563948784
ll
#1563948787
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563948819
scrapy shell 
#1563948867
ll
#1563948925
//*[@id="IdDoAnuncioDefault_28198915"]/div/div[1]/h2
#1563949875
scrapy runspider spiders/cars.py
#1563948988
python3
#1563950200
scrapy list
#1563950210
scrapy crawl cars
#1563950238
scrapy list
#1563950369
scrapy crawl cars
#1563950439
//*[@id="CardVehicle_28198915"]
#1563950449
ll
#1563950452
cd ..
#1563950453
ll
#1563950465
sudo rm -r venv/
#1563950476
virtualenv -p python3 venv
#1563950482
ll
#1563950487
pip3 install scrapy
#1563950495
pip freeze
#1563950510
pip3 freeze
#1563950523
source venv/bin/activate
#1563950528
pip3 install scrapy
#1563950540
pip3 freeze
#1563950550
ll
#1563950555
rm -r webmotors/
#1563950575
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563950619
pip install scrapy-useragents
#1563950627
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563950648
ll
#1563950655
scrapy -h
#1563950667
scrapy startproject webmotors
#1563950683
scrapy genspider cars
#1563950712
scrapy genspider cars https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563950724
kk
#1563950724
ll
#1563950728
cd webmotors/
#1563950728
ll
#1563950734
scrapy list
#1563950745
scrapy crawl cars
#1563950757
cd ..
#1563950759
code .
#1563950780
cd
#1563950782
ll
#1563950901
scrapy list
#1563950904
scrapy crawl cars
#1563952235
scrapy shell https://stackoverflow.com
#1563952254
source ../venv/bin/activate
#1563952256
scrapy shell https://stackoverflow.com
#1563952573
scrapy shell https://www.webmotors.com.br/carros/estoque?idcmpint=t1:c17:m07:webmotors:busca::verofertas&estadocidade=estoque
#1563952665
cd ..
#1563952666
ll
#1563952669
cd ..
#1563952678
cd crawler-and-scrapping/
#1563952684
git clone git clone git@github.com:lidimayra/scrapy-basics.git && cd scrapy-basics
#1563952691
git clone git clone git@github.com:lidimayra/scrapy-basics.git
#1563952709
git clone git@github.com:lidimayra/scrapy-basics.git && cd scrapy-basics
#1563952714
ll
#1563952720
scrapy crawl most_popular_movies
#1563952766
code .
#1563953765
scrapy crawl most_popular_movies
#1563953812
ll
#1563953819
python setup.py install
#1563953820
ll
#1563953822
scrapy crawl most_popular_movies
#1563953882
python setup.py install
#1563953884
scrapy crawl most_popular_movies
#1563953923
python setup.py install
#1563953925
scrapy crawl most_popular_movies
#1563953935
python setup.py install
#1563953936
scrapy crawl most_popular_movies
#1563954136
python setup.py install
#1563954138
scrapy crawl most_popular_movies
#1563954172
python setup.py install
#1563954172
scrapy crawl most_popular_movies
#1563954738
ll
#1563954740
cd webmotors/
#1563954741
ll
#1563954745
cd ..
#1563954748
ll
#1563954752
scrapy crawl cars
#1563955071
python setup.py install
#1563955072
scrapy crawl most_popular_movies
#1563955589
wget https://www.webmotors.com.br/carros/
#1563955689
curl -A "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955702
curl -A "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955726
wget  "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955738
wget  -h | grp agent
#1563955743
wget  -h | grep agent
#1563955753
wget  -U "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955773
wget -I -U "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955786
curl -I -U "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955804
curl -I -A "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0" https://www.webmotors.com.br/carros/
#1563955860
curl -H "User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.89 Safari/537.36" http://stackoverflow.com/questions/28760694/how-to-use-curl-to-get-a-get-request-exactly-same-as-using-chrome
#1563955882
curl -H "User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.89 Safari/537.36" www.webmotors.com.br
#1563955979
scrapy crawl cars
#1563958291
cd ..
#1563958291
ll
#1563958305
code .
#1563958347
ll
#1563958366
python3 webmotors/spiders/cars.py 
#1563958377
pip3 install requests
#1563958382
python3 webmotors/spiders/cars.py 
#1563958404
pip install beautifulsoup4
#1563958412
python3 webmotors/spiders/cars.py 
#1563958979
pip install --upgrade certifi
#1563958987
python3 webmotors/spiders/cars.py 
#1563961328
curl -H "Content-type: application/json" 'https://api.agenty.com/v1/agents/scraping/5792zezroj?apikey=ebfc6fac207bf1b425af74a61c247365'
#1563961335
curl -H "Content-type: application/json" 'https://api.agenty.com/v1/agents/scraping/5792zezroj?apikey=ebfc6fac207bf1b425af74a61c247365' | jq
#1563962956
curl https://api.apify.com/v2/acts/nFJndFXA5zjCTuudP/runs/K2TKNYn63eH3bgemT
#1563963030
curl "http://api.scraperapi.com?api_key=53ebc58c86de72bb6b5e166e28597843&url=http://httpbin.org/ip"
#1563963259
curl -L https://parsehub.com/static/client/parsehub.tar.gz | tar -xzf - -C /tmp && \ 
#1563963546
sudo mv /tmp/parsehub /opt/ && \ 
#1563963612
sudo mv /tmp/parsehub /opt
#1563963620
ll
#1563963626
sudo ln -s /opt/parsehub/parsehub /usr/local/bin/
#1563963637
parsehub
#1564012721
cd ..
#1564012722
ll
#1564012725
cd ..
#1564012726
ll
#1564012753
cd ..
#1564012754
ll
#1564012760
cd crawler-and-scrapping/
#1564012760
ll
#1564012765
git status
#1564012773
git add --all
#1564012786
git rm --cached scrapy-basics
#1564012796
ll
#1564012862
code .
#1564013111
mkdir all_digital
#1564013115
cd all_digital/
#1564013116
ll
#1564013141
scrapy startproject crawl_pan
#1564013177
scrapy genspider login https://panconsig.pansolucoes.com.br/WebAutorizador/Login/AC.UI.LOGIN.aspx
#1564013180
ll
#1564013187
scrapy list
#1564013189
ll
#1564013197
cd ..
#1564013199
code .
#1564013762
pip3 install fill_login_form
#1564013828
git clone https://github.com/scrapy/loginform.git
#1564013876
ll
#1564013884
python3 login.py
#1564014066
tox
#1564014069
sudo apt install tox
#1564014088
tox
#1564014092
ll
#1564014634
scrapy list
#1564014638
ll
#1564014641
cd crawl_pan/
#1564014642
ll
#1564014644
scrapy list
#1564014651
crapy login
#1564014659
scrapy crawl login
#1564014819
ll
#1564014825
cd crawl_pan/
#1564014826
ll
#1564022368
cd scrapy-basics/
#1564022369
ll
#1564022406
sudo rm -r .git/ LICENSE README.md scrapinghub.yml 
#1564022410
ll
#1564022411
cd ..
#1564022414
git status
#1564022420
git add --all
#1564022449
git commit -m "feat"
#1564022453
git push origin master 
#1564022468
git pull origin master 
#1564022475
git push origin master 
#1564022496
cd ..
#1564022497
ll
#1564022498
cd ..
#1564022499
ll
#1564022502
cd ..
#1564022503
ll
#1564022513
rm -r all_digital/ 
#1564022518
rm -rf all_digital/ 
#1564022534
cd challenge-spinver/
#1564022534
ll
#1564022538
cd webmotors/
#1564022539
ll
#1564022543
web
#1564022551
cd webmotors/
#1564022552
ll
#1564022555
cd spiders/
#1564022556
ll
#1564022745
cd ..
#1564022745
ll
#1564022757
cd learning-prolog/
#1564022758
ll
#1564022762
git status
#1564022770
git pull origin master 
#1564022830
cd ..
#1564022836
ll
#1564022848
rm -r challenge-spinver/
#1564022850
ll
#1564022854
deactivate
#1564022856
ll
#1564022882
code .
#1564023019
cd ..
#1564023025
cd devops/
#1564023027
code .
#1564023336
lsb_release -cs
#1564023627
pip freeze | grep azure
#1564023632
pip3 freeze | grep azure
#1564024116
git status
#1564024119
git add --all
#1564024128
git commit -m "feat: azure"
#1564024131
git push origin master 
#1564055758
cd ..
#1564055759
ll
#1564055761
cd ..
#1564055765
cd
#1564055776
cd /
#1564055777
ll
#1564055780
cd mnt/
#1564055781
ll
#1564055783
cd ..
#1564055784
ll
#1564055788
cd media/
#1564055788
ll
#1564055793
tree
#1564055807
ll
#1564055808
cd campos/
#1564055809
ll
#1564055816
cd SAMSUNG/
#1564055817
ll
#1564055818
df
#1564055821
df .
#1564055826
du .
#1564055831
du 
#1564055841
df -h .
#1564055860
pwd
#1564055887
ll
#1564055897
cd backup
#1564055897
ll
#1564055903
cd avell/
#1564055903
ll
#1564055918
rm -r 'VirtualBox VMs'/
#1564055922
ll
#1564055926
cd projetos/
#1564055927
ll
#1564055929
cd ..
#1564055930
ll
#1564055940
rm -rf projetos/
#1564056065
ll
#1564056067
df -h
#1564056080
df -h .
#1564056085
cp -r -v projetos/ /media/campos/SAMSUNG/backup/avell/
#1564059365
dc projetos/
#1564059368
cd projetos/
#1564059368
ll
#1564059371
cd
#1564059373
cd projetos/
#1564059374
ll
#1564059378
df -h .
#1564064003
ll
#1564064007
cd artificial_inteligence/
#1564064007
ll
#1564064016
source ../venv_global/bin/activate
#1564064024
jupyter-notebook 
#1564273476
cd projetos/
#1564273476
ll
#1564273479
cd algoritms/
#1564273483
git status
#1564273488
cd ..
#1564273492
ll
#1564273501
cd artificial_inteligence/
#1564273502
kk
#1564273503
[ll
#1564273504
ll
#1564273507
cd data-science/
#1564273507
ll
#1564273510
git status
#1564273514
git add --all
#1564273522
git commit -m "refactor"
#1564273524
ll
#1564273541
git push origin master 
#1564273549
cd ..
#1564273549
ll
#1564273552
cd ..
#1564273553
ll
#1564273561
cd becoming-a-expert-python/
#1564273563
ll
#1564273565
cd ..
#1564273567
ll
#1564273570
cd seguranca/
#1564273571
ll
#1564273573
git status
#1564273577
git add --all
#1564273585
git commit -m "refactor"
#1564273588
git push origin master 
#1564273595
cd ..
#1564273596
ll
#1564273603
cd learning-
#1564273606
cd learning-prolog/
#1564273606
ll
#1564273610
git status
#1564273612
cd ..
#1564273612
ll
#1564273616
cd redes/
#1564273618
ll
#1564273629
cat README.md 
#1564319369
ll
#1564319394
cat .bash_history 
#1564319402
cat .bash_eternal_history 
#1564319414
cat .bash_history 
#1564319417
cat .bash_eternal_history 
#1618409641
cd ~
#1618409643
ll
#1618409648
cd /ssddisk/
#1618409649
ll
#1618409652
cd SAT_BIG_DATA/
#1618409652
ll
#1618409700
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1618409700
docker-compose up -d
#1618409721
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1618409738
docker-compose up -d
#1618409759
source venv/bin/activate
#1618409763
set -a # export all variables
#1618409765
source configs/.env
#1618409771
airflow db init
#1618409793
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1618410127
ll
#1618410136
ll venv
#1618410144
which python
#1618410216
LL
#1618410217
ll
#1618410221
cd ..
#1618410222
ll
#1618410237
cd bda-operation/
#1618410237
ll
#1618410258
cd bda-ops-infra-as-code/
#1618410259
ll
#1618410294
cat set_personal_config.sh 
#1618410310
sudo vim ~/.bashrc
#1618410328
cat set_personal_config.sh 
#1618410334
vim set_personal_config.sh 
#1618410342
cd ..
#1618410343
ll
#1618410347
cd bda-batch-data-pipeline/
#1618410348
ll
#1618410730
python3 plugins/hooks/utils/prepare_env.py 
#1618410999
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618411005
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1618411011
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1618411015
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618411019
ll
#1618411094
docker ps
#1618411686
ll
#1618411801
user
#1618411807
whoami
#1618412291
python3 plugins/hooks/utils/prepare_env.py 
#1618412567
ll
#1618412585
id
#1618412616
python3 plugins/hooks/utils/prepare_env.py 
#1618438339
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1618438352
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1618438355
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1618438396
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618438402
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1618438405
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1618438411
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618438434
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1618438434
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1618438435
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1618438441
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1618438450
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618438456
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618492040
ll
#1618492100
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1618492101
ll
#1618492150
set -a # export all variables
#1618492152
source configs/.env
#1618492155
source venv/bin/activate
#1618492160
ll
#1618492597
python3 plugins/hooks/utils/prepare_env.py 
#1618438461
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid
#1618584149
airflow db reset
#1618584312
set -a # export all variables
#1618584315
source venv/bin/activate
#1618584317
source configs/.env
#1618584329
python3 plugins/hooks/utils/prepare_env.py 
#1618584373
source venv/bin/activate
#1618584376
source configs/.env
#1618584386
docker rm -vf $(docker ps -a -q)
#1618584389
docker rmi -f $(docker images -a -q)
#1618584392
docker volume prune --force
#1618584392
docker network prune --force
#1618584393
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1618584403
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1618584403
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1618584406
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1618584408
ll
#1618584417
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1618584417
docker-compose up -d
#1618584437
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1618584438
docker-compose up -d
#1618584459
airflow db init
#1618584472
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1618584491
python3 plugins/hooks/utils/prepare_env.py 
#1618584553
kinit bigdata
#1618584558
python3 plugins/hooks/utils/prepare_env.py 
#1618584570
airflow db init
#1618584575
python3 plugins/hooks/utils/prepare_env.py 
#1618584589
docker ps -a
#1618584772
python3 plugins/hooks/utils/prepare_env.py 
#1618584924
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618584980
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1618584984
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1618584987
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618585589
hdfs dfs -text /data/raw/ccg/2018/11/04 | jq
#1618585595
hdfs dfs -text /data/raw/ccg/2018/11/04/* | jq
#1618585595
hdfs dfs -text /data/raw/ccg/2018/11/04/* | jq
#1618585595
hdfs dfs -text /data/raw/ccg/2018/11/04/* | jq
#1618592326
docker rm -vf $(docker ps -a -q)
#1618592328
docker rmi -f $(docker images -a -q)
#1618592329
docker volume prune --force
#1618592329
docker network prune --force
#1618592330
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1618592336
docker rm -vf $(docker ps -a -q)
#1618592336
docker rmi -f $(docker images -a -q)
#1618592336
docker volume prune --force
#1618592337
docker network prune --force
#1618592337
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1618592337
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1618592337
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1618592340
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1618592343
source venv/bin/activate
#1618592346
set -a # export all variables
#1618592348
source configs/.env
#1618592351
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1618592351
docker-compose up -d
#1618592372
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1618592385
docker-compose up -d
#1618592407
airflow db init
#1618592422
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1618592439
python3 plugins/hooks/utils/prepare_env.py 
#1618606204
git add
#1618606209
git add --all
#1618606211
cd ..
#1618606212
git add --all
#1618606240
git commit -m "refactor: alterar query de criação de tabelas"
#1618606253
git push origin master
#1618606270
git status
#1618606278
cd bda-batch-data-pipeline/
#1618606279
ll
#1618606297
python3 plugins/hooks/utils/prepare_env.py 
#1618613690
C
#1618613691
python3 plugins/hooks/utils/prepare_env.py 
#1618631370
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618631378
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1618631383
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618632195
python3 plugins/hooks/utils/prepare_env.py 
#1618638850
hdfs dfs -text /data/raw/acc/2008/02/01/* | jq
#1618638880
hdfs dfs -text /data/raw/acc/2008/02/01/*
#1618642339
ll
#1618642353
sudo rm -rf logs/*
#1618642444
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1618642444
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1618642444
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1618642448
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1618642458
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1618642466
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1618642472
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1618642476
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1618645361
python3 plugins/hooks/utils/prepare_env.py 
#1618655088
hdfs dfs -text /data/raw/acc/2016/02/01/*
#1618655100
hdfs dfs -text /data/raw/acc/2016/02/01/* | jq
#1618656397
python3 plugins/hooks/utils/prepare_env.py 
#1618701499
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1618701651
python3 plugins/hooks/utils/prepare_env.py 
#1618792716
pip3 install cryptography
#1618793392
pip3 install pyOpenSSL
#1618794560
pip3 uninstall cryptography
#1618794766
pip3 install cryptography
#1618794917
pip3 uninstall cryptography
#1618794926
pip3 install cryptography==3.3.1
#1618807146
hdfs dfs -text /data/raw/acc/2017/02/01/* | jq
#1618807184
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618809344
venv-pack -o pyspark_venv.tar.gz
#1618809387
pip install venv-pack
#1618809401
venv-pack -o venv.tar.gz
#1618809442
ll
#1618809535
pwd
#1618811043
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618811598
cat /tmp/import_file
#1618811956
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618815442
1;1;120;120;1;0x65;1;9c
#1618815445
l
#1618815451
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618815942
1;1;120;120;1;0x65;1;9c
#1618815945
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618816429
1;1;120;120;1;0x65;1;9c
#1618816431
ll
#1618816438
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618818126
python3 plugins/hooks/utils/prepare_env.py 
#1618818958
hdfs dfs -text /data/raw/ccg/2021/04/18/* | jq
#1618821479
python3 plugins/hooks/utils/prepare_env.py 
#1618826406
hdfs dfs -text /data/raw/acc/2017/02/01/* | grep 36131964
#1618826412
1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c
#1618826423
hdfs dfs -text /data/raw/acc/2017/02/01/* | jq
#1618826464
1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c
#1618826476
hdfs dfs -text /data/raw/acc/2021/02/01/* | jq
#1618900060
ll
#1618900358
git status
#1618900362
git add --all
#1618900400
git status
#1618900404
git add --all
#1618900406
cd ..
#1618900407
git add --all
#1618900410
git status
#1618900437
git commit -m "refactor: adicionar acc, ccg e ccc"
#1618900441
git push origin master
#1618900447
ll
#1619079445
kinit
#1619097608
cd /ssddisk/SAT_BIG_DATA/
#1619097609
ll
#1619097620
cd bda-batch-data-pipeline/
#1619097620
ll
#1619097629
li
#1619097631
cd libs/
#1619097632
ll
#1619097748
wget https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/3.0.1/spark-avro_2.12-3.0.1.jar
#1619097750
ll
#1619097968
git clone https://github.com/RedisLabs/spark-redis.git
#1619097972
cd spark-redis
#1619097976
mvn clean package -DskipTests
#1619098049
sudo yum install maven
#1619098086
wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
#1619098089
yum install -y apache-maven
#1619098093
sudo yum install -y apache-maven
#1619098095
ll
#1619098147
cd build/
#1619098147
ll
#1619098150
cd ..
#1619098150
ll
#1619098173
sudo yum install maven
#1619098187
wget https://www-us.apache.org/dist/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz -P /tmp
#1619098193
sudo tar xf /tmp/apache-maven-3.6.0-bin.tar.gz -C /opt
#1619098252
ll
#1619098253
cd ..
#1619098253
ll
#1619098267
sudo rm -rf spark-redis*
#1619098423
cd ..
#1619098426
ll
#1619098428
cd SAT_BIG_DATA/
#1619098428
ll
#1619098445
mv spark-redis_2.11-2.6.0-SNAPSHOT-jar-with-dependencies.jar bda-batch-data-pipeline/libs/
#1619098446
ll
#1619112544
cd bda-batch-data-pipeline/
#1619112547
set -a # export all variables
#1619112549
source configs/.env
#1619112553
source venv/bin/activate
#1619112558
python3 plugins/hooks/utils/prepare_env.py 
#1619175597
cd /ssddisk/SAT_BIG_DATA/
#1619175599
ll
#1619175600
cd bda-
#1619175605
cd bda-batch-data-pipeline/
#1619175618
hdfs dfs -text /data/transformed/nfe_anual/t3/2019/* | jq
#1619176179
set -a # export all variables
#1619176181
source venv/bin/activate
#1619176183
source configs/.env
#1619176185
ll
#1619179763
hdfs dfs -text /data/transformed/nfe_anual/t3/2019/* | jq
#1619193250
hdfs dfs -text /data/raw/acc/2021/04/01 | jq
#1619193262
hdfs dfs -text /data/raw/acc/2021/04/01/* | jq
#1619257066
hdfs dfs -text /data/raw/acc/2021/03/01/* | jq
#1619267249
cd ..
#1619267254
git add --all
#1619267258
git commit -m "refactor: adicionar acc, ccg e ccc"
#1619267273
git push origin master
#1619267999
hdfs dfs -text /data/raw/acc/2021/04/11/* | jq
#1619268569
1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x
#1619268578
hdfs dfs -text /data/raw/acc/2021/03/31/* | jq
#1619268600
1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c
#1619268662
hdfs dfs -text /data/raw/acc/2021/04/11/* | jq
#1619268842
1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c
#1619268853
hdfs dfs -du -h /data/raw/acc/2021/04/11/* 
#1619281012
hdfs dfs -du -h /data/raw/acc/2021/03/02/* |jq
#1619281015
hdfs dfs -du -h /data/raw/acc/2021/03/02/* | jq
#1619281170
hdfs dfs -du -h /data/raw/acc/2021/04/01/* | jq
#1619281187
hdfs dfs -text /data/raw/acc/2021/04/01/* | jq
#1619281239
hdfs dfs -text /data/raw/acc/2021/03/02/* | jq
#1619283388
hdfs dfs -text /data/raw/acc/2021/02/03/* | jq
#1619283427
hdfs dfs -text /data/raw/acc/2021/02/03/* | jq | grep T0005273-002.p7b
#1619283447
hdfs dfs -text /data/raw/acc/2021/02/03/* | grep T0005273-002.p7b | jq
#1619283512
hdfs dfs -text /data/raw/acc/2021/02/03/* | jq
#1619283558
hdfs dfs -text /data/raw/acc/2021/02/03/* | wc -l 
#1619289603
hdfs dfs -text /data/raw/acc/2021/01/02/* | wc -l 
#1619289622
hdfs dfs -text /data/raw/acc/2021/02/01/* | wc -l 
#1619289633
hdfs dfs -text /data/raw/acc/2021/02/01/* | jq
#1619289853
hdfs dfs -text /data/raw/acc/2021/02/01/* | grep p7 | jq
#1619289931
hdfs dfs -text /data/raw/acc/2021/02/01/* | grep p7b | jq
#1619289990
hdfs dfs -text /data/raw/acc/2021/02/01/* | grep AAR_NOME_ARQUIVO
#1619290108
hdfs dfs -text /data/raw/acc/2018/05/01/* | grep T0003592-002.p7b | jq
#1619351513
python3 bda-batch-data-pipeline/tests/convert_type_spark.py 
#1619437604
cd /ssddisk/SAT_BIG_DATA/
#1619437619
python3 bda-batch-data-pipeline/tests/convert_type_spark.py 
#1619437635
source bda-batch-data-pipeline/configs/.env
#1619437645
source bda-batch-data-pipeline/venv/bin/activate
#1619437648
python3 bda-batch-data-pipeline/tests/convert_type_spark.py 
#1619437659
set -a # export all variables
#1619437663
source configs/.env
#1619437670
source bda-batch-data-pipeline/configs/.env
#1619437672
python3 bda-batch-data-pipeline/tests/convert_type_spark.py 
#1619453716
kinit bigdata
#1619460105
cd bda-batch-data-pipeline/
#1619460105
ll
#1619460109
python3 plugins/hooks/utils/prepare_env.py 
#1619466436
python3 dags/import.py 
#1619528222
git status
#1619528226
git add --all
#1619528230
git commit -m "refactor: adicionar acc, ccg e ccc"
#1619528233
git push origin master
#1619528966
hdfs dfs -text /data/raw/ccc/2020/01/01/* | jq
#1619528981
ll
#1619528992
hdfs dfs -text /data/raw/ccc/2020/01/01/* | jq
#1619529027
1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c
#1619529598
hdfs dfs -text /data/raw/ccg/2019/06/01/* | jq
#1619529753
hdfs dfs -text /data/raw/ccg/2020/06/01/* | jq
#1619529832
hdfs dfs -du -h /data/raw/ccg/2020
#1619529836
hdfs dfs -du -h /data/raw/ccg/2020/
#1619529940
hdfs dfs -du -h /data/raw/ccg/
#1619529980
hdfs dfs -text /data/raw/ccg/2018/08/01/* | jq
#1619530250
hdfs dfs -text /data/raw/ccc/2020/02/01/* | jq
#1619531261
hdfs dfs -text /data/raw/acc/2008/02/01/* | jq
#1619533851
hdfs dfs -text /data/raw/acc/2018/03/01/* | jq
#1619538028
hdfs dfs -text /data/raw/acc/2016/06/01/* | jq
#1619538042
hdfs dfs -text /data/raw/acc/2015/06/01/* | jq
#1619629437
hdfs dfs -text /data/raw/ccg/2021/02/01/* | jq
#1619629498
hdfs dfs -text /data/raw/ccc/2021/02/01/* | jq
#1619632490
hdfs dfs -text /data/raw/ccc/2019/03/01/* | jq
#1619632497
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619715375
hdfs dfs -text /data/raw/acc/2019/07/04/* | jq
#1619715400
hdfs dfs -text /data/raw/acc/2019/03/01/* | count -l
#1619715416
hdfs dfs -text /data/raw/acc/2019/03/01/* | wc -l
#1619715423
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619717168
hdfs dfs -text /data/raw/acc/2017/07/14/* | jq
#1619720337
hdfs dfs -text /data/raw/acc/2017/07/14/* | wc -l
#1619726386
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619728060
hdfs dfs -text /data/raw/acc/2017/07/14/* | wc -l
#1619728090
hdfs dfs -text /data/raw/acc/2020/07/14/* | wc -l
#1619728139
hdfs dfs -text /data/raw/acc/2020/07/14/* | jq
#1619728437
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619737037
yarn
#1619737049
yarn logs
#1619737065
yarn 
#1619737077
yarn node
#1619737085
yarn node -list
#1619737100
yarn 
#1619737105
yarn cluster
#1619765110
./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 lib/spark-examples*.jar 10
#1619765129
su spark
#1619765164
cd /ssddisk/SAT_BIG_DATA/
#1619765170
cd bda-batch-data-pipeline/
#1619765171
ll
#1619765177
set -a # export all variables
#1619765185
source configs/.env
#1619765190
source da-batch-data-pipeline/configs/.env
#1619765205
source venv/bin/activate
#1619765812
docker rm -vf $(docker ps -a -q)
#1619765814
docker rmi -f $(docker images -a -q)
#1619765816
docker volume prune --force
#1619765816
docker network prune --force
#1619765817
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1619765826
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1619765826
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1619765827
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1619765837
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1619765838
docker-compose up -d
#1619765857
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1619765875
docker-compose up -d
#1619765899
airflow db init
#1619765914
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1619765934
python3 plugins/hooks/utils/prepare_env.py 
#1619765953
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1619765961
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1619765969
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1619790490
hadoop
#1619868398
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1619868401
ll
#1619868407
python3 plugins/hooks/utils/prepare_env.py 
#1619868410
set -a # export all variables
#1619868413
source venv/bin/activate
#1619868420
source configs/.env
#1619868422
set -a # export all variables
#1619868424
python3 plugins/hooks/utils/prepare_env.py 
#1619869706
git add --all
#1619869709
git commit -m "refactor: adicionar acc, ccg e ccc"
#1619869731
python3 plugins/hooks/utils/prepare_env.py 
#1619870418
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619871810
python3 plugins/hooks/utils/prepare_env.py 
#1619873099
airflow db reset
#1619873132
python3 plugins/hooks/utils/prepare_env.py 
#1619879904
docker rm -vf $(docker ps -a -q)
#1619879907
docker rmi -f $(docker images -a -q)
#1619879909
docker volume prune --force
#1619879909
docker network prune --force
#1619879911
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1619879922
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1619879922
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1619879925
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1619879934
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1619879934
docker-compose up -d
#1619879952
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1619879953
docker-compose up -d
#1619879975
airflow db init
#1619881110
python3 plugins/hooks/utils/prepare_env.py 
#1619881122
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1619881163
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1619881168
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1619881203
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1619882162
python3 plugins/hooks/utils/prepare_env.py 
#1619891348
htop
#1619891403
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1619891412
docker rm -vf $(docker ps -a -q)
#1619891415
docker rmi -f $(docker images -a -q)
#1619891418
docker volume prune --force
#1619891418
docker network prune --force
#1619891420
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1619891421
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1619891421
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1619891424
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1619891434
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1619891434
docker-compose up -d
#1619891453
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1619891453
docker-compose up -d
#1619891478
airflow db init
#1619891493
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1619891508
python3 plugins/hooks/utils/prepare_env.py 
#1619891521
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1619891528
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1619891532
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1619891536
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1619891954
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619892284
yum install gcc gcc-c++ python-devel snappy-devel
#1619892290
sudo su
#1619893381
hdfs dfs -text /data/raw/acc/2019/03/01/* | jq
#1619929598
venv-pack -o venv.tar.gz
#1619929629
ll
#1619929630
pwd
#1620045834
kinit
#1620045840
klist
#1620082228
ll
#1620082236
hdfs dfs -cp 
#1620082269
hdfs dfs -cp /data/raw/acc* /tmp
#1620105719
python3 plugins/hooks/utils/prepare_env.py 
#1620111606
ll
#1620111627
hdfs dfs -cp  /tmp/acc* /data/raw/
#1620155779
ll
#1620155796
hdfs dfsadmin -report
#1620155826
sudo -u hdfs -i
#1620161745
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620161747
cd ..
#1620161812
alabaster==0.7.12
#1620161812
alembic==1.4.2
#1620161812
amqp==2.6.1
#1620161812
apache-airflow==1.10.12
#1620161812
apipkg==1.5
#1620161812
apispec==1.3.3
#1620161813
appdirs==1.4.4
#1620161813
argcomplete==1.12.0
#1620161813
astroid==2.5
#1620161813
attrs==19.3.0
#1620161813
autopep8==1.5.5
#1620161813
aws-sam-translator==1.26.0
#1620161813
aws-xray-sdk==2.6.0
#1620161813
Babel==2.8.0
#1620161814
backcall==0.2.0
#1620161814
bcrypt==3.2.0
#1620161814
beautifulsoup4==4.7.1
#1620161814
billiard==3.6.3.0
#1620161814
boto==2.49.0
#1620161814
boto3==1.14.56
#1620161814
botocore==1.17.56
#1620161814
cached-property==1.5.1
#1620161814
cachetools==4.1.1
#1620161815
cattrs==1.0.0
#1620161815
celery==4.4.7
#1620161815
certifi==2020.6.20
#1620161815
cffi==1.14.2
#1620161815
cfgv==3.2.0
#1620161815
cfn-lint==0.35.1
#1620161815
cgroupspy==0.1.6
#1620161815
chardet==3.0.4
#1620161821
ll
#1620161823
cd gabriel/
#1620161824
ll
#1620161827
cd ..
#1620161828
ll
#1620161833
cd gabriel/
#1620161833
ll
#1620161843
cat requirements.txt 
#1620183052
hdfs fsck /
#1620183119
sudo -u hdfs -i
#1620183415
hdfs dfs -cp  /tmp/acc* /data/raw/
#1620186693
hdfs dfs -text /data/raw/acc/2014/01/01/* | jq
#1620186941
hdfs dfs -text /data/raw/acc/2014/01/01/* | wc -l
#1620187017
avro 
#1620187082
cd ..
#1620187083
ll
#1620187090
cd bda-batch-data-pipeline/
#1620187090
ll
#1620187095
cd libs/
#1620187096
ll
#1620187267
hdfs dfs -text /data/raw/acc/2014/12/01/* | wc -l
#1620187324
hdfs dfs -text /data/raw/acc/2014/12/01/* | jq[
#1620187326
hdfs dfs -text /data/raw/acc/2014/12/01/* | jq
#1620187599
hdfs dfs -text /data/raw/acc/2014/01/01/* | wc -l
#1620187915
hdfs dfs -text /data/raw/acc/2014/02/01/* | wc -l
#1620187943
hdfs dfs -text /data/raw/acc/2014/03/01/* | wc -l
#1620188229
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         concat $(hadoop fs -ls /data/raw/acc/2014/04/01/* | awk '{printf "%s ", $NF}')                         /data/raw/acc/2014/04/01/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2014/04/01).avro.snappy
#1620188319
yarn jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         concat $(hadoop fs -ls /data/raw/acc/2014/04/01/* | awk '{printf "%s ", $NF}')                         /data/raw/acc/2014/04/01/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2014/04/01).avro.snappy
#1620201908
hdfs dfs -cp  /data/raw/acc* /tmp/
#1620202535
hdfs dfs -cp  /tmp/acc* /data/raw/
#1620202794
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620203008
hdfs dfs -text /data/raw/acc/2021/01/01/* | wc -l
#1620203196
hdfs dfs -du /data/raw/acc/2021/*
#1620203204
hdfs dfs -du -h /data/raw/acc/2021/*
#1620203258
ll
#1620203262
cd ..
#1620203264
ll
#1620203348
hdfs dfs -cp  /tmp/acc* /data/raw/
#1620207011
hdfs dfs -mv /data/raw/acc/2021/01/06/*                     /data/raw/acc/2021/01/06/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/01/06).avro.snappy
#1620207063
hdfs dfs -mv /data/raw/acc/2021/02/22/*                     /data/raw/acc/2021/02/22/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/02/22).avro.snappy
#1620207104
hdfs dfs -du -h /data/raw/2021/02/*
#1620207111
hdfs dfs -du -h /data/raw/2021/02*
#1620207128
hdfs dfs -du -h /data/raw/acc/2021/02*
#1620207157
hdfs dfs -mv /data/raw/acc/2021/02/23/*                     /data/raw/acc/2021/02/23/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/02/23).avro.snappy
#1620208700
hdfs dfs -mv /data/raw/acc/2021/02/23/*                     /data/raw/acc/2021/02/23/acc_original.avro.snappy
#1620209087
hdfs dfs -mv /data/raw/acc/2021/02/23/*                     /data/raw/acc/2021/02/23/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/02/23).avro.snappy
#1620209257
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/02/2
#1620209274
hdfs dfs -mv /data/raw/acc/2021/02/23/*                     /data/raw/acc/2021/02/23/acc_original.avro.snappy
#1620299792
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620299804
source venv/bin/activate
#1620299807
set -a # export all variables
#1620299811
source configs/.env
#1620299822
docker rm -vf $(docker ps -a -q)
#1620299824
docker rmi -f $(docker images -a -q)
#1620299826
docker volume prune --force
#1620299827
docker network prune --force
#1620299828
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1620299839
docker rm -vf $(docker ps -a -q)
#1620299839
docker rmi -f $(docker images -a -q)
#1620299839
docker volume prune --force
#1620299839
docker network prune --force
#1620299840
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1620299840
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1620299840
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1620299841
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1620299848
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1620299848
docker-compose up -d
#1620299866
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620299868
docker-compose up -d
#1620299889
airflow db init
#1620299905
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1620299944
python3 plugins/hooks/utils/prepare_env.py 
#1620299958
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1620299965
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1620299970
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1620299975
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1620301475
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2021/02/2
#1620301860
hadoop 
#1620301863
hadoop --version
#1620301874
hadoop version
#1620301882
ll
#1620307394
hdfs dfs -text /data/raw/acc/2021/01/01/* | wc -l
#1620308215
ll
#1620308252
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         concat $(hadoop fs -ls /data/raw/acc/2021/01/01/* | awk '{printf "%s ", $NF}')                         /data/raw/acc/2021/01/01/acc_original.avro.snappy
#1620308284
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         
#1620308334
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  getschema /data/raw/acc/2021/01/01/acc_original.avro.snappy
#1620308379
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  getmeta /data/raw/acc/2021/01/01/acc_original.avro.snappy
#1620308428
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  cat /data/raw/acc/2021/01/01/acc_original.avro.snappy
#1620308453
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  cat --limit 100 /data/raw/acc/2021/01/01/acc_original.avro.snappy
#1620308461
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         
#1620308958
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* > /data/raw/cte/2021/01/01/test.json
#1620309051
ll
#1620309062
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620309063
ll
#1620309074
touch text.json
#1620309078
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* > /data/raw/cte/2021/01/01/test.json
#1620309091
touch test.json
#1620309095
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* > /data/raw/cte/2021/01/01/test.json
#1620309101
pwd
#1620309112
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* > /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/test.json
#1620309121
ll
#1620309144
sudo chmod 777 test.json 
#1620309150
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* > /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/test.json
#1620309154
ll
#1620309163
sudo chmod 777 test.json 
#1620309168
ll
#1620309193
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/* >> /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/test.json
#1620309230
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar  tojson /data/raw/cte/2021/01/01/cte_original_2526.avro.snappy >> /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/test.json
#1620309250
ll
#1620309263
cat test.json 
#1620309263
cat test.json 
#1620309263
cat test.json 
#1620309270
cat test.json | jq
#1620329914
ll
#1620329947
rm -rf text.json test.json 
#1620329962
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620330110
hdfs dfs -text /data/raw/acc/2021/01/06/* | jq
#1620330599
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620330606
hdfs dfs -text /data/raw/acc/2021/01/06/* | jq
#1620332427
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620341838
pip install koalas
#1620341838
pip install koalas
#1620341838
pip install koalas
#1620341838
pip install koalas
#1620341838
pip install koalas
#1620341838
pip install koalas
#1620341845
source configs/.env
#1620341847
source venv/bin/activate
#1620341848
pip install koalas
#1620342024
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620342046
source venv/bin/activate
#1620342069
pip install koalas
#1620307951
hdfs dfs -text /data/raw/cte/1900/01/01/* | wc -l
#1620347069
pip install "dask[complete]"
#1620347872
pip install dask-yarn
#1620348202
ll
#1620348209
venv-pack
#1620348225
sudo rm -rf venv.tar.gz 
#1620348229
venv-pack
#1620348263
ll
#1620348265
pwd
#1620350505
hdfs dfs -cp /data/raw/acc* /tmp/
#1620350535
hdfs dfs -ls  /tmp/acc
#1620350545
hdfs dfs -ls  /tmp/acc/2021
#1620350587
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620350616
hdfs dfs -text /data/raw/acc/2021/01* | wc -l
#1620350624
hdfs dfs -text /data/raw/acc/2021/01/* | wc -l
#1620350639
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620351413
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620351423
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620351692
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620352045
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620356472
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620358776
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620358797
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620363354
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620363386
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620363392
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620363484
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620364276
hdfs dfs -cp /data/raw/acc* /tmp/
#1620364614
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620364622
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620370860
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620370867
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620370875
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620370934
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620371160
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620371314
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620371407
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620371687
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620371725
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620371913
hdfs dfs -du -h /data/raw/acc/2021/01*
#1620372996
hdfs dfs -text /data/raw/acc/2021/01/12/* | jq
#1620373122
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620373146
hdfs dfs -text /data/raw/acc/2021/01/27/* | jq
#1620373194
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620373204
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620373222
hdfs dfs -text /data/raw/acc/2021/01/29/* | jq
#1620373273
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620373985
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620374666
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620374988
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620375021
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620375049
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620375119
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620375121
set -a # export all variables
#1620375123
source venv/bin/activate
#1620375125
source configs/.env
#1620375130
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620375290
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620375396
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620375441
hdfs dfs -text /data/raw/acc/2021/01/27/* | jq
#1620405995
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620484391
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620484691
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620484699
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620484714
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620484737
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620485052
hdfs dfs -text /data/raw/acc/2021/01/27/* | jq
#1620485086
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620485529
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620485553
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620485624
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620485646
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620485661
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620485852
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620486272
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620486605
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620488911
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620489330
hdfs dfs -text /data/raw/acc/2021/01/27/*
#1620489350
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620489534
echo $HADOOP_OPTS
#1620490153
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620490232
hdfs dfs -du -h /data/raw/acc/2021/01* 
#1620490808
#HADOOP_HEAPSIZE=768 hdfs dfs -ls /path/to/hdfs/dir
#1620490932
#HADOOP_HEAPSIZE=2048 hdfs dfs -du -h /data/raw/acc/2021/01*
#1620491239
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620491332
HADOOP_HEAPSIZE=2048 hdfs dfs -du -h /data/raw/acc/2021/01*
#1620491364
HADOOP_HEAPSIZE=2048 hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620491372
HADOOP_HEAPSIZE=20048 hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620491528
HADOOP_HEAPSIZE=100048 hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620492067
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620492350
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620493612
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620493655
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620494224
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620494255
hdfs dfsadmin
#1620494315
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620494571
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620494732
ll
#1620494736
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620494737
ll
#1620494738
set -a # export all variables
#1620494740
source configs/.env
#1620494742
source venv/bin/activate
#1620494744
ll
#1620495195
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620495551
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620496042
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620496105
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620496730
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620498758
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620498764
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620499126
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620499609
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620499652
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620502727
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620503936
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620510246
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620510538
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620510702
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620513345
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620513361
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620515087
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620515306
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620515337
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620515733
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620515740
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620515749
hdfs dfs -du -h /data/raw/acc/2021/01/27/* 
#1620515759
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620515793
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620515948
65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c0$y
#1620515955
1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x
#1620516883
1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c65;1;9c1;1;120;120;1;0x1;1;120;120;1;0x65;1;9c1;1;120;120;1;0x65;1;9c65;1;9c65;1;9c
#1620517567
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620526395
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620527133
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620527402
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq | more
#1620527425
hdfs dfs -text /data/raw/acc/2021/01/*/* | more |  jq
#1620527448
hdfs dfs -text /data/raw/acc/2021/01/*/* | more
#1620527481
hdfs dfs -text /data/raw/acc/2021/01/*/* | more |  jq
#1620527529
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620527579
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620527865
hdfs dfs -text /data/raw/acc/2021/01/27/* | wc -l
#1620528245
ll
#1620528289
hdfs fsck /data/raw/acc/2021/01/27/part-0-mapred_acc_000000000000000_27-01-2021.avro -files -blocks
#1620529546
hdfs dfs -text /data/raw/acc/2021/01/*/* | more |  jq
#1620529568
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620529568
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620529568
hdfs dfs -text /data/raw/acc/2021/01/01/* | jq
#1620529765
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620530559
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620532740
hdfs dfs -text /data/raw/acc/2021/01/*/* | wc -l
#1620532775
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq[
#1620532777
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620533477
yarn 
#1620533502
yarn application
#1620533522
yarn application -appId application_1620300645822_0081
#1620533535
yarn application -kill application_1620300645822_0081
#1620533571
yarn application -kill application_1620300645822_0084
#1620539215
hdfs dfs -text /data/raw/nfe/2021/04/19/* | jq
#1620539570
hdfs dfs -text /data/raw/nfe/2021/04/19/* | wc -l
#1620559557
yarn application
#1620559576
yarn application -appId -kill application_1620300645822_0228
#1620559597
yarn application -kill application_1620300645822_0228
#1620584139
cd venv/lib/python3.6/site-packages/pyspark/
#1620584140
ll
#1620584156
cd bin/
#1620584156
ll
#1620584166
cd ..
#1620584172
ll
#1620584175
zip
#1620584196
zip venv.ZIP venv/
#1620584199
LL
#1620584200
ll
#1620584216
sudo rm -rf venv.tar.gz venv.ZIP 
#1620584253
zip -r venv.zip venv/
#1620584307
pp
#1620584308
ll
#1620584312
pwd
#1620586243
python setup.py bdist_egg
#1620586247
ll
#1620586359
cd bda_batch.egg-info/
#1620586359
ll
#1620586362
cd ..
#1620586386
sudo rm -rf bda_batch.egg-info/ dist/ build/
#1620586848
venv-pack o pyspark_venv.tar.gz
#1620586854
venv-pack -o pyspark_venv.tar.gz
#1620586891
ll
#1620586921
sudo rm -rf venv.zip 
#1620586926
pwd
#1620590223
hdfs dfs -text /data/raw/nfe/2021/04/*/* | wc -l
#1620596522
hdfs dfs -du -h /data/raw/acc/*/*/*
#1620604253
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         concat $(hadoop fs -ls /data/raw/nfe/2021/05/02/* | awk '{printf "%s ", $NF}')                         /data/raw/nfe/2021/05/02/nfe_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/nfe/2021/05/02).avro.snappy
#1620605181
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar                         concat $(hadoop fs -ls /data/raw/acc/2007/06/01/* | awk '{printf "%s ", $NF}')                         /data/raw/acc/2007/06/01/acc_original_$(hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/avro-tools-1.10.1.jar count /data/raw/acc/2007/06/01).avro.snappy
#1620606567
hdfs dfs -text /data/raw/acc/2021/01/*/* | jq
#1620606595
hdfs dfs -text /data/raw/acc/*/** jq
#1620611023
python3 dags/check_data_quality.py 
#1620649878
htop
#1620649964
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1620650014
htop
#1620650131
docker rm -vf $(docker ps -a -q)
#1620650135
docker rmi -f $(docker images -a -q)
#1620650139
docker volume prune --force
#1620650140
docker network prune --force
#1620650438
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1620650447
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1620650447
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1620650451
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1620650462
set -a # export all variables
#1620650464
source configs/.env
#1620650467
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1620650467
docker-compose up -d
#1620650490
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1620650499
docker-compose up -d
#1620650533
airflow db init
#1620650548
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1620650592
python3 plugins/hooks/utils/prepare_env.py 
#1620650693
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1620650700
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1620650706
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1620650711
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1620662514
hdfs dfs -text /data/raw/acc/2021/01/* jq
#1620662521
hdfs dfs -text /data/raw/acc/2021/01/* | jq
#1620662529
hdfs dfs -text /data/raw/acc/2021/02/* | jq
#1620662540
hdfs dfs -text /data/raw/acc/2021/02* | jq
#1620662550
hdfs dfs -text /data/raw/acc/2021/02/* | jq
#1620662569
hdfs dfs -text /data/raw/acc/2021/02/01/* | jq
#1620663290
hdfs dfs -du -h/raw/acc/2021/02/01/**/*
#1620663297
hdfs dfs -du -h /raw/acc/2021/02/01/**/*
#1620663304
hdfs dfs -du -h /raw/acc/2021/02/01/*/*
#1620663321
hdfs dfs -du -h /raw/acc/2021/*/*
#1620663337
hdfs dfs -du -h /raw/acc/2021/*
#1620663347
hdfs dfs -du -h /data/raw/acc/2021/*
#1620676241
ll
#1620703595
wget https://bda1node10.sef.sc.gov.br/
#1620746074
pip install apache-flink
#1620746224
pip3 install pyspark==3.1.1
#1620746273
pip uninstall py4j
#1620746280
pip3 install pyspark==3.1.1
#1620746306
pip uninstall apache-flink
#1620746312
pip uninstall py4j
#1620746319
pip3 install pyspark==3.1.1
#1620746408
pip install apache-flink
#1620746460
pip uninstall apache-flink
#1620746474
pip3 install pyspark==3.1.1
#1620746580
/ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/venv/bin/python -m pip install --upgrade pip
#1620746590
pip3 install pyspark==3.1.1
#1620746619
python /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/oracle_blob_to_hdfs.py
#1620746903
pip3 uninstall pyspark
#1620746917
pip3 install -r requirements.txt 
#1620751711
spark --version
#1620775189
pip3 install dask-sql
#1620775334
pip3 install dask>=2021.03.0
#1620775394
pip3 install dask-sql
#1620775956
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1620816438
ll
#1620816453
mv pyspark_venv.tar.gz venv.tar.gz
#1620816948
venv-pack -o venv.tar.gz
#1620816956
sudo rm -rf venv.tar.gz 
#1620816963
venv-pack -o venv.tar.gz
#1620819617
pip install dask[complete]
#1620819952
sudo rm -rf venv.tar.gz 
#1620819958
venv-pack -o venv.tar.gz
#1620842914
imagehistory
#1620849386
hdfs dfs -text /data/raw/nfe/2016/06/10/* | jq
#1620849394
hdfs dfs -text /data/acc/nfe/2016/06/10/* | jq
#1620849409
hdfs dfs -text /data/acc/nfe/2016/06/10/* | wc -l
#1620849560
hdfs dfs -text /data/raw/acc/2016/06/10/* | wc -l
#1620850251
hdfs dfs -text /data/raw/acc/2016/06/10/* | jq
#1620961673
git status
#1620961691
ll
#1620961708
sudo rm -rf 2021.03.0
#1620961713
ll
#1620961723
sudo rm -rf =2021.03.0
#1620961725
ll
#1620961730
git status
#1620961756
git commit add ../bda-operation/playbooks/
#1620961764
gitadd ../bda-operation/playbooks/
#1620961767
git add ../bda-operation/playbooks/
#1620961807
git commit -m "ops: playbook to deploy data pipeline"
#1620961811
git status
#1620961827
git add ../bda-operation/playbooks/
#1620961836
git add --all
#1620961840
cd ..
#1620961841
git add --all
#1620961851
git commit -m "ammended"
#1620961856
git push origin master
#1621010082
beeline -u beeline -u "jdbc:hive2://bda1node04.sef.sc.gov.br:10000/default;principal=hive/bda1node04.sef.sc.gov.br@PROD.SEF.SC.GOV.BR"
#1621010261
beeline -u beeline -u "jdbc:hive2://bda1node04.sef.sc.gov.br:10000/nfe;principal=hive/bda1node04.sef.sc.gov.br@PROD.SEF.SC.GOV.BR"
#1621090063
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621090065
docker rm -vf $(docker ps -a -q)
#1621090069
docker rmi -f $(docker images -a -q)
#1621090072
docker volume prune --force
#1621090073
docker network prune --force
#1621090073
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621090080
docker rm -vf $(docker ps -a -q)
#1621090081
docker rmi -f $(docker images -a -q)
#1621090081
docker volume prune --force
#1621090081
docker network prune --force
#1621090081
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621090082
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1621090082
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1621090086
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1621090108
source venv/bin/activate
#1621090111
set -a # export all variables
#1621090114
source configs/.env
#1621090115
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1621090115
docker-compose up -d
#1621090138
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621090138
docker-compose up -d
#1621090159
airflow db init
#1621090184
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1621090206
python3 plugins/hooks/utils/prepare_env.py 
#1621090237
docker rm -vf $(docker ps -a -q)
#1621090238
docker rmi -f $(docker images -a -q)
#1621090239
docker volume prune --force
#1621090239
docker network prune --force
#1621090240
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621090240
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1621090241
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1621090243
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1621090461
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621090465
source venv/bin/activate
#1621090468
set -a # export all variables
#1621090469
source configs/.env
#1621090473
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1621090473
docker-compose up -d
#1621090491
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621090491
docker-compose up -d
#1621090515
airflow db init
#1621090527
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1621090543
python3 plugins/hooks/utils/prepare_env.py 
#1621090558
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1621090565
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1621090581
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1621090586
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1621090591
cd ..
#1621090593
git status
#1621090598
git add --all
#1621090604
git commit -m "amended"
#1621090607
git push origin master
#1621090663
ll
#1621090838
wget http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA?path=%2Fbda-operation%2Fplaybooks%2Fansible.cfg&version=GBmaster
#1621091292
ll
#1621091293
l
#1621144849
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1621145077
htop
#1621145092
deactivate 
#1621145101
htop
#1621145160
free -m
#1621145192
docker rm -vf $(docker ps -a -q)
#1621145195
docker rmi -f $(docker images -a -q)
#1621145199
docker volume prune --force
#1621145199
docker network prune --force
#1621145200
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621145299
ll
#1621145336
htop
#1621145349
free -m
#1621145352
free -m -h
#1621145614
htop
#1621145626
free -m -h
#1621145821
htop
#1621146935
git add --all
#1621146938
git commit -m "amended"
#1621146940
git push origin master
#1621246270
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621246272
source configs/.env
#1621246275
set -a # export all variables
#1621246293
docker rm -vf $(docker ps -a -q)
#1621246294
docker rmi -f $(docker images -a -q)
#1621246294
docker volume prune --force
#1621246294
docker network prune --force
#1621246297
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621246303
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1621246303
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1621246304
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1621246309
source venv/bin/activate
#1621246313
set -a # export all variables
#1621246314
source configs/.env
#1621246318
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1621246318
docker-compose up -d
#1621246346
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621246348
docker-compose up -d
#1621246373
airflow db init
#1621246394
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1621246410
python3 plugins/hooks/utils/prepare_env.py 
#1621246431
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1621246438
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1621246442
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1621246446
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1621255783
ll
#1621284738
python3 plugins/hooks/utils/prepare_env.py 
#1621288541
hdfs dfs -du -h /data/raw/dimp/
#1621288547
hdfs dfs -du -h /data/raw/dimp/2020
#1621288553
hdfs dfs -du -h /data/raw/dimp/2020/06
#1621288559
hdfs dfs -du -h /data/raw/dimp/2020/06/01
#1621288594
hdfs dfs -text /data/raw/dimp/2020/06/01/* | jq
#1621288610
hdfs dfs -text /data/raw/dimp/2021/03/01/* | jq
#1621288706
hdfs dfs -text /data/raw/dimp/2021/05/01/* | jq
#1621289669
python3 plugins/hooks/utils/prepare_env.py 
#1621291915
hdfs dfs -text /data/raw/dimp/2021/05/01/* | jq
#1621291958
hdfs dfs -text /data/raw/dimp/2020/06/01/* | jq
#1621472457
65;1;9c65;1;9c1;1;120;120;1;0x.p7b
#1621472472
cd ..
#1621472475
git status
#1621472478
git add --all
#1621472485
git commit -m "amended"
#1621472489
git push origin master
#1621472727
cd ..
#1621472728
ll
#1621472756
zip -r SAT_BIG_DATA.zip SAT_BIG_DATA/
#1621472763
sudo zip -r SAT_BIG_DATA.zip SAT_BIG_DATA/
#1621472869
ll
#1621472894
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621472901
sudo zip -r SAT_BIG_DATA.zip SAT_BIG_DATA/
#1621473029
ll
#1621473306
scp SAT_BIG_DATA.zip sat_job@bda1node08.sef.sc.gov.br:/ssddisk/ 
#1621473329
scp SAT_BIG_DATA.zip root@bda1node08.sef.sc.gov.br:/ssddisk/ 
#1621496847
spark-submit
#1621496970
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621496973
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621496975
set -a # export all variables
#1621496977
source configs/.env
#1621496979
source venv/bin/activate
#1621496980
set -a # export all variables
#1621496982
source configs/.env
#1621496984
source venv/bin/activate
#1621497668
spark --version
#1621497702
./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 lib/spark-examples*.jar 10
#1621497737
spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 lib/spark-examples*.jar 10
#1621497754
spark-submit --class org.apache.spark.examples.SparkPi --master yarn --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 lib/spark-examples*.jar 10
#1621497805
spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster /opt/cloudera/parcels/CDH/jars/spark-examples*.jar 10
#1621497909
'airflow tasks run import_nfe extract_decompress_load 2021-05-19T05:00:00+00:00 --job-id 1923 --pool default_pool --raw --subdir DAGS_FOLDER/import.py --cfg-path /tmp/tmpnn6k0179 --error-file /tmp/tmpha3edsp_

#1621497919
airflow tasks run import_nfe extract_decompress_load 2021-05-19T05:00:00+00:00 --job-id 1923 --pool default_pool --raw --subdir DAGS_FOLDER/import.py --cfg-path /tmp/tmpnn6k0179 --error-file /tmp/tmpha3edsp_
#1621497924
airflow tasks run import_nfe extract_decompress_load 2021-05-19T05:00:00+00:00 --job-id 1923 --pool default_pool --raw --subdir DAGS_FOLDER/import.py --cfg-path /tmp/tmpnn6k0179 
#1621498375
kinit sat_job
#1621498380
klist
#1621501781
ll
#1621501793
deactivate 
#1621501803
sudo rm -rf venv/
#1621501847
docker rm -vf $(docker ps -a -q)
#1621501850
docker rmi -f $(docker images -a -q)
#1621501855
docker volume prune --force
#1621501856
docker network prune --force
#1621501856
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1621501862
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1621501862
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1621501865
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1621501875
virtualenv -p python3 venv
#1621501897
virtualenv 
#1621501925
yum install virtualenv
#1621501928
sudo yum install virtualenv
#1621501992
pip3 install virtualenv
#1621502002
pip3 freeze
#1621502014
virtualenv -p python3 venv
#1621502025
source venv/bin/activate
#1621502028
pip3 install -r requirements.txt
#1621502139
set -a # export all variables
#1621502142
source configs/.env
#1621502150
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1621502150
docker-compose up -d
#1621502169
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621502169
docker-compose up -d
#1621502190
airflow db init
#1621502232
pip3 install dask_yarn
#1621502245
pip3 install "dask[complete]
#1621502251
pip3 install "dask[complete]"
#1621502305
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1621502340
pip3 install pyopenssl
#1621502347
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1621502371
python3 plugins/hooks/utils/prepare_env.py 
#1621502384
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1621502391
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1621502396
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1621502400
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1621504088
hdfs dfs -text /data/raw/dimp/2020/06/01/* | jq
#1621596046
ll
#1621596052
pip3 freeze
#1621601758
cd ..
#1621601762
git add --all
#1621601764
git commit -m "amended"
#1621601768
git push origin master
#1621608922
ll
#1621631173
hdfs dfs -text /data/raw/dimp/2020/06/01/* | jq
#1621636716
hdfs dfs -text /data/raw/dimp/2020/06/01/* | more
#1621944006
hadoop fs -ls -R / |wc -l
#1621944022
kinit
#1621944030
ll
#1621944026
hadoop fs -ls -R / |wc -l
#1621945319
hadoop fs -du -s -h
#1621945249
hadoop fs -ls -R / | wc -l
#1621945898
hadoop fsck / -files -blocks -locations
#1621946080
hadoop fs -ls -R / | wc -l
#1621946232
hdfs fsck 
#1621946241
hdfs fsck -list-corruptfileblocks
#1621955129
hdfs dfs -text /data/raw/dimp/2020/06/01/* | more
#1621955260
hdfs dfs -text /data/raw/nfe/2020/06/01/* | more
#1621955493
hadoop fs -ls -R / | wc -l
#1621955737
spark --version
#1621955790
spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster /opt/cloudera/parcels/CDH/jars/spark-examples*.jar 10
#1621955902
spark
#1621955909
spark-sumit
#1621955935
./bin/spark-shell
#1621955953
spark-shell
#1621957239
pyspark-shell
#1621957243
spark-shell
#1621957553
export HADOOP_CONF_DIR=/etc/hadoop/conf
#1621957555
spark-shell
#1621958591
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/tests/spark_oracle_to_hdfs.py
#1621946253
sudo su
#1621959526
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1621959529
sour]ce configs/.env
#1621959534
source configs/.env
#1621959535
set -a # export all variables
#1621959537
source configs/.env
#1621959539
sour]ce configs/.env
#1621959541
source venv/bin/activate
#1621959682
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/tests/spark_oracle_to_hdfs.py
#1621959962
hdfs dfs -text /data/raw/nfe/2020/06/01/* | more
#1621960068
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/tests/spark_oracle_to_hdfs.py
#1621968033
ll
#1622116765
hdfs dfs -text /data/raw/mdfe/2020/01/01/* | jq
#1622116785
ll
#1622403138
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1622403140
set -a # export all variables
#1622403141
source venv/bin/activate
#1622403143
sour]ce configs/.env
#1622403148
source configs/.env
#1622403174
hdf dfs -text /data/raw/efd/2010/03/04/*| jq
#1622403180
hdfs dfs -text /data/raw/efd/2010/03/04/*| jq
#1622403198
kinit
#1622403202
hdfs dfs -text /data/raw/efd/2010/03/04/*| jq
#1622465893
hdfs dfs -text /data/raw/efd/2010/03/01/*| jq
#1622468472
python3 prepare_env.py 
#1622468474
ll
#1622481145
hdfs dfs -text /data/raw/cte/2020/01/01/*| jq
#1622539121
ll
#1622539129
spark --version
#1622539145
sudo bigdata
#1622539159
sudo -u bigdata -i
#1622666736
klist
#1622666754
kinit
#1622668227
klist
#1623079441
,
#1623079441
6578447896
#1623079442
+0465
#1623079442
345+1*0/1
#1623079443
6324+*/43120
#1623079523
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1623079524
set -a # export all variables
#1623079526
source configs/.env
#1623079528
source venv/bin/activate
#1623079551
kinit 
#1623087491
ll
#1623087530
hdfs dfs -text /data/raw/cte/2020/01/01/*| jq | more
#1623087534
hdfs dfs -text /data/raw/cte/2020/01/01/*| jq
#1623088978
hdfs dfs -text /data/transformed/nfe_diario/t5/anoEmissao=2020/mesEmissao=10/diaEmissao=01/*| jq
#1623093413
hdfs dfs -text /data/raw/cte/2020/01/01/*| jq
#1623141733
ll
#1623141738
hdfs dfs -text /data/raw/nfe/2020/01/02/* | jq
#1623146286
hdfs dfs -text /data/transformed/nfe_diario/t1/2017/07/27/* | jq
#1623146322
hdfs dfs -text /data/transformed/nfe_diario/t1/2017/07/27/* | more
#1623159098
ll
#1623159136
hdfs dfs -text /data/raw/nfe/1900/01/01/* | grep ID_FILE
#1623159171
hdfs dfs -text /data/raw/nfe/1900/01/01/* | grep "ID_FILE":"ea1d9240-70a2-451e-9cb4-1e1c00d60e86"
#1623282682
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/01/01/* | jq
#1623282692
kinit
#1623282695
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/01/01/* | jq
#1623282971
hdfs dfs -text /data/transformed/nfe_diario/t2/2020/01/01/* | jq
#1623283141
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/01/01/* | jq
#1623328803
ll
#1623337610
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/01/01/* | jq
#1623343396
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1623343414
set -a # export all variables
#1623343415
source venv/bin/activate
#1623343417
source configs/.env
#1623343428
ll
#1623345292
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/01/01/* | jq
#1623345369
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | jq
#1623349025
hdfs dfs -text /data/ransformed/nfe_diario/t3/2020/06/01/* | jq
#1623349051
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | jq
#1623349100
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | more
#1623349373
hdfs dfs -text /data/raw/efd/2020/01/01/* | more
#1623349535
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | more
#1623349569
hdfs dfs -text /data/raw/acc/2020/01/01/* | more
#1623349590
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | more
#1623349610
hdfs dfs -text /data/raw/dime/2020/01/01/* | more
#1623351244
hdfs dfs -text /data/raw/dime/2020/01/01/* | jq
#1623351375
hdfs dfs -text /data/raw/efd/2020/01/01/* | jq
#1623351410
hdfs dfs -text /data/raw/efd/2020/01/01/* | more
#1623351489
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | jq
#1623351827
hdfs dfs -text /data/raw/acc/2020/01/01/* | jq
#1623352382
hdfs dfs -text /data/raw/dime/2020/01/01/* | jq
#1623426218
hdfs dfs -text /data/raw/sintegra/2020/01/01/* | jq
#1623677985
hdfs dfs -text /data/raw/ccg/*/*/*/* | wc -l
#1623677995
kinit
#1623687440
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1623687443
set -a # export all variables
#1623687445
source configs/.env
#1623687446
source venv/bin/activate
#1623687448
ll
#1623687497
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | jq
#1623678006
hdfs dfs -text /data/raw/mdfe/*/*/*/* | wc -l
#1623694412
hdfs dfs -text /data/transformed/nfe_diario/t5/2020/06/01/* | jq
#1623694441
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | grep SIT
#1623694446
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | grep sit
#1623694464
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | grep <sit
#1623694469
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | grep "<sit"
#1623694728
hdfs dfs -text /data/transformed/nfe_diario/t3/2020/06/01/* | grep cStat
#1623694930
hdfs dfs -text /data/transformed/nfe_diario/t5/anoEmissao=2007/mesEmissao=12/diaEmissao=02/part-00000-4a5ab083-3ac3-46d0-b56b-949fdd2f0fe1-c000.avro | jq
#1623700481
ll
#1623700493
ll
#1623949731
cd ..
#1623949732
ll
#1623949738
cd ..
#1623949739
ll
#1623949748
sudo rm -rf SAT_BIG_DATA.zip 
#1623949759
ll
#1624031256
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624031258
cd ..
#1624031259
ll
#1624031305
cd ..
#1624031852
mv -r SAT_BIG_DATA/gabriel/ .
#1624031860
mv SAT_BIG_DATA/gabriel .
#1624031865
sudo mv SAT_BIG_DATA/gabriel .
#1624031872
ll
#1624031878
cd gabriel/
#1624031879
ll
#1624031882
cd ..
#1624031932
ll
#1624031943
sudo rm -rf SAT_BIG_DATA/
#1624032210
ll
#1624032232
mv gabriel SAT_BIG_DATA/
#1624032247
sudo mv gabriel SAT_BIG_DATA/
#1624032259
sudo mv gabriel* SAT_BIG_DATA/
#1624032644
sudo chown sat_job -R SAT_BIG_DATA
#1624032650
ll
#1624032668
sudo rm -rf SAT_BIG_DATA.zip
#1624032692
ll
#1624032715
sudo chgrp job_group -R SAT_BIG_DATA
#1624032717
ll
#1624032955
cd SAT_BIG_DATA/
#1624032959
ll
#1624032973
sudo mv gabriel/ /tmp
#1624032976
ll
#1624032978
cd ..
#1624032979
ll
#1624032989
mv gabriel SAT_BIG_DATA/
#1624032993
sudo mv gabriel SAT_BIG_DATA/
#1624032995
ll
#1624032999
cd SAT_BIG_DATA/
#1624032999
ll
#1624033080
cd ..
#1624033081
ll
#1624034077
ocker rm -vf $(docker ps -a -q)
#1624034078
docker rmi -f $(docker images -a -q)
#1624034079
docker volume prune --force
#1624034079
docker network prune --force
#1624034079
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624034085
docker rm -vf $(docker ps -a -q)
#1624034087
docker rmi -f $(docker images -a -q)
#1624034091
docker volume prune --force
#1624034091
docker network prune --force
#1624034092
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624034092
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1624034092
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1624034095
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1624034122
cd SAT_BIG_DATA/bda-
#1624034125
cd SAT_BIG_DATA/bda-batch-data-pipeline/
#1624034126
virtualenv -p python3 venv
#1624034128
source venv/bin/activate
#1624034175
pip3 install -r requirements.txt
#1624035438
source venv/bin/activate
#1624035439
pip3 install -r requirements.txt
#1624035447
set -a # export all variables
#1624035450
source configs/.env
#1624035454
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1624035454
docker-compose up -d
#1624035474
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624035476
docker-compose up -d
#1624035496
airflow db init
#1624035513
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1624037699
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1624037699
docker-compose up -d
#1624037700
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624037700
docker-compose up -d
#1624037711
airflow db init
#1624037734
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1624037954
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1624038851
set -a # export all variables
#1624038852
source configs/.env
#1624038866
docker rm -vf $(docker ps -a -q)
#1624038867
docker rmi -f $(docker images -a -q)
#1624038868
docker volume prune --force
#1624038868
docker network prune --force
#1624038869
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624038876
docker rm -vf $(docker ps -a -q)
#1624038877
docker rmi -f $(docker images -a -q)
#1624038877
docker volume prune --force
#1624038877
docker network prune --force
#1624038877
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624038878
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1624038878
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1624038879
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1624038882
set -a # export all variables
#1624038883
source configs/.env
#1624038886
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1624038886
docker-compose up -d
#1624038904
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624038904
docker-compose up -d
#1624038925
airflow db init
#1624038939
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1624038957
python3 prepare_env.py
#1624038996
kinit
#1624039000
python3 prepare_env.py
#1624039014
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1624039021
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1624039025
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1624039029
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1624177164
docker rm -vf $(docker ps -a -q)
#1624177167
docker rmi -f $(docker images -a -q)
#1624177170
docker volume prune --force
#1624177170
docker network prune --force
#1624177171
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624177345
cd ..
#1624177345
ll
#1624177362
mv gabriel/ ../
#1624177365
sudo mv gabriel/ ../
#1624177368
cd ..
#1624177368
ll
#1624222132
lll
#1624222133
ll
#1624222272
cd SAT_BIG_DATA/l
#1624222275
cd SAT_BIG_DATA/
#1624222277
ll
#1624246280
cd ..
#1624246281
ll
#1624246293
sudo rm -rf SAT_BIG_DATA/
#1624246321
sudo mv -R SAT_BIG_DATA /tmp
#1624246330
sudo mv SAT_BIG_DATA* /tmp
#1624246359
ll
#1624246381
git clone http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1624246388
sudo git clone http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1624246430
ll
#1624246588
sudo chown sat_job -R SAT_BIG_DATA/
#1624246598
sudo chgrp job_group -R SAT_BIG_DATA/
#1624246600
ll
#1624246639
docker rm -vf $(docker ps -a -q)
#1624246639
docker rmi -f $(docker images -a -q)
#1624246639
docker volume prune --force
#1624246639
docker network prune --force
#1624246639
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1624246639
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1624246640
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1624246641
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1624246657
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624246661
virtualenv -p python3 venv
#1624246663
source venv/bin/activate
#1624246663
pip3 install -r requirements.txt
#1624246802
ll
#1624246810
set -a # export all variables
#1624246810
source configs/.env
#1624246818
python3 configs/generate_conn_config.py --env PROD
#1624246823
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1624246823
docker-compose up -d
#1624246841
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624246842
docker-compose up -d
#1624246864
airflow db init
#1624246878
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1624247083
python3 prepare_env.py
#1624247112
kinit
#1624247117
python3 prepare_env.py
#1624247162
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1624247169
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1624247173
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1624247178
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1624269633
ll
#1624295003
hdfs dfs -text /data/raw/nfe/*/*/*/* | wc -l
#1624372171
ll
#1624399292
cd ..
#1624399301
git pull origin master
#1624399490
rm -rf bda-batch-data-pipeline/dags/expand.py bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/plugins/operators/hdfs_concat_files.py bda-batch-data-pipeline/plugins/hooks/hdfs/hdfs_helper.py 
#1624399493
git pull origin master
#1624420507
hdfs dfs -text /data/raw/cte/2018/03/03/part-00000-48ac2506-eafa-4575-afa8-8ea836b1c849-c000.avro | jq
#1624420518
hdfs dfs -text /data/raw/cte/2018/03/03/part-00000-48ac2506-eafa-4575-afa8-8ea836b1c849-c000.avro | wc -l
#1624421252
hdfs dfs -text /data/raw/cte/2018/03/03/part-00002-b31f2e4c-2476-4cd0-ba64-f338b6732665-c000.avro | wc -l
#1624421266
hdfs dfs -text /data/raw/cte/2018/01/01/part-00002-b31f2e4c-2476-4cd0-ba64-f338b6732665-c000.avro | wc -l
#1624422197
git pull origin master
#1624422468
rm -rf bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/dags/expand.py
#1624422472
git pull origin master
#1624425080
ll
#1624425086
cd ..
#1624425086
ll
#1624425099
cd SAT_BIG_DATA/
#1624425099
ll
#1624425120
sudo rm -fr gabriel/
#1624425131
sudo rm -rf gabriel/
#1624425171
ll
#1624425173
cd ..
#1624425175
ll
#1624425183
cp gabriel* SAT_BIG_DATA/
#1624425192
cp -R gabriel/ SAT_BIG_DATA/
#1624425202
ll
#1624425205
cd SAT_BIG_DATA/
#1624425207
ll
#1624456209
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624456211
set -a # export all variables
#1624456213
source configs/.env
#1624456214
source venv/bin/activate
#1624646692
ll
#1624646713
ll /ssddisk/SAT_BIG_DATA/gabriel/venv_gabriel/bin/python3
#1624760965
hdfs dfs -du -h /raw/cte/*/*/*/* 
#1624760974
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624761159
git pull origin master
#1624761190
git diif bda-batch-data-pipeline/configs/conn_config.json
#1624761196
git diff bda-batch-data-pipeline/configs/conn_config.json
#1624761209
git --diff bda-batch-data-pipeline/configs/conn_config.json
#1624761211
git diff bda-batch-data-pipeline/configs/conn_config.json
#1624761215
git diff bda-batch-data-pipeline/configs/docs_config.json
#1624761219
git diff bda-batch-data-pipeline/dags/parser.py
#1624761251
cd ..
#1624761253
git diff bda-batch-data-pipeline/dags/parser.py
#1624761287
rm -rf bda-batch-data-pipeline/configs/conn_config.json bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/expand.py bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/dags/parser.py bda-batch-data-pipeline/plugins/hooks/db/hive_helper.py bda-batch-data-pipeline/plugins/operators/compare_data_hdfs_oracle.py
#1624761293
git pull origin master
#1624761332
python3 configs/generate_conn_config.py --env PROD
#1624761336
cd bda-batch-data-pipeline/
#1624761337
python3 configs/generate_conn_config.py --env PROD
#1624761944
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624762063
git pull origin master
#1624762084
rm -rf bda-batch-data-pipeline/configs/docs_config.json
#1624762146
python3 configs/generate_conn_config.py --env PROD
#1624762221
git pull origin master
#1624762238
rm -rf bda-batch-data-pipeline/configs/docs_config.json
#1624762241
git pull origin master
#1624762258
rm -rf bda-batch-data-pipeline/configs/docs_config.json
#1624762261
git pull origin master
#1624762287
git stash bda-batch-data-pipeline/configs/docs_config.json
#1624762295
git stash add bda-batch-data-pipeline/configs/docs_config.json
#1624762304
git stash save bda-batch-data-pipeline/configs/docs_config.json
#1624762309
rm -rf bda-batch-data-pipeline/configs/docs_config.json
#1624762314
git pull origin master
#1624762385
python3 configs/generate_conn_config.py --env PROD
#1624764848
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624769399
git pull origin master
#1624769425
rm -rf bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/expand.py bda-batch-data-pipeline/dags/import.py
#1624769429
git pull origin master
#1624769455
git stach add bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/dags/expand.py
#1624769465
git stash add bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/dags/expand.py
#1624769471
git stash save bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/import.py bda-batch-data-pipeline/dags/expand.py
#1624769475
rm -rf bda-batch-data-pipeline/configs/docs_config.json bda-batch-data-pipeline/dags/expand.py bda-batch-data-pipeline/dags/import.py
#1624769479
git pull origin master
#1624769496
ll
#1624769525
python3 configs/generate_conn_config.py --env PROD
#1624770609
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624771954
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1624772346
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624821626
yarn application -kill application_1624371736473_19577
#1624838761
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624838849
hdfs dfs -du -h /data/raw/cte/2021/06/17/part-00000-d4ca0f23-656d-4c3f-8c65-e6aa3e31efd6-c000.avro
#1624838862
hdfs dfs -text /data/raw/cte/2021/06/17/part-00000-d4ca0f23-656d-4c3f-8c65-e6aa3e31efd6-c000.avro | jq
#1624838871
hdfs dfs -text /data/raw/cte/2021/06/17/part-00000-d4ca0f23-656d-4c3f-8c65-e6aa3e31efd6-c000.avro | wc -l
#1624839284
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624839305
hdfs dfs -text /data/raw/cte/2021/06/23/part-00000-8ae26580-dae6-4de9-8fb8-e4b59d220863-c000.avro | wc -l
#1624839476
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624850587
hdfs dfs -du -h /data/raw/nfe/*/*/*/* 
#1624879217
hdfs dfs -du -h /data/raw/cte/*/*/*/* 
#1624885233
ll
#1624885950
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/tests/test_import_table.py
#1624886003
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624889185
sudo -u hdfs -i 
#1624889338
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624889450
groups
#1624889537
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624889569
groups
#1624889589
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624889591
set -a # export all variables
#1624889593
source venv/bin/activate
#1624889594
source configs/.env
#1624889599
groups
#1624889606
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624889627
kinit
#1624889632
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624889881
sudo -u hdfs -i 
#1624890351
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624908582
ll
#1624908626
python3 prepare_env.py 
#1624908635
set -a # export all variables
#1624908637
source configs/.env
#1624908638
source venv/bin/activate
#1624908819
python3 prepare_env.py 
#1624908920
python /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/oracle_blob_to_hdfs.py
#1624908946
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624909039
python3 prepare_env.py 
#1624909857
ll
#1624911805
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/operators/test_import_table.py
#1624915200
ll
#1624946840
python3 prepare_env.py 
#1624949301
ll
#1624949352
python /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/hive_helper.py
#1624949485
ll
#1624949683
python /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/hive_helper.py
#1624950211
python3 prepare_env.py 
#1624957224
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624963880
python3 prepare_env.py 
#1624963982
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624964081
python3 prepare_env.py 
#1624964161
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624964665
python3 prepare_env.py 
#1624964698
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624965753
python3 prepare_env.py 
#1624965766
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624965930
python3 prepare_env.py 
#1624965947
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624966204
python3 prepare_env.py 
#1624966225
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624966294
hdfs dfs -text /data/raw/cadastro/2021/01/01/* | jq
#1624966424
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624966484
hdfs dfs -text /data/raw/cadastro/2021/01/01/* | jq
#1624966495
hdfs dfs -text /data/raw/cadastro/2021/01/01/*
#1624966551
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar   cat --json /data/raw/cadastro/2021/01/01/* | jq
#1624966639
hdfs dfs -du -h /data/raw/cadastro/2021/01/01
#1624966649
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar   cat --json /data/raw/cadastro/2021/01/01/part-00000-6d0dc424-5427-4c1a-8ef3-a753b3f9acd9-c000.snappy.parquet | jq
#1624968344
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624969591
python3 prepare_env.py 
#1624987547
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1624997919
ll
#1624998110
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1624998121
set -a # export all variables
#1624998127
source venv/bin/activate
#1624998129
source configs/.env
#1624998135
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625002472
git status
#1625002485
git add configs/
#1625002573
git commit -m "refactor: criar arquivos separados referente as configurações dos dados"
#1625002727
ll /opt/cloudera/parcels
#1625002744
ll /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/
#1625002750
ll /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/
#1625002898
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625070296
python prepare_env.py 
#1625084739
python3 dags/import.py 
#1625085400
python prepare_env.py 
#1625085557
python3 dags/import.py 
#1625085560
python prepare_env.py 
#1625087016
python3 dags/import.py 
#1625087490
python prepare_env.py 
#1625087540
python3 dags/import.py 
#1625090958
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625093494
python prepare_env.py 
#1625094566
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625095002
python prepare_env.py 
#1625095013
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625095060
python prepare_env.py 
#1625095228
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625108409
python prepare_env.py 
#1625108970
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625110367
python prepare_env.py 
#1625110385
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625111571
python prepare_env.py 
#1625111571
python prepare_env.py 
#1625111571
python prepare_env.py 
#1625111571
python prepare_env.py 
#1625111571
python prepare_env.py 
#1625111648
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625111992
python3 dags/import.py 
#1625111996
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625113706
python prepare_env.py 
#1625114222
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625115738
python prepare_env.py 
#1625115766
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625116059
ll /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/
#1625116083
/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools 
#1625116094
hadoop -jar /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools 
#1625116110
#hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar   cat --json /data/raw/cadastro/2021/01/01/part-00000-6d0dc424-5427-4c1a-8ef3-a753b3f9acd9-c000.snappy.parquet | jq
#1625116115
hadoop jar /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools 
#1625116121
hadoop /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools 
#1625116132
hadoop jar /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools.jar
#1625116259
hdfs dfs -du -h /data/raw/cadastro/*
#1625116285
hadoop /opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1580995/bin/parquet-tools cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | jq
#1625116303
hadoop /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | jq
#1625116313
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | jq
#1625116495
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | more
#1625116495
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | more
#1625116495
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | more
#1625116495
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | more
#1625116495
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | more
#1625117833
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625121076
python prepare_env.py 
#1625121332
git status
#1625121351
git diff plugins/hooks/utils/data_helper.py
#1625121581
python prepare_env.py 
#1625121692
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625122788
#hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-edb6297c-5e03-4704-9c3d-d458711b507a-c000.snappy.parquet | jq
#1625122793
hdfs dfs -du -h /data/raw/cadastro/*
#1625122812
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-a83cbbf4-69a3-482c-88fb-81aa69473734-c000.snappy.parquet | jq
#1625122854
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625123018
hdfs dfs -du -h /data/raw/cadastro/*
#1625123030
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-f4b00bda-7f39-41cd-a55a-eb061aa2fa18-c000.snappy.parquet | jq
#1625123176
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625124014
git status
#1625124071
git add ../.gitignore
#1625124191
git commit -m "docs: adicionar novos arquivos no gitignore"
#1625124195
git status
#1625124224
git add --all
#1625124263
cd ..
#1625124263
ll
#1625124265
git add --all
#1625124280
git commit -m "refactor"
#1625124322
git status
#1625124324
git add --all
#1625124326
git commit -m "refactor"
#1625125526
python3 bda-batch-data-pipeline/dags/check_data_quality.py 
#1625127128
kinit 
#1625127216
kdestroy 
#1625127221
klist
#1625127239
kinit sat_job
#1625127385
echo $KRB5CCNAME
#1625127392
ll /tmp/airflow_krb5_ccache
#1625127402
ll /tmp/airflow_krb5_ccache/
#1625127526
kinit -r
#1625127530
kinit -E
#1625127558
klist
#1625129451
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625129455
echo $KRB5CCNAME
#1625129462
set -a # export all variables
#1625129464
source configs/.env
#1625129466
echo $KRB5CCNAME
#1625129504
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625129509
set -a # export all variables
#1625129514
source configs/.env
#1625129524
source venv/bin/activate
#1625129546
source configs/.env
#1625129550
echo $KRB5CCNAME
#1625129566
klist
#1625129628
kdestroy
#1625129630
klist
#1625129640
kinit sat_job
#1625129645
klist
#1625131340
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625158830
klist
#1625159113
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625159915
#hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json  | jq
#1625159941
hdfds dfs -du -h /data/raw/cadastro/* 
#1625159951
hdfs dfs -du -h /data/raw/cadastro/* 
#1625159967
#hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-98f8f3d2-42ae-4d76-adc8-18d822ae6bcc-c000.snappy.parquet | jq
#1625159971
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-98f8f3d2-42ae-4d76-adc8-18d822ae6bcc-c000.snappy.parquet | jq
#1625160307
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625161362
ll
#1625161375
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625163220
pyt prepare_env.py 
#1625163225
python prepare_env.py 
#1625165559
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625167132
python prepare_env.py 
#1625167737
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625168412
python prepare_env.py 
#1625168571
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625228758
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625228761
set -a # export all variables
#1625228763
source configs/.env
#1625228765
source venv/bin/activate
#1625228766
ll
#1625228810
ps aux | grep 'airflow' | awk '{print $2}'
#1625228817
ps aux | grep 'airflow'
#1625228851
sudo kill -9 568836 565940 524688 540532 
#1625228857
ps aux | grep 'airflow'
#1625228953
sudo kill -9 186197 186263 186266 186422 221642 
#1625228955
ps aux | grep 'airflow'
#1625228968
airflow scheduler
#1625229010
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625229023
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625229038
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625229281
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625229281
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625229283
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230040
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625230047
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625230053
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625230058
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625230251
cd logs/
#1625230251
ll
#1625230325
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/airflow-*
#1625230339
ll
#1625230484
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230500
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230500
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230501
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230517
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230517
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230517
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230523
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230528
cd ..
#1625230529
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230530
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230530
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230534
kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230597
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230598
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230599
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230612
ps aux | grep 'flower' | awk '{print $2}')
#1625230614
ps aux | grep 'flower' | awk '{print $2}'
#1625230633
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230640
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230643
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230646
ps aux | grep 'flower' | awk '{print $2}'
#1625230658
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230659
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230659
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230660
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230671
ps aux | grep airflow
#1625230683
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230697
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625230704
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625230708
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625230713
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625230869
docker rm -vf $(docker ps -a -q)
#1625230872
docker rmi -f $(docker images -a -q)
#1625230874
docker volume prune --force
#1625230876
docker network prune --force
#1625230877
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230878
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230878
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230879
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230883
docker rm -vf $(docker ps -a -q)
#1625230883
docker rmi -f $(docker images -a -q)
#1625230883
docker volume prune --force
#1625230884
docker network prune --force
#1625230884
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625230884
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625230885
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625230885
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625230893
set -a # export all variables
#1625230894
source configs/.env
#1625230898
python3 configs/generate_conn_config.py --env PROD
#1625230910
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625230910
docker-compose up -d
#1625230930
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625230930
docker-compose up -d
#1625230988
/ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/hooks/utils/generate_conn_config.py
#1625231012
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625231249
airflow db init
#1625231262
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625231279
python3 prepare_env.py
#1625231333
airflow conn
#1625231344
airflow connections 
#1625231347
airflow connections list
#1625231403
python3 prepare_env.py
#1625231409
airflow connections list
#1625231422
airflow connections
#1625231506
airflow connections get hive
#1625231559
python3 prepare_env.py
#1625231660
/ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/hooks/utils/generate_conn_config.py
#1625231664
python3 prepare_env.py
#1625231684
docker rm -vf $(docker ps -a -q)
#1625231685
docker rmi -f $(docker images -a -q)
#1625231686
docker volume prune --force
#1625231686
docker network prune --force
#1625231687
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625231694
docker rm -vf $(docker ps -a -q)
#1625231694
docker rmi -f $(docker images -a -q)
#1625231695
docker volume prune --force
#1625231695
docker network prune --force
#1625231695
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625231696
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625231696
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625231696
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625231709
set -a # export all variables
#1625231709
source configs/.env
#1625231716
python3 configs/generate_conn_config.py --env PROD
#1625231724
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625231729
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625231729
docker-compose up -d
#1625231747
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625231748
docker-compose up -d
#1625231768
airflow db init
#1625231781
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625231796
python3 prepare_env.py
#1625231809
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625232020
python3 prepare_env.py
#1625233019
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625233033
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625233037
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625233041
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625233289
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233298
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233334
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233343
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625233343
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233344
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233344
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233348
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625233357
kill
#1625233360
kill -9
#1625233366
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233456
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625233456
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233456
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233457
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233463
ll
#1625233468
ps aux | grep 'airflow'
#1625233478
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233481
ps aux | grep 'airflow'
#1625233500
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233505
ps aux | grep 'airflow'
#1625233510
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233510
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233511
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233523
ps aux | grep airflow
#1625233527
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233528
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233529
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233535
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233535
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233536
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233539
ps aux | grep airflow
#1625233555
sudo kill -9 89098 89099 89105 89803
#1625233556
ps aux | grep airflow
#1625233570
sudo kill -9 6778464 407948 6778508 114344
#1625233571
ps aux | grep airflow
#1625233578
docker rm -vf $(docker ps -a -q)
#1625233579
docker rmi -f $(docker images -a -q)
#1625233580
docker volume prune --force
#1625233580
docker network prune --force
#1625233581
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625233581
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625233581
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625233582
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625233590
set -a # export all variables
#1625233591
source configs/.env
#1625233593
python3 configs/generate_conn_config.py --env PROD
#1625233606
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625233609
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625233610
docker-compose up -d
#1625233627
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625233627
docker-compose up -d
#1625233649
airflow db init
#1625233668
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625233682
python3 prepare_env.py
#1625233698
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625233704
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625233708
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625233711
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625233891
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625233904
cd logs/
#1625233905
ll
#1625233917
cd scheduler/
#1625233918
ll
#1625233922
cd ..
#1625233923
ll
#1625233931
cat airflow-scheduler.err 
#1625233945
ll
#1625233964
airflow scheduler help
#1625233969
airflow scheduler -help
#1625233991
ll
#1625234009
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625234016
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625234018
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625234020
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625234029
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625234032
cd ..
#1625234032
ll
#1625234035
cd logs/
#1625234035
ll
#1625234039
cd scheduler/
#1625234039
ll
#1625234061
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625234064
ll
#1625234065
cd ..
#1625234065
ll
#1625234068
cd ..
#1625234068
ll
#1625234071
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625234073
ll
#1625234087
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625234087
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625234087
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625234093
llsudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625234094
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625234096
ll
#1625234110
ps aux | grep 'airflow'
#1625234140
sudo kill -9 169447 169481 169493 175588
#1625234142
ps aux | grep 'airflow'
#1625234155
airflow db reset
#1625234174
ps aux | grep 'airflow'
#1625234180
ll
#1625234183
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625234185
ll
#1625234198
python prepare_env.py 
#1625234220
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625234248
ll
#1625234252
cd logs/
#1625234253
ll
#1625234261
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625234268
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625234313
ll
#1625234317
cd ..
#1625234318
ll
#1625234322
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625234328
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625234346
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid
#1625234374
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid
#1625234960
ll
#1625234969
airflow
#1625234974
deactivate
#1625234976
airflow
#1625234984
source configs/.env
#1625234986
source venv/bin/activate
#1625234990
airflweo
#1625234992
airflow
#1625235012
airflow info
#1625235079
airflow help
#1625235095
ll
#1625235097
cd logs/
#1625235098
ll
#1625235118
sudo rm -rf scheduler/ 
#1625235122
ll
#1625235493
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid
#1625241179
docker rm -vf $(docker ps -a -q)
#1625241181
docker rmi -f $(docker images -a -q)
#1625241182
docker volume prune --force
#1625241182
docker network prune --force
#1625241182
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625241856
docker rm -vf $(docker ps -a -q)
#1625241856
docker rmi -f $(docker images -a -q)
#1625241856
docker volume prune --force
#1625241857
docker network prune --force
#1625241857
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625241864
docker rm -vf $(docker ps -a -q)
#1625241864
docker rmi -f $(docker images -a -q)
#1625241864
docker volume prune --force
#1625241865
docker network prune --force
#1625241865
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625241865
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625241865
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625241866
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625241872
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625241879
ps aux | grep 'airflow'
#1625241884
ps aux | grep airflow
#1625241889
docker rm -vf $(docker ps -a -q)
#1625241889
docker rmi -f $(docker images -a -q)
#1625241889
docker volume prune --force
#1625241890
docker network prune --force
#1625241890
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625241890
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625241890
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625241890
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625242575
ll
#1625242576
cd ..
#1625242576
ll
#1625242597
sudo rm -rf venv/
#1625242607
virtualenv -p python3 venv
#1625242609
source venv/bin/activate
#1625242610
pip3 install -r requirements.txt
#1625242627
deactivate 
#1625242632
sudo rm -rf venv/
#1625242633
ll
#1625242717
virtualenv -p python3 venv
#1625242721
pip3 install -r requirements.txt
#1625242835
ll
#1625242860
pip3 uninstall -r requirements.txt 
#1625243124
pip3 freeze
#1625243140
pip3 uninstall anyio 
#1625243146
pip3 uninstall appdirs
#1625243153
pip3 uninstall connexion
#1625243167
pip3 uninstall httpcore
#1625243176
pip3 uninstall distlib
#1625243183
pip3 freeze
#1625243190
pip3 async-generator
#1625243200
pip3 uninstall  async-generator
#1625243207
pip3 uninstall blinker
#1625243214
pip3 uninstall filelock
#1625243219
pip3 uninstall h11
#1625243227
pip3 uninstall httpx
#1625243233
pip3 uninstall rfc3986
#1625243239
pip3 uninstall sniffio
#1625243246
pip3 freeze
#1625243250
pip3 cryptography
#1625243257
pip3 uninstall cryptography
#1625243269
ll
#1625243275
cd ..
#1625243283
cd bda-batch-data-pipeline/
#1625243289
virtualenv -p python3 venv
#1625243299
pip3 isntall appdirs
#1625243305
pip3 install appdirs
#1625243331
virtualenv -p python3 venv
#1625243351
pip3 install appdirs --use-feature=2020-resolver
#1625243353
virtualenv -p python3 venv
#1625243360
pip3 install six
#1625243364
virtualenv -p python3 venv
#1625243370
pip3 install filelock
#1625243373
virtualenv -p python3 venv
#1625243378
pip3 install importlib_metadata
#1625243382
virtualenv -p python3 venv
#1625243388
pip3 install distlib
#1625243391
virtualenv -p python3 venv
#1625243398
pip3 install importlib_resources
#1625243400
virtualenv -p python3 venv
#1625243405
source venv/bin/activate
#1625243409
pip3 install -r requirements.txt
#1625243478
set -a # export all variables
#1625243479
source configs/.env
#1625243517
python3  $AIRFLOW_HOME/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625243522
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625243523
docker-compose up -d
#1625243541
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625243541
docker-compose up -d
#1625243568
airflow db init
#1625243581
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625243796
python3 prepare_env.py
#1625243819
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625243835
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625243846
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625243854
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625243931
ll
#1625243935
cd logs/
#1625243936
ll
#1625243947
cd scheduler/
#1625243947
ll
#1625243955
cd 2021-07-02/
#1625243956
ll
#1625243959
cd ..
#1625243960
ll
#1625243967
cd ..
#1625243968
ll
#1625243983
ps aux | grep airflow
#1625244067
airflow db reset
#1625244083
set -a # export all variables
#1625244084
source configs/.env
#1625244091
airflow db init
#1625244102
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625244120
python3 prepare_env.py
#1625244134
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625244141
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625244146
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625244151
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625244223
airflow
#1625244227
airflow config
#1625244277
airflow config list
#1625244349
docker rm -vf $(docker ps -a -q)
#1625244350
docker rmi -f $(docker images -a -q)
#1625244351
docker volume prune --force
#1625244351
docker network prune --force
#1625244352
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625244362
docker rm -vf $(docker ps -a -q)
#1625244362
docker rmi -f $(docker images -a -q)
#1625244363
docker volume prune --force
#1625244363
docker network prune --force
#1625244363
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625244373
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625244373
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625244374
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625244386
source venv/bin/activate
#1625244389
set -a # export all variables
#1625244390
source configs/.env
#1625244394
python3  $AIRFLOW_HOME/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625244400
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625244400
docker-compose up -d
#1625244418
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625244418
docker-compose up -d
#1625244470
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625244499
airflow config list
#1625244502
airflow config 
#1625244507
airflow db
#1625244512
airflow db check
#1625244524
airflow 
#1625244533
airflow infoi
#1625244534
airflow info
#1625244649
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625244678
deav
#1625244680
deactivate 
#1625244700
sudo rm -rf venv/
#1625244711
virtualenv -p python3 venv
#1625244713
source venv/bin/activate
#1625244715
pip3 install -r requirements.txt
#1625244903
set -a # export all variables
#1625244905
source configs/.env
#1625244908
python3  $AIRFLOW_HOME/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625244912
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625244912
docker-compose up -d
#1625244913
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625244913
docker-compose up -d
#1625244916
airflow db init
#1625244935
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625244948
python3 prepare_env.py
#1625244966
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625245001
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625245015
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625245019
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625248984
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625275756
deactivate 
#1625275758
set -a # export all variables
#1625275761
source configs/.env
#1625275763
source venv/bin/activate
#1625275769
ll
#1625275805
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625275807
set -a # export all variables
#1625275809
source venv/bin/activate
#1625275810
source configs/.env
#1625275813
ll
#1625276017
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625276728
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625284753
ll
#1625285301
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625285303
set -a # export all variables
#1625285306
source configs/.env
#1625285307
source venv/bin/activate
#1625285329
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625290272
yarn application -kill application_1625229864242_0714
#1625290276
ll
#1625290347
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625476037
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/*parquet | jq
#1625476065
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/* | jq
#1625476135
hdfs dfs -du -h /data/raw/cadastro/*/*/*/*
#1625476139
hdfs dfs -du -h /data/raw/cadastro/*/*/*
#1625476155
hdfs dfs -du -h /data/raw/cadastro/*/*
#1625476161
hdfs dfs -du -h /data/raw/cadastro/*
#1625476196
hdfs dfs -du -h /data/raw/cadastro/*.parquet
#1625476248
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -du -h /data/raw/cadastro/*.parquet) | jq
#1625476284
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $("hdfs dfs -du -h /data/raw/cadastro/*.parquet") | jq
#1625476315
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-dfa6075a-46cc-4720-acd0-0a39a5f6b9bf-c000.snappy.parquet | jq
#1625476330
#hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json /data/raw/cadastro/part-00000-dfa6075a-46cc-4720-acd0-0a39a5f6b9bf-c000.snappy.parquet | jq
#1625476346
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $("hdfs dfs -du -h /data/raw/cadastro/*.parquet")
#1625476370
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -du -h /data/raw/cadastro/*.parquet) | jq
#1625476405
hdfs dfs -du -h /data/raw/cadastro/*.parquet
#1625476434
hdfs dfs -du -h /data/raw/cadastro/*.parquet | awk "print $3"
#1625476449
hdfs dfs -du -h /data/raw/cadastro/*.parquet | awk "{print $3}"
#1625476457
hdfs dfs -du -h /data/raw/cadastro/*.parquet | awk "{print $0}"
#1625476462
hdfs dfs -du -h /data/raw/cadastro/*.parquet | awk "{print $1}"
#1625476472
hdfs dfs -du -h /data/raw/cadastro/*.parquet | awk "{print $2}"
#1625476485
hdfs dfs -ls /data/raw/cadastro/*.parquet | awk "{print $2}"
#1625476638
hdfs dfs -ls /data/raw/cadastro/*.parquet | awk "{printf $2}"
#1625476655
hdfs dfs -ls /data/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}'
#1625476665
hdfs dfs -ls /data/raw/cadastro/*.parquet | awk '{printf "%s "}'
#1625476681
hdfs dfs -ls /data/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}'
#1625476717
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1625476861
hdfs dfs -text /data/raw/nfe/*/*/*/* | wc -l
#1625476904
hdfs dfs -text /data/raw/nfe/2021/01/01/* | wc -l
#1625476912
hdfs dfs -text /data/raw/nfe/2021/01/01/*.avro | wc -l
#1625476929
hdfs dfs -text /data/raw/nfe/2021/01/01/*.avro | jq
#1625478943
ll
#1625478945
ll
#1625496153
ll
#1625500233
l
#1625500844
python3 /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/poc/test_import_table.py
#1625505166
ccat
#1625505168
cart
#1625505170
cat
#1625505176
ll
#1625505182
cat unittests.cfg
#1625506132
ll
#1625506163
d ..
#1625506165
cd ..
#1625506167
git status
#1625506190
git add bda-batch-data-pipeline/README.md 
#1625506227
git commit -m "doc: migrar informações de acesso aos dados para a wiki"
#1625506242
git add bda-batch-data-pipeline/avro_schemas/*
#1625506271
git commit -m "config: alterar configurações dos schemas dos dados"
#1625506300
git add bda-batch-data-pipeline/configs*
#1625506303
git commit -m "config: alterar configurações dos schemas dos dados"
#1625506306
git status
#1625506334
git add bda-batch-data-pipeline/poc/*
#1625506364
git commit -m "poc: testar a importação de tabelas como arquivos p o HDFSD"
#1625506369
git status
#1625506395
git add bda-batch-data-pipeline/dags/*
#1625506402
git add bda-batch-data-pipeline/dags/
#1625506405
ll
#1625506408
git status
#1625506423
ll
#1625506427
cd bda-batch-data-pipeline/
#1625506428
ll
#1625506434
sudo rm -rf core.python3.340096
#1625506440
ll
#1625506471
git status
#1625506493
git add dags/
#1625506502
git add requirements.txt 
#1625506527
git commit -m "chore: atualizar versao do ariflow"
#1625506530
git status
#1625506542
git add prepare_env.py 
#1625506664
git commit -m "refactor: adaptar a criação de bd e tabelas"
#1625506670
git add --all
#1625506675
cd ..
#1625506676
git add --all
#1625506693
git commit -m "feat: adicionar novas funcionalidades"
#1625506699
git push origin master
#1625506905
git status
#1625652292
ll
#1625652323
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625652326
cd libs/
#1625652327
ll
#1625658006
hdfs dfs -text /data/raw/acc/2020/01/02/* | jq
#1625658014
hdfs dfs -text /data/raw/acc/2020/01/01/* | jq
#1625675755
ll
#1625675758
cd ..
#1625675758
ll
#1625675813
set -a # export all variables
#1625675815
source venv/bin/activate
#1625675816
source configs/.env
#1625675818
ll
#1625675888
python3 dags/expand.py 
#1625675966
deu erro
#1625675990
python3 dags/expand.py 
#1625676768
python3 dags/import_file.py 
#1625677790
python3 dags/expand.py 
#1625678517
python3 prepare_env.py 
#1625678973
python3 dags/expand.py 
#1625687862
python
#1625688048
ll
#1625693430
kinit bigdata
#1625693480
klist
#1625693547
kdestroy
#1625693549
klist
#1625694037
kdestroy
#1625694041
kdestroy bigdata
#1625694102
klist
#1625694107
ll
#1625726523
klist
#1625726527
kinit
#1625726552
klist
#1625727107
ll
#1625727112
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625727114
set -a # export all variables
#1625727115
source venv/bin/activate
#1625727118
source configs/.env
#1625727141
python plugins/hooks/db/hive_helper.py 
#1625727261
kinit
#1625727265
python plugins/hooks/db/hive_helper.py 
#1625727269
klist
#1625727521
python plugins/hooks/db/hive_helper.py 
#1625728755
klist
#1625728767
kdestroy hive
#1625728779
kdestroy -c hive
#1625728800
kdestroy -A
#1625728805
klist
#1625728811
python plugins/hooks/db/hive_helper.py 
#1625728835
kinit
#1625728841
python plugins/hooks/db/hive_helper.py 
#1625694138
sudo -u bigdata -i
#1625757703
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625757706
set -a # export all variables
#1625757707
source configs/.env
#1625757718
source venv/bin/activate
#1625757735
git add big_data-central/requisitos.md bda-operation/README.md bda-batch-data-pipeline/avro_schemas/.gitkeep bda-operation/bda_sw_problem/
#1625757740
cd ..
#1625757741
git add big_data-central/requisitos.md bda-operation/README.md bda-batch-data-pipeline/avro_schemas/.gitkeep bda-operation/bda_sw_problem/
#1625757747
git status
#1625757756
git add bda-batch-data-pipeline/avro_schemas/.gitkeep
#1625757782
git add bda-batch-data-pipeline/poc/
#1625757790
git status
#1625757823
git commit -m "doc: atualizar documentação da parte operacional"
#1625757825
git status
#1625757834
git add bda-operation/playbooks/
#1625757881
git commit -m "ops: atualizar playbooks com as novas configurações do cluster"
#1625757883
git status
#1625757891
git add bda-batch-data-pipeline/poc/
#1625757912
git status
#1625757933
git add bda-operation/bkp/
#1625757966
git commit -m "bkp: fazer backup dos arquivos de config do BDA"
#1625757971
git status
#1625761122
ll
#1625761125
git status
#1625761133
git add bda-operation/bda_sw_problem
#1625769756
git commit -m "doc:"
#1625769878
python bda-batch-data-pipeline/poc/test_import_table.py 
#1625769960
git status
#1625770025
git add bda-batch-data-pipeline/configs/
#1625770027
git status
#1625770036
git add bda-batch-data-pipeline/avro_schemas/.gitkeep
#1625770105
git commit -m "config: diminuir recursos para importação de dados"
#1625770107
git status
#1625770135
git add bda-batch-data-pipeline/plugins/
#1625770149
git add --all
#1625770211
git commit -m "refactor: encapsular funcionalidades em cada classe "
#1625770221
git pull origin master
#1625770255
git push origin master
#1625770734
git status
#1625771143
ll
#1625771944
hdfs dfs du -h /data/raw/nfe/2020/01/
#1625771955
hdfs dfs -du -h /data/raw/nfe/2020/01/
#1625771969
hdfs dfs -du -h /data/raw/nfe/2020/01/31
#1625772191
hdfs dfs -text /data/raw/ccg/2019/07/01/* | jq
#1625772246
hdfs dfs -text /data/raw/sintegra/2018/05/01/* | jq
#1625773603
hdfs dfs -text /data/raw/dime/2018/05/01/* | jq
#1625773603
hdfs dfs -text /data/raw/dime/2018/05/01/* | jq
#1625773603
hdfs dfs -text /data/raw/dime/2018/05/01/* | jq
#1625773737
hdfs dfs -text /data/raw/sintegra/2018/05/01/* | jq
#1625773829
hdfs dfs -text /data/raw/efd/2018/05/01/* | jq
#1625779525
ll
#1625779540
cd bda-batch-data-pipeline/
#1625779540
ll
#1625779542
cd ..
#1625779543
ll
#1625779582
cd bda-batch-data-pipeline/
#1625779584
cd ..
#1625779587
cd batch-data-pipeline/
#1625779587
ll
#1625779603
mv * ../bda-batch-data-pipeline/
#1625779608
l
#1625779611
cd ..
#1625779611
ll
#1625779614
cd bda-batch-data-pipeline/
#1625779615
ll
#1625779620
cd ..
#1625779685
docker rm -vf $(docker ps -a -q)
#1625779688
docker rmi -f $(docker images -a -q)
#1625779691
docker volume prune --force
#1625779691
docker network prune --force
#1625779692
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625779698
docker rm -vf $(docker ps -a -q)
#1625779698
docker rmi -f $(docker images -a -q)
#1625779699
docker volume prune --force
#1625779699
docker network prune --force
#1625779699
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625779699
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625779700
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625779700
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625812883
ll
#1625812888
deactivate 
#1625812890
ll
#1625812899
cd ..
#1625812902
cd SAT_BIG_DATA/
#1625812902
ll
#1625837462
cd ..
#1625837463
ll
#1625837475
sudo mv SAT_BIG_DATA/ /tmp
#1625837866
ll
#1625837870
cd ..
#1625837878
ll
#1625838038
ll ssddisk/
#1625838070
sudo chown sat_job -R ssddisk/
#1625838077
ll ssddisk/
#1625838079
ll
#1625838123
if
#1625838126
id
#1625838393
cd ssddisk/SAT_BIG_DATA/
#1625838393
ll
#1625838405
cd data-pipeline/batch/
#1625838406
ll
#1625838825
cd ..
#1625838826
cd..
#1625838827
ll
#1625838886
cd ..
#1625838886
ll
#1625838896
sudo rm -rf SAT_BIG_DATA/
#1625838927
git clone http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1625838945
cd SAT_BIG_DATA/
#1625838947
ll
#1625838952
cd bda-batch-data-pipeline/
#1625838953
ll
#1625838966
set -a # export all variables
#1625838969
source configs/.env
#1625838989
virtualenv -p python3 venv
#1625838995
source venv/bin/activate
#1625838999
pip3 install -r requirements.txt
#1625839081
set -a # export all variables
#1625839083
source configs/.env
#1625839087
python3  $AIRFLOW_HOME/plugins/hooks/utils/generate_conn_config.py --env PROD
#1625839093
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625839094
docker-compose up -d
#1625839114
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625839116
docker-compose up -d
#1625839141
airflow db init
#1625839232
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625839247
python3 prepare_env.py
#1625839546
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625839552
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625839556
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625839575
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625839626
python3 prepare_env.py
#1625839868
ll
#1625839992
mkdir /ssddisk/SAT_BIG_DATA/gabriel/
#1625840000
mkdir /ssddisk/SAT_BIG_DATA/gabriel/venv_gabriel
#1625840009
cd ..
#1625840010
ll
#1625840013
cd gabriel/
#1625840014
ll
#1625840017
cd venv_gabriel/
#1625840018
ll
#1625840029
cd ..
#1625840033
sudo rm -rf venv_gabriel/
#1625840037
ll
#1625840110
virtualenv -p python3 venv_gabriel
#1625840115
source venv/bin/activate
#1625840123
source venv_gabriel/bin/activate
#1625840127
pip3 install -r requirements.txt
#1625840269
pwd
#1625840286
ll
#1625844123
deactivate 
#1625844516
ll
#1625844520
cd ..
#1625845243
ll
#1625845263
cd bda-batch-data-pipeline/
#1625845263
ll
#1625845284
set -a # export all variables
#1625845286
source venv_gabriel/bin/activate
#1625845290
source venv/bin/activate
#1625845295
source configs/.env
#1625845300
python3 prepare_env.py
#1625850255
ll
#1625851719
cd ..
#1625851720
ll
#1625851722
cd gabriel/
#1625851723
ll
#1625851730
pwd
#1625855517
ll
#1625855520
cd ..
#1625855520
ll
#1625855527
cd bda-batch-data-pipeline/
#1625855529
ll
#1625855548
pip3 install -r requirements.txt 
#1625855627
docker rm -vf $(docker ps -a -q)
#1625855630
docker rmi -f $(docker images -a -q)
#1625855636
docker volume prune --force
#1625855637
docker network prune --force
#1625855637
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625855646
docker rm -vf $(docker ps -a -q)
#1625855646
docker rmi -f $(docker images -a -q)
#1625855646
docker volume prune --force
#1625855647
docker network prune --force
#1625855647
sudo rm -rf /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/logs/
#1625855647
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625855647
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625855648
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625855659
deactivate 
#1625855661
source venv/bin/activate
#1625855663
set -a # export all variables
#1625855665
source configs/.env
#1625855673
pip3 install -r requirements.txt
#1625855682
cd /ssddisk/SAT_BIG_DATA/bda-cache/
#1625855682
docker-compose up -d
#1625855700
cd /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline
#1625855702
docker-compose up -d
#1625855723
airflow db init
#1625855750
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625855763
python3 prepare_env.py
#1625855776
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625855782
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625855786
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625855789
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625856177
sudo rm -rf requirements.txt 
#1625856185
alabaster==0.7.12
#1625856185
alembic==1.4.2
#1625856185
amqp==2.6.1
#1625856186
apache-airflow==2.1.1
#1625856186
apache-airflow-providers-apache-hdfs==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856186
apache-airflow-providers-apache-hive==2.0.0
#1625856205
pip-compile --generate-hashes --output-file=requirements.txt
#1625856217
pip install pip-tools
#1625856223
pip-compile --generate-hashes --output-file=requirements.txt
#1625856243
cat requirements.txt 
#1625856253
ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/venv/bin/python -m pip install --upgrade pip
#1625856298
ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/venv/bin/python3 -m pip install --upgrade pip
#1625856319
pip-compile --generate-hashes --output-file requirements.txt
#1625856351
pip --upgrade pi
#1625856353
pip --upgrade pip
#1625856574
pip3 freeze > requirements.in
#1625856582
car requirements.in 
#1625856586
cat requirements.in 
#1625856592
pip-compile --generate-hashes requirements.in
#1625856680
cat requirements.txt 
#1625860342
cd ..
#1625860342
ll
#1625860953
cd ..
#1625860954
ll
#1625860960
cd SAT_BIG_DATA/
#1625860960
ll
#1625861206
cd ..
#1625861206
ll
#1625861210
cd ..ll
#1625861211
cd ..
#1625861213
cd
#1625861214
ll
#1625861216
cd /
#1625861217
ll
#1625861225
cd ssddisk/
#1625861296
ll
#1625861592
mv SAT_BIG_DATA/ SAT_BIG_DATA_bkp/
#1625861612
ll
#1625861768
mv SAT_BIG_DATA_bkp/ SAT_BIG_DATA/
#1625861769
ll
#1625956372
mv SAT_BIG_DATA/ SAT_BIG_DATA_bkp/
#1625956413
ll
#1625956426
ll /ssddisk/
#1625956430
ll /
#1625956541
ll
#1625959975
cd SAT_BIG_DATA
#1625959976
ll
#1625959989
sudo rm -rf venv/
#1625960073
ll
#1625961600
cd ..
#1625961601
ll
#1625961608
sudo rm -rf SAT_BIG_DATA_bkp/
#1625961833
cd SAT_BIG_DATA/
#1625961833
ll
#1625961846
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625961851
ll
#1625961859
virtualenv -p python3 venv
#1625961864
deactivate 
#1625961867
ll
#1625961871
source venv/bin/activate
#1625961875
pip3 install --require-hashes -r requirements.txt
#1625962030
set -a # export all variables
#1625962031
source configs/.env
#1625962035
env
#1625962057
python3  $AIRFLOW_HOME/src/hooks/utils/generate_conn_config.py --env PROD
#1625962070
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py --env PROD
#1625962098
echo  $AIRFLOW_HOME
#1625962139
source configs/.env
#1625962141
echo  $AIRFLOW_HOME
#1625962149
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py --env PROD
#1625962260
cd /ssddisk/SAT_BIG_DATA/cache/
#1625962263
docker-compose up -d
#1625962281
docker rm -vf $(docker ps -a -q)
#1625962284
docker rmi -f $(docker images -a -q)
#1625962285
docker volume prune --force
#1625962285
docker network prune --force
#1625962287
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/
#1625962296
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625962296
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625962297
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625962305
cd /ssddisk/SAT_BIG_DATA/cache/
#1625962305
docker-compose up -d
#1625962323
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625962323
docker-compose up -d
#1625962347
airflow db init
#1625962361
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625962394
python3 prepare_env.py
#1625962482
echo $AIRFLOW__CORE__PLUGINS_FOLDER
#1625962513
python3 prepare_env.py
#1625963816
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625963885
airflow webserver     --help
#1625964008
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625964043
ll
#1625964047
cd logs/
#1625964048
ll
#1625964094
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid \
#1625964096
cd ..
#1625964098
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625964104
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625964110
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625964114
ll
#1625964721
echo $AIRFLOW__CORE__PLUGINS_FOLDER
#1625964730
echo $AIRFLOW_HOME
#1625964960
python3 dags/import_file.py 
#1625966098
echo #
#1625966104
echo $AIRFLOW__CORE__PLUGINS_FOLDER
#1625966625
python3 dags/import_file.py 
#1625967744
echo $PYTHONPATH
#1625967964
sudo vim ~/.bashrc
#1625968038
echo $PYTHONPATH
#1625968066
echo $PYTHONPATH
#1625968926
python3 dags/import_file.py 
#1625968962
sudo vim ~/.bashrc
#1625969070
set -a # export all variables
#1625969073
source configs/.env
#1625969092
python3 dags/import_file.py 
#1625969114
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625969114
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625969114
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625969118
source venv/bin/activate
#1625969124
set -a # export all variables
#1625969127
source configs/.env
#1625969136
python3 dags/import_file.py 
#1625969406
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625969411
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/dags
#1625969438
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs
#1625969447
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/dag_processor_manager/dag_processor_manager.log
#1625969468
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src
#1625969471
set -a # export all variables
#1625969474
source configs/.env
#1625969478
python3 dags/import_file.py 
#1625969507
source configs/.env
#1625969509
python3 dags/import_file.py 
#1625969548
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625969550
source venv/bin/activate
#1625969553
set -a # export all variables
#1625969553
source configs/.env
#1625969560
python3 dags/import_file.py 
#1625969573
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/dags
#1625969578
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src
#1625969586
ll /ssddisk/SAT_BIG_DATA/data-pipeline/batch/config
#1625969749
python3 dags/import_file.py 
#1625970907
python3 dags/import_table.py 
#1625970922
python3 dags/expand.py 
#1625971186
python3 dags/check_data_quality.py 
#1625971211
docker rm -vf $(docker ps -a -q)
#1625971213
docker rmi -f $(docker images -a -q)
#1625971214
docker volume prune --force
#1625971214
docker network prune --force
#1625971214
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/airflow*
#1625971223
docker rm -vf $(docker ps -a -q)
#1625971223
docker rmi -f $(docker images -a -q)
#1625971223
docker volume prune --force
#1625971223
docker network prune --force
#1625971223
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/airflow*
#1625971223
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625971224
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625971224
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625971239
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625971242
virtualenv -p python3 venv
#1625971251
source venv/bin/activate
#1625971256
pip3 freeze
#1625971262
set -a # export all variables
#1625971264
source configs/.env
#1625971280
cd /ssddisk/SAT_BIG_DATA/cache/
#1625971280
docker-compose up -d
#1625971301
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625971301
docker-compose up -d
#1625971322
airflow db init
#1625971337
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625971352
python3 prepare_env.py
#1625971467
kinit
#1625971471
python3 prepare_env.py
#1625971761
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625971767
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625971786
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080    
#1625971810
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625971913
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.err
#1625971922
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.out
#1625971922
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.pid
#1625971922
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/scheduler*
#1625971934
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625971935
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625971950
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625971955
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.err
#1625971955
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.out
#1625971955
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/*.pid
#1625971955
sudo rm -rf /ssddisk/SAT_BIG_DATA/batch-data-pipeline/logs/scheduler*
#1625972000
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1625972000
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1625972000
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1625972001
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1625972019
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1625972026
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625972036
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625972042
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625972047
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625972066
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid  
#1625972167
docker rm -vf $(docker ps -a -q)
#1625972168
docker rmi -f $(docker images -a -q)
#1625972169
docker volume prune --force
#1625972169
docker network prune --force
#1625972170
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1625972170
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1625972170
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1625972171
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1625972171
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1625972171
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1625972171
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1625972171
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1625972179
set -a # export all variables
#1625972180
source configs/.env
#1625972183
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py --env PROD
#1625972187
cd /ssddisk/SAT_BIG_DATA/cache/
#1625972187
docker-compose up -d
#1625972204
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1625972204
docker-compose up -d
#1625972224
airflow db init
#1625972238
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1625972253
python3 prepare_env.py
#1625972561
pip3 freeze | grep kerbe
#1625972622
python3 dags/import_file.py 
#1625972661
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1625972668
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1625972671
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1625972675
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1625972685
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid   
#1625973482
python3 dags/import_file.py 
#1625973723
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid   
#1625973912
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid   --daemon
#1625973920
python3 dags/import_file.py 
#1626017538
ll
#1626017621
airflow 
#1626017633
airflow tasks 
#1626017639
airflow tasks list
#1626017660
airflow tasks test
#1626017672
airflow tasks test task_id 
#1626017712
airflow tasks test dag_id import_file_efd 
#1626017734
airflow tasks test dag_id import_file_efd task_id task_oracle_execute_count
#1626017754
airflow tasks test dag_id import_file_efd task_id task_oracle_execute_count 2020-01-01
#1626017774
airflow tasks test dag_id import_file_efd task_id task_oracle_execute_count "2021-07-11, 00:22:36"
#1626038535
sudo su
#1626038623
ll
#1626038868
python3 tests/src/hooks/db/test_oracle_helper.py 
#1626040160
pip3 uninstall apache-airflow-providers-oracle==2.0.
#1626040163
pip3 uninstall apache-airflow-providers-oracle==2.0.0
#1626040202
pip3 install apache-airflow-providers-oracle==1.0.1
#1626040220
pip3 freeze | grep apache-airflow-providers-oracle==2.0.0
#1626040223
pip3 freeze | grep apache-airflow-providers-oracle
#1626040309
python3 prepare_env.py
#1626040347
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py --env PROD
#1626040354
python3 prepare_env.py
#1626043002
cd ..
#1626043006
git status
#1626043964
cd /ssddisk/
#1626081463
cd /ssddisk/SAT_BIG_DATA
#1626081487
mkdir gabriel
#1626081534
deactivate
#1626081565
python3 -m venv venv_gabriel
#1626081623
cd gabriel/
#1626081646
python3 -m venv venv_gabriel
#1626081742
source venv_gabriel/bin/activate
#1626082098
pip install --upgrade pip
#1626082121
pip3 install --require-hashes -r ../data-pipeline/batch/requirements.txt
#1626160184
ll
#1626186542
cd /ssddisk/SAT_BIG_DATA
#1626186543
ll
#1626186568
cd data-pipeline/
#1626186569
ll
#1626186572
cd batch/
#1626186572
ll
#1626186578
set -a # export all variables
#1626186580
source venv_gabriel/bin/activate
#1626186585
source configs/.env
#1626186590
source venv/bin/activate
#1626186592
ll
#1626186617
python3 prepare_env.py 
#1626204526
ll
#1626204577
set -a # export all variables
#1626204578
source configs/.env
#1626204585
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1626204591
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1626204591
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1626204591
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1626204592
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204601
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626204601
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626204602
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626204606
ll
#1626204607
cd logs/
#1626204608
ll
#1626204627
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204629
ll
#1626204647
cd scheduler/
#1626204648
lll
#1626204907
ll
#1626204912
cd ..
#1626204913
ll
#1626204920
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204922
ll
#1626204924
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204928
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626204930
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204931
ll
#1626204934
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626204936
ll
#1626204942
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/schedul*
#1626204944
ll
#1626204967
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs
#1626204969
ll
#1626204971
cd ..
#1626204972
ll
#1626204974
cd logs/
#1626204974
ll
#1626204981
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626204981
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626204982
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626204985
cd ..
#1626204985
ll
#1626205185
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1626205185
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1626205185
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1626205185
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1626205187
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/schedul*
#1626205204
ll
#1626205225
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1626205225
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1626205225
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1626205225
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1626205226
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/schedul*
#1626205235
ll
#1626205241
cd logs/
#1626205336
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626205336
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626205337
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626205344
ps aux | grep 'airflow' | awk '{print $2}'
#1626205369
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626205369
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626205370
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626205420
ps aux | grep 'airflow' | awk '{print $2}'
#1626205425
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626205433
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626205434
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626205437
ps aux | grep 'airflow' | awk '{print $2}'
#1626205455
airflow scheduler -h
#1626205471
pkill -f -USR2 "airflow scheduler"
#1626205477
ps aux | grep 'airflow' | awk '{print $2}'
#1626205489
ll
#1626205498
rm -rf scheduler/
#1626205499
ll
#1626205538
ps aux | grep 'airflow' | awk '{print $2}'
#1626205557
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626205557
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626205557
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626205558
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1626205558
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1626205558
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1626205558
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1626205559
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626205566
ps aux | grep 'airflow' | awk '{print $2}'
#1626205577
ps aux | grep 'airflow'
#1626205594
sudo kill -9 216697 219994
#1626205599
docker rm -vf $(docker ps -a -q)
#1626205602
docker rmi -f $(docker images -a -q)
#1626205604
docker volume prune --force
#1626205605
docker network prune --force
#1626205605
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1626205605
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1626205606
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1626205606
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1626205606
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1626205606
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1626205606
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1626205608
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1626205610
ll
#1626205612
cd ..
#1626205613
ll
#1626205616
cd logs/
#1626205617
ll
#1626205619
cd ..
#1626205619
ll
#1626205625
virtualenv -p python3 venv
#1626205634
source venv/bin/activate
#1626205637
set -a # export all variables
#1626205637
source configs/.env
#1626205640
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py --env PROD
#1626205645
cd /ssddisk/SAT_BIG_DATA/cache/
#1626205645
docker-compose up -d
#1626205663
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1626205663
docker-compose up -d
#1626205689
airflow db init
#1626205704
airflow users create     --username bigdata    --firstname bigdata    --lastname bigdata    --role Admin    --email bcampos@sef.sc.gov.br
#1626205718
python3 prepare_env.py
#1626205736
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1626205743
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1626205750
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1626205757
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1626213726
python3 prepare_env.py
#1626214055
yarn application --kill application_1625861254504_0193
#1626214063
yarn application --kill application_1625861254504_0194
#1626214070
yarn application --kill application_1625861254504_0196
#1626214075
yarn application --kill application_1625861254504_0197
#1626232395
python3 prepare_env.py
#1626237415
ll
#1626237420
cd logs/
#1626237421
ll
#1626237432
cd import_file_efd/
#1626237433
ll
#1626237437
cd extract_decompress_load/
#1626237438
ll
#1626237449
cd 2021-07-13T22\:23\:30.510128+00\:00/
#1626237450
ll
#1626237460
cat 1.log 
#1626237516
tail 1.log 
#1626238461
cd ..
#1626238466
python3 prepare_env.py
#1626266701
yarn application --kill application_1625861254504_0919
#1626286961
ll /home/campos/projects/sef/prod/SAT_BIG_DATA/data-pipeline/batch/poc/campos/test_import_table.py
#1626286977
ls /home/campos/projects/sef/prod/SAT_BIG_DATA/data-pipeline/batch/poc/campos/test_import_table.py
#1626286995
ls poc/campos/test_import_table.py
#1626287018
python3 poc/campos/test_import_table.py
#1626290821
cd .
#1626290822
cd ..
#1626290823
ll
#1626290824
cd ..
#1626290827
ll
#1626290927
ll /home/sat_csoliveira/
#1626297155
ll
#1626297178
cd SAT_BIG_DATA/data-pipeline/batch/
#1626297179
ll
#1626297187
python3 prepare_env.py 
#1626297212
ll
#1626297709
python /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/prepare_env.py
#1626297714
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/prepare_env.py
#1626300529
spark-shell
#1626300785
hdfs dfs -du -h /data/raw/dime/2020/03/01/
#1626300794
hdfs dfs -du -h /data/raw/dime/2020/03
#1626300799
hdfs dfs -du -h /data/raw/dime/2020/03/
#1626300810
hdfs dfs -du -h /data/prod/raw/dime/2020/03/
#1626300816
hdfs dfs -du -h /data/prod/raw/dime/2020/03/01
#1626300848
ll
#1626300867
hdfs dfs -text /data/prod/raw/dime/2020/03/01/part-00000-4145ad8e-47ee-4c3a-a69f-4e1ee222b2b8-c000.avro | jq
#1626341526
ll
#1626348741
python3 src/utils/generate_all_partitions.py
#1626348780
cat src/utils/generate_all_partitions.py
#1626349002
python3 src/utils/generate_all_partitions.py
#1626349281
cat src/utils/generate_all_partitions.py
#1626349421
python3 src/utils/generate_all_partitions.py
#1626350478
python
#1626350522
which python3
#1626350528
deactivate 
#1626350533
source configs/.env
#1626350534
set -a # export all variables
#1626350535
source configs/.env
#1626350537
source venv/bin/activate
#1626350540
which python3
#1626350547
python3 src/utils/generate_all_partitions.py
#1626350555
cd src/
#1626350555
ll
#1626350558
python3 src/utils/generate_all_partitions.py
#1626350562
python3 utils/generate_all_partitions.py
#1626350684
python3 validators/compare_data_oracle_impala.py 
#1626350711
python3 src/utils/generate_all_partitions.py
#1626350716
python3 utils/generate_all_partitions.py
#1626350767
python3 utils/generate_all_part.py 
#1626350851
python3 utils/generate_all_partitions.py
#1626351055
ll
#1626351067
sudo rm -rf __pycache__/
#1626351072
python3 utils/generate_all_partitions.py
#1626351077
ll
#1626351336
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/poc/campos/generate_all_partitions.py
#1626351366
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/poc/campos/test_import_table.py 
#1626351576
cd ..
#1626351584
python3 dags/import_file.py 
#1626351828
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/poc/campos/test_import_table.py 
#1626351846
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626352641
echo $PYTHONPATH
#1626352874
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626352899
airflow --config
#1626352905
airflow info
#1626352959
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626353178
]
#1626353181
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626353456
python3 src/utils/prepare_env.py 
#1626353472
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626353547
echo $PYTHONPATH
#1626353568
export PYTHONPATH="/ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/"
#1626353569
echo $PYTHONPATH
#1626353574
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/src/utils/generate_all_partitions.py 
#1626358354
python3 src/utils/prepare_env.py 
#1626363775
python3 /ssddisk/SAT_BIG_DATA/data-pipeline/batch/poc/campos/test_import_table.py 
#1626363802
python3 dags/import_file.py 
#1626363809
set -a # export all variables
#1626363811
source configs/.env
#1626363813
python3 dags/import_file.py 
#1626363901
source configs/.env
#1626363902
python3 dags/import_file.py 
#1626363936
ll
#1626363953
cd /ssddisk/
#1626363954
ll
#1626363956
cd SAT_BIG_DATA/
#1626363956
ll
#1626363960
set -a # export all variables
#1626363962
source configs/.env
#1626363970
cd data-pipeline/
#1626363970
ll
#1626363974
cd batch/
#1626363974
ll
#1626363999
source configs/.env
#1626364006
set -a # export all variables
#1626364009
source venv/bin/activate
#1626364011
ll
#1626364015
python3 dags/import_file.py 
#1626364108
set -a # export all variables
#1626364110
source configs/.env
#1626364114
python3 dags/import_file.py 
#1626364191
ll
#1626364197
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1626364198
set -a # export all variables
#1626364200
source configs/.env
#1626364201
source venv/bin/activate
#1626364209
python3 dags/import_file.py 
#1626368345
sudo su
#1626496368
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1626496369
set -a # export all variables
#1626496371
source venv/bin/activate
#1626496372
source configs/.env
#1626496374
pip install pytest
#1626496386
pytest
#1626496498
pytest -h
#1626496882
pytest tests/src/hooks/db/test_oracle_helper.py 
#1626496900
pytest tests/src/hooks/db/test_oracle_helper.py -v
#1626498305
python3 tests/src/hooks/db/test_oracle_helper.py
#1626498315
pytest tests/src/hooks/db/test_oracle_helper.py -v
#1626499892
python3 tests/src/hooks/db/test_oracle_helper.py
#1626499974
pytest tests/src/hooks/db/test_oracle_helper.py -v
#1626500348
python3 tests/src/hooks/db/test_oracle_helper.py
#1626500372
pytest tests/src/hooks/db/test_oracle_helper.py -v
#1626501073
pytest tests/src/ -v
#1626649298
yarn application --kill application_1626372459586_1151
#1626649737
yarn application --kill application_1626372459586_1153
#1626649742
yarn application --kill application_1626372459586_1154
#1626649746
yarn application --kill application_1626372459586_1155
#1626649749
yarn application --kill application_1626372459586_1156
#1626649753
yarn application --kill application_1626372459586_1157
#1626649757
yarn application --kill application_1626372459586_1158
#1626649760
yarn application --kill application_1626372459586_1159
#1626664434
yarn application --kill application_1626372459586_1180
#1626664439
yarn application --kill application_1626372459586_1181
#1626664442
yarn application --kill application_1626372459586_1182
#1626664445
yarn application --kill application_1626372459586_1183
#1626664448
yarn application --kill application_1626372459586_1184
#1626664459
yarn application --kill application_1626372459586_1185
#1626664462
yarn application --kill application_1626372459586_1186
#1626664465
yarn application --kill application_1626372459586_1187
#1626664470
yarn application --kill application_1626372459586_1188
#1626664477
yarn application --kill application_1626372459586_1189
#1626664482
yarn application --kill application_1626372459586_1190
#1626664485
yarn application --kill application_1626372459586_1191
#1626664488
yarn application --kill application_1626372459586_1192
#1626664491
yarn application --kill application_1626372459586_1193
#1626664494
yarn application --kill application_1626372459586_1194
#1626664497
yarn application --kill application_1626372459586_1195
#1626664500
yarn application --kill application_1626372459586_1196
#1626664643
yarn application --kill application_1626372459586_1171
#1626664648
yarn application --kill application_1626372459586_1172
#1626664651
yarn application --kill application_1626372459586_1173
#1626664653
yarn application --kill application_1626372459586_1174
#1626664658
yarn application --kill application_1626372459586_1175
#1626664661
yarn application --kill application_1626372459586_1176
#1626664665
yarn application --kill application_1626372459586_1177
#1626665101
yarn application --kill application_1626372459586_1166
#1626665104
yarn application --kill application_1626372459586_1167
#1626665108
yarn application --kill application_1626372459586_1169
#1626665113
yarn application --kill application_1626372459586_1170
#1626665117
yarn application --kill application_1626372459586_1178
#1626665124
yarn application --kill application_1626372459586_1179
#1626665129
yarn application --kill application_1626372459586_1197
#1626665133
yarn application --kill application_1626372459586_1198
#1626665137
yarn application --kill application_1626372459586_1199
#1626665143
yarn application --kill application_1626372459586_11200
#1626665148
yarn application --kill application_1626372459586_11201
#1626665151
yarn application --kill application_1626372459586_11202
#1626665153
yarn application --kill application_1626372459586_11203
#1626665159
yarn application --kill application_1626372459586_11204
#1626665162
yarn application --kill application_1626372459586_11205
#1626665164
yarn application --kill application_1626372459586_11206
#1626665167
yarn application --kill application_1626372459586_11207
#1626665170
yarn application --kill application_1626372459586_11208
#1626665173
yarn application --kill application_1626372459586_11209
#1626665177
yarn application --kill application_1626372459586_11210
#1626665182
yarn application --kill application_1626372459586_11211
#1626665357
yarn application --kill application_1626372459586_11201
#1626665360
yarn application --kill application_1626372459586_11202
#1626665362
yarn application --kill application_1626372459586_11203
#1626665365
yarn application --kill application_1626372459586_11204
#1626665367
yarn application --kill application_1626372459586_11205
#1626665371
yarn application --kill application_1626372459586_11206
#1626665374
yarn application --kill application_1626372459586_1120
#1626665381
yarn application --kill application_1626372459586_11207
#1626665386
yarn application --kill application_1626372459586_11208
#1626665390
yarn application --kill application_1626372459586_11209
#1626665426
yarn application --kill application_1626372459586_1201
#1626665431
yarn application --kill application_1626372459586_1202
#1626665434
yarn application --kill application_1626372459586_1203
#1626665436
yarn application --kill application_1626372459586_1204
#1626665439
yarn application --kill application_1626372459586_1205
#1626665457
yarn application --kill application_1626372459586_120~
#1626665461
yarn application --kill application_1626372459586_1206
#1626665463
yarn application --kill application_1626372459586_1207
#1626665466
yarn application --kill application_1626372459586_1208
#1626665469
yarn application --kill application_1626372459586_1209
#1626665630
yarn application --kill application_1626372459586_1211
#1626665643
yarn application --kill application_1626372459586_1210
#1626693903
yarn application --kill application_1626372459586_1216
#1626693908
yarn application --kill application_1626372459586_1217
#1626693911
yarn application --kill application_1626372459586_1218
#1626693915
yarn application --kill application_1626372459586_1220
#1626693919
yarn application --kill application_1626372459586_1219
#1626693923
yarn application --kill application_1626372459586_1221
#1626693926
yarn application --kill application_1626372459586_1222
#1626693930
yarn application --kill application_1626372459586_1223
#1626693933
yarn application --kill application_1626372459586_1224
#1626693937
yarn application --kill application_1626372459586_1225
#1626693942
yarn application --kill application_1626372459586_1226
#1626693948
yarn application --kill application_1626372459586_1227
#1626693955
yarn application --kill application_1626372459586_1228
#1626693958
yarn application --kill application_1626372459586_1229
#1626693962
yarn application --kill application_1626372459586_1230
#1626693965
yarn application --kill application_1626372459586_1231
#1626693969
yarn application --kill application_1626372459586_1232
#1626693972
yarn application --kill application_1626372459586_1233
#1626693975
yarn application --kill application_1626372459586_1234
#1626693978
yarn application --kill application_1626372459586_1235
#1626693993
yarn application --kill application_1626372459586_1236
#1626693996
yarn application --kill application_1626372459586_1237
#1626693998
yarn application --kill application_1626372459586_1238
#1626694001
yarn application --kill application_1626372459586_1239
#1626694005
yarn application --kill application_1626372459586_1240
#1626694009
yarn application --kill application_1626372459586_1241
#1626694012
yarn application --kill application_1626372459586_1242
#1626694016
yarn application --kill application_1626372459586_1243
#1626694019
yarn application --kill application_1626372459586_1244
#1626694022
yarn application --kill application_1626372459586_1245
#1626694026
yarn application --kill application_1626372459586_1246
#1626694030
yarn application --kill application_1626372459586_1247
#1626694033
yarn application --kill application_1626372459586_1248
#1626694036
yarn application --kill application_1626372459586_1249
#1626694041
yarn application --kill application_1626372459586_1250
#1626694043
yarn application --kill application_1626372459586_1251
#1626694046
yarn application --kill application_1626372459586_1252
#1626694049
yarn application --kill application_1626372459586_1253
#1626694052
yarn application --kill application_1626372459586_1254
#1626694055
yarn application --kill application_1626372459586_1255
#1626694058
yarn application --kill application_1626372459586_1256
#1626694061
yarn application --kill application_1626372459586_1257
#1626694065
yarn application --kill application_1626372459586_1258
#1626694068
yarn application --kill application_1626372459586_1259
#1626708298
ll
#1626708520
python3 poc/campos/test_import_table.py 
#1626708570
echo $PYTHONPATH
#1626708603
python3 poc/campos/test_import_table.py 
#1626714923
airflow run
#1626714938
airflow tasks
#1626714947
airflow tasks list
#1626714982
airflow tasks list dag_id import_table_ecf
#1626715030
airflow dag
#1626715037
airflow dags list
#1626715049
airflow tasks list dag_id import_table_ecf
#1626715059
airflow tasks list import_table_ecf
#1626715076
airflow tasks 
#1626715087
airflow tasks test
#1626715097
airflow tasks test extract_transform_load
#1626715121
airflow tasks test import_table_ecf extract_transform_load
#1626715139
airflow tasks test import_table_ecf extract_transform_load 2017-1-23
#1626718127
airflow tasks test import_table_ecf 
#1626718315
airflow dags list
#1626718335
airflow tasks lsit import_table_ecf 
#1626718341
airflow tasks list import_table_ecf 
#1626718428
airflow test update_control_var import_table_ecf
#1626718439
airflow test update_control_var import_table_ecf 2017-01-01
#1626718449
airflow test update_control_var import_table_ecf 2017-10-10
#1626718469
airflow tasks test update_control_var import_table_ecf 2017-10-10
#1626718507
airflow tasks test update_control_var import_table_ecf 
#1626718531
airflow tasks test import_table_ecf update_control_var 2017-10-10
#1626721316
airflow tasks test import_table_ecf extract_transform_load 2017-10-10
#1626731658
git status
#1626731660
cd ..
#1626731661
ll
#1626731665
cd ..
#1626731668
ll
#1626731670
git status
#1626731695
ll
#1626731704
git status
#1626891444
ll
#1626891448
cd ..
#1626891449
cd
#1626891460
cd /home/sat_bcampos/
#1626891461
ll
#1626891467
git clone http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1626891475
pwd
#1626970237
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1626970241
set -a # export all variables
#1626970243
source configs/.env
#1626970246
source venv/bin/activate
#1626970248
ll
#1626970285
python3 poc/campos/test_import_table.py 
#1627024553
pip3 freeze
#1627024561
pip3 freeze | grep datacla
#1627024579
pip3 freeze >> requirements.in
#1627024585
cat requirements.
#1627024587
cat requirements.in 
#1627058489
hdfs dfs -text /data/raw/prod/nfe/2020/06/01/* | jq
#1627058508
hdfs dfs -text /data/prod/raw/nfe/2020/06/01/* | jq
#1627058523
hdfs dfs -du -h /data/prod/raw/nfe/2020/06/01
#1627058529
hdfs dfs -du -h /data/prod/raw/nfe/2020/06
#1626891490
sudo -u sat_bcampos -i
#1627574672
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1627574673
ll
#1627574674
set -a # export all variables
#1627574675
source venv/bin/activate
#1627574677
source configs/.env
#1627574695
python3 poc/campos/test_cx_oracle.py 
#1627665197
git status
#1627665202
cd ..
#1627665203
ll
#1627665205
cd ..
#1627665206
ll
#1627665208
git status
#1627665251
ll
#1627665259
git remove -v
#1627665263
git remote -v
#1627665273
cd ..
#1627665274
ll
#1627665718
git status
#1627665729
cd SAT_BIG_DATA/
#1627665729
ll
#1627665732
git status
#1627665737
git init
#1627665747
git remote -v
#1627665758
git remote add origin http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1627665761
git remote -v
#1627665764
git status
#1627665778
git add --all
#1627665791
git status
#1627665831
git add commit -m "refactor: alterar a lib de importação do dados"
#1627665836
git add --all
#1627665837
git add commit -m "refactor: alterar a lib de importação do dados"
#1627665843
git commit -m "refactor: alterar a lib de importação do dados"
#1627665848
git push origin master
#1627665892
git remote remove origin 
#1627665901
git remote add origin http://satdevops.sef.sc.gov.br/tfs/SAT-DevOps/SAT_DES/_git/SAT_BIG_DATA
#1627665907
git add --all
#1627665910
git commit -m "refactor: alterar a lib de importação do dados"
#1627665914
git push origin master
#1627666296
git pull origin master
#1627666323
git status
#1627666380
git add --all
#1627666385
git commit -m "refactor: alterar a lib de importação do dados"
#1627666388
git push origin master
#1627666486
git logh
#1627666487
git log
#1627666524
git status
#1627666548
git reset HEAD 252e44e4c65ae62dbf180d9055f453a1a6753411
#1627666551
ll
#1627666555
git status
#1627666578
cat cd data-pipeline/batch/dags/expand.py 
#1627667243
ll
#1627667340
cat cd data-pipeline/batch/dags/expand.py 
#1627667704
ll
#1627667708
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1627667718
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1627667719
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1627667732
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon]
#1627667735
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1627667741
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1627667745
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1627754366
ll
#1627959513
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/raw/ttd/*.parquet | jq
#1627959537
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1627959549
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1627959572
hadoop jar /ssddisk/SAT_BIG_DATA/batch/data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1627959610
#/ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar 
#1627959626
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1627969153
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1627969153
ll
#1627969180
python3 src/utils/prepare_env.py 
#1627969186
set -a # export all variables
#1627969189
source configs/.env
#1627969191
source venv/bin/activate
#1627969195
python3 src/utils/prepare_env.py 
#1627997613
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1627997737
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet |  jq
#1627997778
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet) | jq
#1627999620
ll
#1627999889
python3 src/utils/prepare_env.py 
#1628038876
ll
#1628076740
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/conta_corrente/*.parquet | awk '{printf "%s ", $NF}') | jq
#1628076837
hdfs dfs -ls /data/prod/raw/conta_corrente/*.parquet
#1628076848
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/conta_corrente/*.parquet | awk '{printf "%s ", $NF}') | jq
#1628076890
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet) | jq
#1628076920
hadoop jar /ssddisk/SAT_BIG_DATA/bda-batch-data-pipeline/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/ttd/*.parquet | awk '{printf "%s ", $NF}') | jq
#1628077081
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/conta_corrente/*.parquet | awk '{printf "%s ", $NF}') | jq
#1628077158
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/conta_corrente/part-00000-019f654a-00be-4729-8ef9-021f4e4a0e8d-c000.snappy.parquet | awk '{printf "%s ", $NF}') | jq
#1628250104
python3 src/utils/prepare_env.py 
#1628251687
python3 poc/campos/remove_duplicates.py 
#1628270264
python3 poc/campos/df_delete_rows.py 
#1628289233
airflow tasks test import_table_ttd sync_data 2017-1-23
#1628329898
airflow tasks test import_table_cadastro sync_data 2017-1-23
#1628332388
airflow tasks test import_table_ecf sync_data 2017-1-23
#1628333487
airflow tasks test import_table_cadastro sync_data 2017-1-23
#1628341204
airflow tasks test import_table_ecf sync_data 2017-1-23
#1628341428
airflow tasks test import_table_cadastro sync_data 2017-1-23
#1628349414
airflow tasks test import_table_ecf sync_data 2017-1-23
#1628353688
airflow tasks test import_table_cadastro sync_data 2017-1-23
#1628354558
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1628562983
ll
#1628563056
l
#1628563091
airflow tasks test import_table_conta_corrente extract_transform_load 2017-1-23
#1628566883
airflow tasks test import_table_pagamento extract_transform_load 2017-1-23
#1628655796
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1628655800
set -a # export all variables
#1628655803
source venv/bin/activate
#1628655805
source configs/.env
#1628655808
pytest tests/src/hooks/db/test_oracle_helper.py -v
#1628655845
pytest tests/dags/test_import_table.py -v
#1628655868
pytest tests/dags -v
#1628655878
pytest tests/dags/test_import_table.py -v
#1628656083
python3 tests/dags/test_import_table.py
#1628656549
pytest tests/dags/test_import_table.py -v
#1628656679
python3 tests/dags/test_import_table.py
#1628657288
pytest tests/dags/test_import_table.py -v
#1628657981
python3 tests/dags/test_import_table.py
#1628658679
pytest tests/dags/test_import_table.py -v
#1628658746
python3 tests/dags/test_import_table.py
#1628658776
pytest tests/dags/test_import_table.py -v
#1628659116
python3 tests/dags/test_import_table.py
#1628659180
pytest tests/dags/test_import_table.py -v
#1628661413
python3 tests/dags/test_import_table.py
#1628661547
pytest tests/dags/test_import_table.py -v
#1628661704
pytest tests/dags/test_import_table.py -vv
#1628664806
airflow tasks test import_table_conta_corrente sync_data 2017-1-23
#1628700699
ll
#1628703075
airflow tasks test import_table_conta_corrente sync_data 2017-1-23
#1628715845
ll
#1628716961
airflow tasks test import_table_conta_corrente sync_data 2017-1-23
#1628758363
pyspark
#1628759619
airflow tasks test import_table_conta_corrente sync_data 2017-1-23
#1628778861
ipaddr
#1628778866
ip addr
#1628790229
ping 219.215.0.1
#1628790245
ping 200.19.215.1
#1628790545
ping 200.19.215.2
#1628790561
ping 200.19.215.9
#1628790591
cat /etc/resolv.conf
#1628790599
ping 200.19.215.2
#1628790648
ping 200.19.215.9
#1628790672
ping 200.19.215.2
#1628790747
ping 200.19.215.9
#1628790832
ping 200.19.215.2
#1628792110
ip addr
#1628792436
ping 200.19.215.9
#1628792440
cat /etc/resolv.conf
#1628792453
ping 200.19.215.9
#1628831604
python3 dags/expand.py 
#1628831613
python3 -m pdb dags/expand.py 
#1628831899
python3 dags/expand.py 
#1628832190
ipython
#1628832196
ipython3
#1628919092
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1628919095
ll
#1628919103
pip3 install showenv
#1628919114
showenv
#1628919129
pip3 install pyfiglet
#1628919132
showenv
#1629144546
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1629144548
set -a # export all variables
#1629144551
source configs/.env
#1629144553
source venv/bin/activate
#1629144556
ll
#1629144630
python3 poc/campos/test_import_table.py 
#1629148753
python3 poc/campos/test__slots__.py 
#1629173339
python3 -m pdb poc/campos/test__slots__.py 
#1629178367

#1629178371
ll
#1629221887
git status
#1629293463
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1629293466
ll
#1629293471
set -a # export all variables
#1629293473
source venv/bin/activate
#1629293474
source configs/.env
#1629293476
ll
#1629293493
python poc/campos/test_import_table.py 
#1629374014
ll
#1629441196
ll /opt/oracle/bda/install/
#1629441298
ll /opt/oracle/bda/install/state/
#1629463257
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1629463258
ll
#1629463271
set -a # export all variables
#1629463273
source configs/.env
#1629463277
source venv/bin/activate
#1629463278
ll
#1629463293
rm -rf struture_project.txt
#1629463295
ll
#1629464023
kinit
#1629464279
klist
#1629464298
kdestroy
#1629464299
klist
#1629464307
kinit
#1629464389
klist
#1629464396
kdestroy -h
#1629464407
kdestroy -c hive
#1629464414
kdestroy -c hive/bda1node04.sef.sc.gov.br@PROD.SEF.SC.GOV.BR
#1629464425
kdestroy
#1629464428
klist
#1629513585
kdestroy
#1629513687
klist
#1629789381
cd ..
#1629789383
ll
#1629789428
cd gabriel/
#1629789428
ll
#1629789575
cd ..
#1629789577
ll
#1629789603
sudo rm -rf bda-batch-data-pipeline/
#1629789619
cd data-pipeline/batch/
#1629789619
ll
#1630443055
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1630443058
set -a # export all variables
#1630443060
source venv/bin/activate
#1630443061
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1630443083
python3  $AIRFLOW_HOME/src/utils/generate_dag_config.py
#1630443098
pwd
#1630443100
ll
#1630443111
python3  $AIRFLOW_HOME/src/utils/generate_dag_config.py
#1630443122
set -a # export all variables
#1630443126
source configs/.env
#1630443129
python3  $AIRFLOW_HOME/src/utils/generate_dag_config.py
#1630443146
python3  \$AIRFLOW_HOME/src/utils/generate_conn_config.py
#1630443155
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1630447736
ll
#1630447750
pytest tests/dags/test_import_table.py -vv
#1630447794
pytest tests/dags/test_import_table.py 
#1630447890
pytest tests/dags/
#1630447897
pytest tests/
#1630447933
pytest tests -vv
#1630449070
hdfs dfs -text /data/prod/raw/nfe/2020/06/01/* | jq
#1630449095
hdfs dfs -text /data/prod/raw/dime/2020/06/01/* | jq
#1630449124
hdfs dfs -text /data/prod/raw/sintegra/2020/06/01/* | jq
#1630449150
hdfs dfs -text /data/prod/raw/ed/2020/06/01/* | jq
#1630449155
hdfs dfs -text /data/prod/raw/efd/2020/06/01/* | jq
#1630449290
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1630449352
ll
#1630498922
hdfs dfs -text /data/prod/raw/nfe/2020/06/01/* | jq
#1630498948
hdfs dfs -text /data/prod/raw/nfe/2020/06/01/* | more
#1630499033
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1630499125
hdfs dfs -text /data/prod/raw/efd/2020/06/01/* | jq
#1630499184
hdfs dfs -text /data/prod/raw/dime/2020/06/01/* | jq
#1630501880
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1630524689
ll
#1630950486
klist
#1631196286
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch/
#1631196287
ll
#1631196301
cd configs/
#1631196301
ll
#1631196303
cd data/
#1631196304
ll
#1631196325
sudo chown -R sat_job ccg.json 
#1631196329
ll
#1631196345
sudo chgrp -R job_group ccg.json 
#1631196346
ll
#1631196376
cat ccg.json
#1631198066
cd ..
#1631198067
ll
#1631198088
virtualenv -p python3 venv
#1631198091
source venv/bin/activate
#1631198097
set -a # export all variables
#1631198097
source configs/.env
#1631198108
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631198129
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631198132
python3  $AIRFLOW_HOME/src/utils/generate_dag_config.py
#1631198135
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631211270
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631211347
hdfs dfs -ls /data/prod/raw/pagamento/
#1631211427
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631211456
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/part-00024-2c4e678a-9ec5-460b-ba65-8510f2b5df3f-c000.snappy.parquet | awk '{printf "%s ", $NF}') | jq
#1631211516
ipython
#1631211524
pip3 install ipython
#1631211536
ipython
#1631220472
ll
#1631221706
source /opt/jupyterhub/venv/bin/activate
#1631221712
which python
#1631221822
pip3 install keras
#1631222289
pip3 install tensorflow
#1631283777
sudo -u hdfs -i
#1631296461
echo $USER
#1631296522
source configs/.env
#1631296548
echo $ORACLE_PASSWORD
#1631296562
source configs/.env
#1631296564
echo $ORACLE_PASSWORD
#1631296617
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631296627
cat /ssddisk/SAT_BIG_DATA/data-pipeline/batch/configs/conn_config.json
#1631296958
source configs/.env
#1631296966
echo $BIGDATA_LOGIN
#1631307126
ll
#1631307171
hdfs dfs -text /data/raw/nfe/2021/09/01/*.avro | wc -l
#1631307184
hdfs dfs -text /data/prod/raw/nfe/2021/09/01/*.avro | wc -l
#1631311425
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631311752
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631311759
which python3
#1631311762
ex
#1631311827
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1631311832
source venv/bin/activate
#1631311836
set -a # export all variables
#1631311836
source configs/.env
#1631311840
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631311844
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631312628
python3  $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631312632
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631313226
ping exacc01-scan.sef.sc.gov.br
#1631313258
ping exacc02-scan.sef.sc.gov.br
#1631313284
python3 $AIRFLOW_HOME/src/utils/generate_conn_config.py
#1631313291
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631562854
pwd
#1631562860
cd /
#1631562893
cd /ssddisk/SAT_BIG_DATA/
#1631562935
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1631562987
vim ~/.bashrc
#1631563168
ip addr
#1631563204
cat README.md
#1631563233
set -a
#1631563260
source configs/.env
#1631563290
source venv/bin/activate
#1631563326
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631572108
pwd
#1631597284
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1631597286
set -a # export all variables
#1631597288
source configs/.env
#1631597330
ll
#1631597399
source venv/bin/activate
#1631597401
ll
#1631597418
airflow
#1631597425
airflow scheduler
#1631597433
airflow scheduler --help
#1631597478
l
#1631597483
cat
#1631597501
cat logs/airflow-scheduler.err 
#1631597533
cat logs/airflow-scheduler.log 
#1631597544
tail logs/airflow-scheduler.log 
#1631597620
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1631597632
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1631597633
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1631597653
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1631597661
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1631597666
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1631597670
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1631597765
sudo kill -9 $(ps aux | grep 'airflow' | awk '{print $2}')
#1631597765
sudo kill -9 $(ps aux | grep 'celery' | awk '{print $2}')
#1631597766
sudo kill -9 $(ps aux | grep 'flower' | awk '{print $2}')
#1631597770
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.err
#1631597770
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.out
#1631597771
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.pid
#1631597771
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/*.log
#1631597772
sudo rm -rf /ssddisk/SAT_BIG_DATA/data-pipeline/batch/logs/scheduler*
#1631597785
airflow webserver     --stdout $AIRFLOW_HOME/logs/airflow-webserver.out     --stderr $AIRFLOW_HOME/logs/airflow-webserver.err     --log-file $AIRFLOW_HOME/logs/airflow-webserver.log     --pid $AIRFLOW_HOME/logs/airflow-webserver.pid     --port 8080     --daemon
#1631597792
airflow celery flower     --stdout $AIRFLOW_HOME/logs/airflow-flower.out     --stderr $AIRFLOW_HOME/logs/airflow-flower.err     --log-file $AIRFLOW_HOME/logs/airflow-flower.log     --pid $AIRFLOW_HOME/logs/airflow-flower.pid     --daemon
#1631597796
airflow scheduler     --stdout $AIRFLOW_HOME/logs/airflow-scheduler.out     --stderr $AIRFLOW_HOME/logs/airflow-scheduler.err     --log-file $AIRFLOW_HOME/logs/airflow-scheduler.log     --pid $AIRFLOW_HOME/logs/airflow-scheduler.pid     --daemon
#1631597800
airflow celery worker     --stdout $AIRFLOW_HOME/logs/airflow-worker.out     --stderr $AIRFLOW_HOME/logs/airflow-worker.err     --log-file $AIRFLOW_HOME/logs/airflow-worker.log     --pid $AIRFLOW_HOME/logs/airflow-worker.pid     --daemon
#1631597866
airflow tasks 
#1631597871
airflow tasks list
#1631597881
airflow tasks list import_file_cte
#1631635067
cd /ssddisk/SAT_BIG_DATA/data-pipeline/batch
#1631635070
set -a # export all variables
#1631635072
source venv/bin/activate
#1631635076
source configs/.env
#1631635087
ll
#1631635096
cd configs/
#1631635096
ll
#1631635099
cd data/
#1631635100
ll
#1631635121
sudo chown sat_job nfce.json 
#1631635144
sudo chgrp job_group nfce.json 
#1631635145
ll
#1631636414
hdfs dfs -text /data/prod/raw/nfe/2021/09/01/*.avro | wc -l
#1631636433
hdfs dfs -text /data/prod/raw/nfe/2021/09/01/*.avro | jq
#1631636470
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/part-00024-2c4e678a-9ec5-460b-ba65-8510f2b5df3f-c000.snappy.parquet | awk '{printf "%s ", $NF}') | jq
#1631636489
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631636507
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631636716
ctop
#1631639092
hdfs dfs -text /data/prod/raw/nfe/2021/09/01/*.avro | jq
#1631639129
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/cadastro/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631641461
ping bda1node05.sef.sc.gov.br
#1631642320
ll
#1631654761
source configs/.env
#1631654783
source venv/bin/activate
#1631654784
pwd
#1631654791
cd /ssddisk/
#1631654793
cd SAT_BIG_DATA/
#1631654799
source venv/bin/activate
#1631654810
cd data-pipeline/
#1631654813
cd batch/
#1631654815
source venv/bin/activate
#1631654827
set -a # export all variables
#1631654828
source configs/.env
#1631654831
pytest
#1631654849
pytest tests -vv
#1631678475
cd ..
#1631678475
ll
#1631678511
cd ..
#1631678519
ll
#1631678525
cd tests/
#1631678525
ll
#1631678530
pytest tests -vv
#1631678544
cd ..
#1631678546
pytest tests -vv
#1631681115
hadoop jar /ssddisk/SAT_BIG_DATA/data-pipeline/batch/libs/parquet-tools-1.10.99.7.2.8.0-228.jar cat --json $(hdfs dfs -ls /data/prod/raw/pagamento/*.parquet | awk '{printf "%s ", $NF}') | jq
#1631682263
python3 $AIRFLOW_HOME/src/utils/prepare_env.py
#1631702139
pytest tests -vv
#1631702864
vim $AIRFLOW_HOME/src/utils/prepare_env.py
#1631703307
cat a
#1631703317
sudo vim ~/.bash
#1631703317
sudo vim ~/.bash
#1631703317
sudo vim ~/.bash
#1631703323
sudo vim ~/.bashrc
#1631703377
cat a
#1631703379
cat airflow.cfg 
#1631703424
cd
#1631703428
ll
#1631703430
wget https://github.com/jingweno/ccat/releases/download/v1.1.0/linux-amd64-1.1.0.tar.gz
#1631703434
tar xfz linux-amd64-1.1.0.tar.gz 
#1631703437
sudo cp linux-amd64-1.1.0/ccat /usr/local/bin/
#1631703440
sudo chmod +x /usr/local/bin/ccat
#1631703444
cat airflow.cfg 
#1631703458
cat .bashrc
#1631703536
ll
#1631703554
exity
#1631703578
cat .bash_eternal_history 
#1631703600
cat .bash_history 
#1631703616
ll
#1631703627
cat .bash_eternal_history 
